2022-08-02 14:44:38.134  INFO   53 --- [           main] com.elite.cdr.validator.Application      : Starting ASN1 Reader 
2022-08-02 14:44:38.149  INFO   55 --- [           main] com.elite.cdr.validator.Application      : ############### Run with the args [--env, local, --file, src/main/resources/data/simpleTypes.ber, --prop, src/main/resources/myapp.properties]
2022-08-02 14:44:38.227  INFO   61 --- [           main] com.elite.cdr.validator.Application      : ############### Run in local mode
2022-08-02 14:44:40.045  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Running Spark version 3.2.1
2022-08-02 14:44:40.451  INFO   57 --- [           main] org.apache.spark.internal.Logging        : ==============================================================
2022-08-02 14:44:40.451  INFO   57 --- [           main] org.apache.spark.internal.Logging        : No custom resources configured for spark.driver.
2022-08-02 14:44:40.451  INFO   57 --- [           main] org.apache.spark.internal.Logging        : ==============================================================
2022-08-02 14:44:40.451  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Submitted application: NiFi Spark Streaming example
2022-08-02 14:44:40.529  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2022-08-02 14:44:40.560  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Limiting resource is cpu
2022-08-02 14:44:40.576  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Added ResourceProfile id: 0
2022-08-02 14:44:40.779  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Changing view acls to: Wael Hamdi
2022-08-02 14:44:40.779  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Changing modify acls to: Wael Hamdi
2022-08-02 14:44:40.779  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Changing view acls groups to: 
2022-08-02 14:44:40.779  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Changing modify acls groups to: 
2022-08-02 14:44:40.779  INFO   57 --- [           main] org.apache.spark.internal.Logging        : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Wael Hamdi); groups with view permissions: Set(); users  with modify permissions: Set(Wael Hamdi); groups with modify permissions: Set()
2022-08-02 14:44:43.861  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Successfully started service 'sparkDriver' on port 61425.
2022-08-02 14:44:43.909  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Registering MapOutputTracker
2022-08-02 14:44:43.974  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Registering BlockManagerMaster
2022-08-02 14:44:44.021  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2022-08-02 14:44:44.021  INFO   57 --- [           main] org.apache.spark.internal.Logging        : BlockManagerMasterEndpoint up
2022-08-02 14:44:44.037  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Registering BlockManagerMasterHeartbeat
2022-08-02 14:44:44.084  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Created local directory at C:\Users\Wael Hamdi\AppData\Local\Temp\blockmgr-a6c1a88f-75e0-4976-8651-c99532727885
2022-08-02 14:44:44.115  INFO   57 --- [           main] org.apache.spark.internal.Logging        : MemoryStore started with capacity 897.6 MiB
2022-08-02 14:44:44.131  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Registering OutputCommitCoordinator
2022-08-02 14:44:44.240  INFO  170 --- [           main] org.sparkproject.jetty.util.log.Log      : Logging initialized @7247ms to org.sparkproject.jetty.util.log.Slf4jLog
2022-08-02 14:44:44.334  INFO  375 --- [           main] org.sparkproject.jetty.server.Server     : jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_301-b09
2022-08-02 14:44:44.365  INFO  415 --- [           main] org.sparkproject.jetty.server.Server     : Started @7374ms
2022-08-02 14:44:44.412  INFO  331 --- [           main] rkproject.jetty.server.AbstractConnector : Started ServerConnector@476aac9{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2022-08-02 14:44:44.412  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Successfully started service 'SparkUI' on port 4040.
2022-08-02 14:44:44.459  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3591009c{/jobs,null,AVAILABLE,@Spark}
2022-08-02 14:44:44.459  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@410954b{/jobs/json,null,AVAILABLE,@Spark}
2022-08-02 14:44:44.459  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3b366632{/jobs/job,null,AVAILABLE,@Spark}
2022-08-02 14:44:44.459  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@617fe9e1{/jobs/job/json,null,AVAILABLE,@Spark}
2022-08-02 14:44:44.459  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1cf2fed4{/stages,null,AVAILABLE,@Spark}
2022-08-02 14:44:44.459  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@245a26e1{/stages/json,null,AVAILABLE,@Spark}
2022-08-02 14:44:44.459  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@466cf502{/stages/stage,null,AVAILABLE,@Spark}
2022-08-02 14:44:44.459  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5f7f2382{/stages/stage/json,null,AVAILABLE,@Spark}
2022-08-02 14:44:44.459  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6815c5f2{/stages/pool,null,AVAILABLE,@Spark}
2022-08-02 14:44:44.474  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@60094a13{/stages/pool/json,null,AVAILABLE,@Spark}
2022-08-02 14:44:44.474  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1c32886a{/storage,null,AVAILABLE,@Spark}
2022-08-02 14:44:44.474  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@10b892d5{/storage/json,null,AVAILABLE,@Spark}
2022-08-02 14:44:44.474  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3546d80f{/storage/rdd,null,AVAILABLE,@Spark}
2022-08-02 14:44:44.474  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3670f00{/storage/rdd/json,null,AVAILABLE,@Spark}
2022-08-02 14:44:44.474  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@46ab18da{/environment,null,AVAILABLE,@Spark}
2022-08-02 14:44:44.474  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@42257bdd{/environment/json,null,AVAILABLE,@Spark}
2022-08-02 14:44:44.474  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@687a762c{/executors,null,AVAILABLE,@Spark}
2022-08-02 14:44:44.474  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@733c423e{/executors/json,null,AVAILABLE,@Spark}
2022-08-02 14:44:44.474  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@70925b45{/executors/threadDump,null,AVAILABLE,@Spark}
2022-08-02 14:44:44.490  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@aa22f1c{/executors/threadDump/json,null,AVAILABLE,@Spark}
2022-08-02 14:44:44.490  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@37cd92d6{/static,null,AVAILABLE,@Spark}
2022-08-02 14:44:44.490  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@226f885f{/,null,AVAILABLE,@Spark}
2022-08-02 14:44:44.506  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7d61eccf{/api,null,AVAILABLE,@Spark}
2022-08-02 14:44:44.506  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2427e004{/jobs/job/kill,null,AVAILABLE,@Spark}
2022-08-02 14:44:44.506  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@63f34b70{/stages/stage/kill,null,AVAILABLE,@Spark}
2022-08-02 14:44:44.506  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Bound SparkUI to 0.0.0.0, and started at http://host.docker.internal:4040
2022-08-02 14:44:44.803  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Starting executor ID driver on host host.docker.internal
2022-08-02 14:44:44.881  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 61449.
2022-08-02 14:44:44.881  INFO   82 --- [           main] .network.netty.NettyBlockTransferService : Server created on host.docker.internal:61449
2022-08-02 14:44:44.881  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2022-08-02 14:44:44.896  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Registering BlockManager BlockManagerId(driver, host.docker.internal, 61449, None)
2022-08-02 14:44:44.896  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Registering block manager host.docker.internal:61449 with 897.6 MiB RAM, BlockManagerId(driver, host.docker.internal, 61449, None)
2022-08-02 14:44:44.896  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Registered BlockManager BlockManagerId(driver, host.docker.internal, 61449, None)
2022-08-02 14:44:44.896  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Initialized BlockManager: BlockManagerId(driver, host.docker.internal, 61449, None)
2022-08-02 14:44:45.193  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6ad5923a{/metrics/json,null,AVAILABLE,@Spark}
2022-08-02 14:44:45.928  INFO   57 --- [streaming-start] org.apache.spark.internal.Logging        : Starting 1 receivers
2022-08-02 14:44:45.928  INFO   57 --- [streaming-start] org.apache.spark.internal.Logging        : ReceiverTracker started
2022-08-02 14:44:45.943  INFO   57 --- [streaming-start] org.apache.spark.internal.Logging        : Slide time = 1000 ms
2022-08-02 14:44:45.943  INFO   57 --- [streaming-start] org.apache.spark.internal.Logging        : Storage level = Serialized 1x Replicated
2022-08-02 14:44:45.943  INFO   57 --- [streaming-start] org.apache.spark.internal.Logging        : Checkpoint interval = null
2022-08-02 14:44:45.943  INFO   57 --- [streaming-start] org.apache.spark.internal.Logging        : Remember interval = 1000 ms
2022-08-02 14:44:45.943  INFO   57 --- [streaming-start] org.apache.spark.internal.Logging        : Initialized and validated org.apache.spark.streaming.dstream.PluggableInputDStream@3f69ad10
2022-08-02 14:44:45.943  INFO   57 --- [streaming-start] org.apache.spark.internal.Logging        : Slide time = 1000 ms
2022-08-02 14:44:45.943  INFO   57 --- [streaming-start] org.apache.spark.internal.Logging        : Storage level = Serialized 1x Replicated
2022-08-02 14:44:45.943  INFO   57 --- [streaming-start] org.apache.spark.internal.Logging        : Checkpoint interval = null
2022-08-02 14:44:45.943  INFO   57 --- [streaming-start] org.apache.spark.internal.Logging        : Remember interval = 1000 ms
2022-08-02 14:44:45.943  INFO   57 --- [streaming-start] org.apache.spark.internal.Logging        : Initialized and validated org.apache.spark.streaming.dstream.MappedDStream@491f9f05
2022-08-02 14:44:45.943  INFO   57 --- [streaming-start] org.apache.spark.internal.Logging        : Slide time = 1000 ms
2022-08-02 14:44:45.943  INFO   57 --- [streaming-start] org.apache.spark.internal.Logging        : Storage level = Serialized 1x Replicated
2022-08-02 14:44:45.943  INFO   57 --- [streaming-start] org.apache.spark.internal.Logging        : Checkpoint interval = null
2022-08-02 14:44:45.943  INFO   57 --- [streaming-start] org.apache.spark.internal.Logging        : Remember interval = 1000 ms
2022-08-02 14:44:45.943  INFO   57 --- [streaming-start] org.apache.spark.internal.Logging        : Initialized and validated org.apache.spark.streaming.dstream.ForEachDStream@61ad55d8
2022-08-02 14:44:46.068  INFO   57 --- [er-event-loop-3] org.apache.spark.internal.Logging        : Receiver 0 started
2022-08-02 14:44:46.068  INFO   57 --- [streaming-start] org.apache.spark.internal.Logging        : Started timer for JobGenerator at time 1659447886000
2022-08-02 14:44:46.068  INFO   57 --- [streaming-start] org.apache.spark.internal.Logging        : Started JobGenerator at 1659447886000 ms
2022-08-02 14:44:46.068  INFO   57 --- [streaming-start] org.apache.spark.internal.Logging        : Started JobScheduler
2022-08-02 14:44:46.093  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 0 (start at Application.java:188) with 1 output partitions
2022-08-02 14:44:46.094  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 0 (start at Application.java:188)
2022-08-02 14:44:46.094  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2125ad3{/streaming,null,AVAILABLE,@Spark}
2022-08-02 14:44:46.095  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List()
2022-08-02 14:44:46.096  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@f4c0e4e{/streaming/json,null,AVAILABLE,@Spark}
2022-08-02 14:44:46.097  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-08-02 14:44:46.098  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6eb82908{/streaming/batch,null,AVAILABLE,@Spark}
2022-08-02 14:44:46.100  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3d98d138{/streaming/batch/json,null,AVAILABLE,@Spark}
2022-08-02 14:44:46.112  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5e2f3be5{/static/streaming,null,AVAILABLE,@Spark}
2022-08-02 14:44:46.112  INFO   57 --- [           main] org.apache.spark.internal.Logging        : StreamingContext started
2022-08-02 14:44:46.116  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 0 (Receiver 0 ParallelCollectionRDD[0] at makeRDD at ReceiverTracker.scala:609), which has no missing parents
2022-08-02 14:44:46.152  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659447886000 ms
2022-08-02 14:44:46.181  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659447886000 ms.0 from job set of time 1659447886000 ms
2022-08-02 14:44:46.317  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkContext; some configuration may not take effect.
2022-08-02 14:44:46.430  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_0 stored as values in memory (estimated size 97.5 KiB, free 897.5 MiB)
2022-08-02 14:44:46.579  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_0_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 897.5 MiB)
2022-08-02 14:44:46.584  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_0_piece0 in memory on host.docker.internal:61449 (size: 34.2 KiB, free: 897.6 MiB)
2022-08-02 14:44:46.590  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 0 from broadcast at DAGScheduler.scala:1478
2022-08-02 14:44:46.616  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 0 (Receiver 0 ParallelCollectionRDD[0] at makeRDD at ReceiverTracker.scala:609) (first 15 tasks are for partitions Vector(0))
2022-08-02 14:44:46.618  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 0.0 with 1 tasks resource profile 0
2022-08-02 14:44:46.757  INFO   57 --- [er-event-loop-0] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 0.0 (TID 0) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 5950 bytes) taskResourceAssignments Map()
2022-08-02 14:44:46.806  INFO   57 --- [age 0.0 (TID 0)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 0.0 (TID 0)
2022-08-02 14:44:46.906  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2022-08-02 14:44:47.013  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659447887000 ms
2022-08-02 14:44:47.277  INFO   57 --- [age 0.0 (TID 0)] org.apache.spark.internal.Logging        : Started timer for BlockGenerator at time 1659447887400
2022-08-02 14:44:47.279  INFO   57 --- [age 0.0 (TID 0)] org.apache.spark.internal.Logging        : Started BlockGenerator
2022-08-02 14:44:47.288  INFO   57 --- [      Thread-14] org.apache.spark.internal.Logging        : Started block pushing thread
2022-08-02 14:44:47.292  INFO   57 --- [er-event-loop-0] org.apache.spark.internal.Logging        : Registered receiver for stream 0 from host.docker.internal:61425
2022-08-02 14:44:47.295  INFO   57 --- [age 0.0 (TID 0)] org.apache.spark.internal.Logging        : Starting receiver 0
2022-08-02 14:44:47.298  INFO   57 --- [age 0.0 (TID 0)] org.apache.spark.internal.Logging        : Called receiver 0 onStart
2022-08-02 14:44:47.300  INFO   57 --- [age 0.0 (TID 0)] org.apache.spark.internal.Logging        : Waiting for receiver to be stopped
2022-08-02 14:44:47.877  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Warehouse path is 'file:/C:/IntelliJProjects/NifiSparkStreaming/spark-warehouse'.
2022-08-02 14:44:47.895  INFO  915 --- [-job-executor-0] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@49daaf4a{/SQL,null,AVAILABLE,@Spark}
2022-08-02 14:44:47.897  INFO  915 --- [-job-executor-0] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4bcd9bec{/SQL/json,null,AVAILABLE,@Spark}
2022-08-02 14:44:47.899  INFO  915 --- [-job-executor-0] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1d3944db{/SQL/execution,null,AVAILABLE,@Spark}
2022-08-02 14:44:47.901  INFO  915 --- [-job-executor-0] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@501a1095{/SQL/execution/json,null,AVAILABLE,@Spark}
2022-08-02 14:44:47.904  INFO  915 --- [-job-executor-0] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4228d12d{/static/sql,null,AVAILABLE,@Spark}
2022-08-02 14:44:48.011  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659447888000 ms
2022-08-02 14:44:48.967  INFO  571 --- [  NiFi Receiver] g.apache.nifi.remote.client.PeerSelector : Successfully refreshed peer status cache; remote group consists of 1 peers
2022-08-02 14:44:48.967  INFO  571 --- [ool Maintenance] g.apache.nifi.remote.client.PeerSelector : Successfully refreshed peer status cache; remote group consists of 1 peers
2022-08-02 14:44:49.004  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659447889000 ms
2022-08-02 14:44:49.054  INFO   57 --- [  NiFi Receiver] org.apache.spark.internal.Logging        : Block input-0-1659447887266 stored as values in memory (estimated size 5.1 MiB, free 892.4 MiB)
2022-08-02 14:44:49.079  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added input-0-1659447887266 in memory on host.docker.internal:61449 (size: 5.1 MiB, free: 892.5 MiB)
2022-08-02 14:44:50.008  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659447890000 ms
2022-08-02 14:44:51.006  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659447891000 ms
2022-08-02 14:44:52.028  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659447892000 ms
2022-08-02 14:44:53.121  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659447893000 ms
2022-08-02 14:44:54.004  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659447894000 ms
2022-08-02 14:44:55.002  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659447895000 ms
2022-08-02 14:44:55.687  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Code generated in 354.4553 ms
2022-08-02 14:44:56.005  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659447896000 ms
2022-08-02 14:44:56.041  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Code generated in 26.1367 ms
2022-08-02 14:44:56.097  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Code generated in 16.1388 ms
2022-08-02 14:44:56.167  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:164
2022-08-02 14:44:56.174  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 28 (count at Application.java:164) as input to shuffle 0
2022-08-02 14:44:56.180  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 1 (count at Application.java:164) with 1 output partitions
2022-08-02 14:44:56.180  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 2 (count at Application.java:164)
2022-08-02 14:44:56.180  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 1)
2022-08-02 14:44:56.181  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-08-02 14:44:56.183  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 2 (MapPartitionsRDD[31] at count at Application.java:164), which has no missing parents
2022-08-02 14:44:56.193  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_1 stored as values in memory (estimated size 11.0 KiB, free 892.4 MiB)
2022-08-02 14:44:56.200  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 892.4 MiB)
2022-08-02 14:44:56.201  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_1_piece0 in memory on host.docker.internal:61449 (size: 5.4 KiB, free: 892.5 MiB)
2022-08-02 14:44:56.202  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 1 from broadcast at DAGScheduler.scala:1478
2022-08-02 14:44:56.202  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[31] at count at Application.java:164) (first 15 tasks are for partitions Vector(0))
2022-08-02 14:44:56.203  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 2.0 with 1 tasks resource profile 0
2022-08-02 14:44:56.206  INFO   57 --- [er-event-loop-2] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 2.0 (TID 1) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-08-02 14:44:56.207  INFO   57 --- [age 2.0 (TID 1)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 2.0 (TID 1)
2022-08-02 14:44:56.434  WARN   69 --- [ver-heartbeater] org.apache.spark.internal.Logging        : Exception when trying to compute pagesize, as a result reporting of ProcessTree metrics is stopped
2022-08-02 14:44:56.446  INFO   57 --- [age 2.0 (TID 1)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-08-02 14:44:56.452  INFO   57 --- [age 2.0 (TID 1)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 15 ms
2022-08-02 14:44:56.478  INFO   57 --- [age 2.0 (TID 1)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 2.0 (TID 1). 2641 bytes result sent to driver
2022-08-02 14:44:56.486  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 2.0 (TID 1) in 281 ms on host.docker.internal (executor driver) (1/1)
2022-08-02 14:44:56.490  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Removed TaskSet 2.0, whose tasks have all completed, from pool 
2022-08-02 14:44:56.498  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 2 (count at Application.java:164) finished in 0.306 s
2022-08-02 14:44:56.503  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2022-08-02 14:44:56.504  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 2: Stage finished
2022-08-02 14:44:56.507  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 1 finished: count at Application.java:164, took 0.339098 s
2022-08-02 14:44:56.516  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659447886000 ms.0 from job set of time 1659447886000 ms
2022-08-02 14:44:56.518  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 10.515 s for time 1659447886000 ms (execution: 10.335 s)
2022-08-02 14:44:56.518  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659447887000 ms.0 from job set of time 1659447887000 ms
2022-08-02 14:44:56.521  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-08-02 14:44:56.522  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-08-02 14:44:56.529  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 
2022-08-02 14:44:56.532  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 
2022-08-02 14:44:56.694  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_1_piece0 on host.docker.internal:61449 in memory (size: 5.4 KiB, free: 892.5 MiB)
2022-08-02 14:44:56.754  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:164
2022-08-02 14:44:56.756  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 37 (count at Application.java:164) as input to shuffle 1
2022-08-02 14:44:56.757  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 2 (count at Application.java:164) with 1 output partitions
2022-08-02 14:44:56.757  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 4 (count at Application.java:164)
2022-08-02 14:44:56.757  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 3)
2022-08-02 14:44:56.757  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-08-02 14:44:56.758  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 4 (MapPartitionsRDD[40] at count at Application.java:164), which has no missing parents
2022-08-02 14:44:56.763  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_2 stored as values in memory (estimated size 11.0 KiB, free 892.4 MiB)
2022-08-02 14:44:56.765  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 892.4 MiB)
2022-08-02 14:44:56.768  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_2_piece0 in memory on host.docker.internal:61449 (size: 5.4 KiB, free: 892.5 MiB)
2022-08-02 14:44:56.769  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 2 from broadcast at DAGScheduler.scala:1478
2022-08-02 14:44:56.770  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[40] at count at Application.java:164) (first 15 tasks are for partitions Vector(0))
2022-08-02 14:44:56.770  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 4.0 with 1 tasks resource profile 0
2022-08-02 14:44:56.771  INFO   57 --- [er-event-loop-1] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 4.0 (TID 2) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-08-02 14:44:56.772  INFO   57 --- [age 4.0 (TID 2)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 4.0 (TID 2)
2022-08-02 14:44:56.777  INFO   57 --- [age 4.0 (TID 2)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-08-02 14:44:56.778  INFO   57 --- [age 4.0 (TID 2)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-08-02 14:44:56.780  INFO   57 --- [age 4.0 (TID 2)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 4.0 (TID 2). 2598 bytes result sent to driver
2022-08-02 14:44:56.783  INFO   57 --- [result-getter-1] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 4.0 (TID 2) in 12 ms on host.docker.internal (executor driver) (1/1)
2022-08-02 14:44:56.784  INFO   57 --- [result-getter-1] org.apache.spark.internal.Logging        : Removed TaskSet 4.0, whose tasks have all completed, from pool 
2022-08-02 14:44:56.786  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 4 (count at Application.java:164) finished in 0.026 s
2022-08-02 14:44:56.787  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
2022-08-02 14:44:56.787  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 4: Stage finished
2022-08-02 14:44:56.788  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 2 finished: count at Application.java:164, took 0.033431 s
2022-08-02 14:44:56.790  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659447887000 ms.0 from job set of time 1659447887000 ms
2022-08-02 14:44:56.791  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 9.790 s for time 1659447887000 ms (execution: 0.272 s)
2022-08-02 14:44:56.792  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659447888000 ms.0 from job set of time 1659447888000 ms
2022-08-02 14:44:56.793  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 2 from persistence list
2022-08-02 14:44:56.794  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-08-02 14:44:56.795  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-08-02 14:44:56.803  INFO   57 --- [c-thread-pool-6] org.apache.spark.internal.Logging        : Removing RDD 2
2022-08-02 14:44:56.804  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 1 from persistence list
2022-08-02 14:44:56.810  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[1] at receiverStream at Application.java:127 of time 1659447887000 ms
2022-08-02 14:44:56.811  INFO   57 --- [c-thread-pool-9] org.apache.spark.internal.Logging        : Removing RDD 1
2022-08-02 14:44:56.815  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 
2022-08-02 14:44:56.816  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 
2022-08-02 14:44:56.945  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:164
2022-08-02 14:44:56.948  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 46 (count at Application.java:164) as input to shuffle 2
2022-08-02 14:44:56.952  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 3 (count at Application.java:164) with 1 output partitions
2022-08-02 14:44:56.952  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 6 (count at Application.java:164)
2022-08-02 14:44:56.952  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 5)
2022-08-02 14:44:56.952  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-08-02 14:44:56.954  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 6 (MapPartitionsRDD[49] at count at Application.java:164), which has no missing parents
2022-08-02 14:44:56.969  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_3 stored as values in memory (estimated size 11.0 KiB, free 892.4 MiB)
2022-08-02 14:44:56.999  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_3_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 892.4 MiB)
2022-08-02 14:44:57.000  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_3_piece0 in memory on host.docker.internal:61449 (size: 5.4 KiB, free: 892.5 MiB)
2022-08-02 14:44:57.002  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 3 from broadcast at DAGScheduler.scala:1478
2022-08-02 14:44:57.003  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[49] at count at Application.java:164) (first 15 tasks are for partitions Vector(0))
2022-08-02 14:44:57.003  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 6.0 with 1 tasks resource profile 0
2022-08-02 14:44:57.007  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659447897000 ms
2022-08-02 14:44:57.010  INFO   57 --- [er-event-loop-0] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 6.0 (TID 3) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-08-02 14:44:57.011  INFO   57 --- [age 6.0 (TID 3)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 6.0 (TID 3)
2022-08-02 14:44:57.021  INFO   57 --- [age 6.0 (TID 3)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-08-02 14:44:57.021  INFO   57 --- [age 6.0 (TID 3)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 1 ms
2022-08-02 14:44:57.024  INFO   57 --- [age 6.0 (TID 3)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 6.0 (TID 3). 2555 bytes result sent to driver
2022-08-02 14:44:57.029  INFO   57 --- [result-getter-2] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 6.0 (TID 3) in 20 ms on host.docker.internal (executor driver) (1/1)
2022-08-02 14:44:57.030  INFO   57 --- [result-getter-2] org.apache.spark.internal.Logging        : Removed TaskSet 6.0, whose tasks have all completed, from pool 
2022-08-02 14:44:57.031  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 6 (count at Application.java:164) finished in 0.068 s
2022-08-02 14:44:57.032  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
2022-08-02 14:44:57.032  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 6: Stage finished
2022-08-02 14:44:57.036  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 3 finished: count at Application.java:164, took 0.090003 s
2022-08-02 14:44:57.040  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659447888000 ms.0 from job set of time 1659447888000 ms
2022-08-02 14:44:57.041  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 9.040 s for time 1659447888000 ms (execution: 0.248 s)
2022-08-02 14:44:57.041  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659447889000 ms.0 from job set of time 1659447889000 ms
2022-08-02 14:44:57.043  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 6 from persistence list
2022-08-02 14:44:57.041  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-08-02 14:44:57.044  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-08-02 14:44:57.045  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 5 from persistence list
2022-08-02 14:44:57.054  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[5] at receiverStream at Application.java:127 of time 1659447888000 ms
2022-08-02 14:44:57.055  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659447886000 ms
2022-08-02 14:44:57.055  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659447886000 ms
2022-08-02 14:44:57.057  INFO   57 --- [-thread-pool-12] org.apache.spark.internal.Logging        : Removing RDD 6
2022-08-02 14:44:57.058  INFO   57 --- [-thread-pool-13] org.apache.spark.internal.Logging        : Removing RDD 5
2022-08-02 14:44:57.178  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:164
2022-08-02 14:44:57.180  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 57 (count at Application.java:164) as input to shuffle 3
2022-08-02 14:44:57.180  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 4 (count at Application.java:164) with 1 output partitions
2022-08-02 14:44:57.180  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 8 (count at Application.java:164)
2022-08-02 14:44:57.181  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 7)
2022-08-02 14:44:57.181  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-08-02 14:44:57.182  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 8 (MapPartitionsRDD[60] at count at Application.java:164), which has no missing parents
2022-08-02 14:44:57.186  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_4 stored as values in memory (estimated size 11.0 KiB, free 892.3 MiB)
2022-08-02 14:44:57.189  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_4_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 892.3 MiB)
2022-08-02 14:44:57.191  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_4_piece0 in memory on host.docker.internal:61449 (size: 5.4 KiB, free: 892.5 MiB)
2022-08-02 14:44:57.191  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 4 from broadcast at DAGScheduler.scala:1478
2022-08-02 14:44:57.192  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[60] at count at Application.java:164) (first 15 tasks are for partitions Vector(0))
2022-08-02 14:44:57.192  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 8.0 with 1 tasks resource profile 0
2022-08-02 14:44:57.194  INFO   57 --- [er-event-loop-3] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 8.0 (TID 4) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-08-02 14:44:57.195  INFO   57 --- [age 8.0 (TID 4)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 8.0 (TID 4)
2022-08-02 14:44:57.205  INFO   57 --- [age 8.0 (TID 4)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-08-02 14:44:57.206  INFO   57 --- [age 8.0 (TID 4)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 1 ms
2022-08-02 14:44:57.208  INFO   57 --- [age 8.0 (TID 4)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 8.0 (TID 4). 2598 bytes result sent to driver
2022-08-02 14:44:57.214  INFO   57 --- [result-getter-3] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 8.0 (TID 4) in 21 ms on host.docker.internal (executor driver) (1/1)
2022-08-02 14:44:57.215  INFO   57 --- [result-getter-3] org.apache.spark.internal.Logging        : Removed TaskSet 8.0, whose tasks have all completed, from pool 
2022-08-02 14:44:57.218  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 8 (count at Application.java:164) finished in 0.034 s
2022-08-02 14:44:57.220  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
2022-08-02 14:44:57.220  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 8: Stage finished
2022-08-02 14:44:57.221  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 4 finished: count at Application.java:164, took 0.042186 s
2022-08-02 14:44:57.224  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659447889000 ms.0 from job set of time 1659447889000 ms
2022-08-02 14:44:57.225  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 8.224 s for time 1659447889000 ms (execution: 0.183 s)
2022-08-02 14:44:57.228  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659447890000 ms.0 from job set of time 1659447890000 ms
2022-08-02 14:44:57.228  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-08-02 14:44:57.228  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-08-02 14:44:57.227  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 8 from persistence list
2022-08-02 14:44:57.230  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 7 from persistence list
2022-08-02 14:44:57.230  INFO   57 --- [-thread-pool-18] org.apache.spark.internal.Logging        : Removing RDD 8
2022-08-02 14:44:57.232  INFO   57 --- [-thread-pool-19] org.apache.spark.internal.Logging        : Removing RDD 7
2022-08-02 14:44:57.231  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[7] at receiverStream at Application.java:127 of time 1659447889000 ms
2022-08-02 14:44:57.236  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659447887000 ms
2022-08-02 14:44:57.236  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659447887000 ms
2022-08-02 14:44:57.315  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: show at Application.java:161
2022-08-02 14:44:57.317  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 5 (show at Application.java:161) with 1 output partitions
2022-08-02 14:44:57.317  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 9 (show at Application.java:161)
2022-08-02 14:44:57.317  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List()
2022-08-02 14:44:57.318  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-08-02 14:44:57.319  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 9 (MapPartitionsRDD[64] at show at Application.java:161), which has no missing parents
2022-08-02 14:44:57.336  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_5 stored as values in memory (estimated size 13.4 KiB, free 892.3 MiB)
2022-08-02 14:44:57.340  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_5_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 892.3 MiB)
2022-08-02 14:44:57.341  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_5_piece0 in memory on host.docker.internal:61449 (size: 6.0 KiB, free: 892.5 MiB)
2022-08-02 14:44:57.342  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 5 from broadcast at DAGScheduler.scala:1478
2022-08-02 14:44:57.343  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[64] at show at Application.java:161) (first 15 tasks are for partitions Vector(0))
2022-08-02 14:44:57.343  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 9.0 with 1 tasks resource profile 0
2022-08-02 14:44:57.346  INFO   57 --- [er-event-loop-2] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 9.0 (TID 5) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
2022-08-02 14:44:57.347  INFO   57 --- [age 9.0 (TID 5)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 9.0 (TID 5)
2022-08-02 14:44:57.376  INFO   57 --- [age 9.0 (TID 5)] org.apache.spark.internal.Logging        : Found block input-0-1659447887266 locally
2022-08-02 14:44:57.861  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_3_piece0 on host.docker.internal:61449 in memory (size: 5.4 KiB, free: 892.5 MiB)
2022-08-02 14:44:57.878  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_2_piece0 on host.docker.internal:61449 in memory (size: 5.4 KiB, free: 892.5 MiB)
2022-08-02 14:44:57.910  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_4_piece0 on host.docker.internal:61449 in memory (size: 5.4 KiB, free: 892.5 MiB)
2022-08-02 14:44:58.004  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659447898000 ms
2022-08-02 14:44:58.111  INFO   57 --- [age 9.0 (TID 5)] org.apache.spark.internal.Logging        : 1 block locks were not released by task 0.0 in stage 9.0 (TID 5)
[input-0-1659447887266]
2022-08-02 14:44:58.112  INFO   57 --- [age 9.0 (TID 5)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 9.0 (TID 5). 2885 bytes result sent to driver
2022-08-02 14:44:58.113  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 9.0 (TID 5) in 769 ms on host.docker.internal (executor driver) (1/1)
2022-08-02 14:44:58.114  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Removed TaskSet 9.0, whose tasks have all completed, from pool 
2022-08-02 14:44:58.115  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 9 (show at Application.java:161) finished in 0.790 s
2022-08-02 14:44:58.115  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
2022-08-02 14:44:58.116  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 9: Stage finished
2022-08-02 14:44:58.116  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 5 finished: show at Application.java:161, took 0.801056 s
2022-08-02 14:44:58.196  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Code generated in 30.2258 ms
2022-08-02 14:44:58.261  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 68 (count at Application.java:164) as input to shuffle 4
2022-08-02 14:44:58.262  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got map stage job 6 (count at Application.java:164) with 1 output partitions
2022-08-02 14:44:58.263  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ShuffleMapStage 10 (count at Application.java:164)
2022-08-02 14:44:58.263  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List()
2022-08-02 14:44:58.264  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-08-02 14:44:58.267  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ShuffleMapStage 10 (MapPartitionsRDD[68] at count at Application.java:164), which has no missing parents
2022-08-02 14:44:58.281  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_6 stored as values in memory (estimated size 13.7 KiB, free 892.4 MiB)
2022-08-02 14:44:58.284  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_6_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 892.4 MiB)
2022-08-02 14:44:58.285  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_6_piece0 in memory on host.docker.internal:61449 (size: 6.7 KiB, free: 892.5 MiB)
2022-08-02 14:44:58.286  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 6 from broadcast at DAGScheduler.scala:1478
2022-08-02 14:44:58.287  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[68] at count at Application.java:164) (first 15 tasks are for partitions Vector(0))
2022-08-02 14:44:58.288  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 10.0 with 1 tasks resource profile 0
2022-08-02 14:44:58.290  INFO   57 --- [er-event-loop-3] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 10.0 (TID 6) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4383 bytes) taskResourceAssignments Map()
2022-08-02 14:44:58.291  INFO   57 --- [ge 10.0 (TID 6)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 10.0 (TID 6)
2022-08-02 14:44:58.307  INFO   57 --- [ge 10.0 (TID 6)] org.apache.spark.internal.Logging        : Found block input-0-1659447887266 locally
2022-08-02 14:44:58.370  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_5_piece0 on host.docker.internal:61449 in memory (size: 6.0 KiB, free: 892.5 MiB)
2022-08-02 14:44:58.708  INFO   57 --- [ge 10.0 (TID 6)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 10.0 (TID 6). 1881 bytes result sent to driver
2022-08-02 14:44:58.710  INFO   57 --- [result-getter-1] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 10.0 (TID 6) in 421 ms on host.docker.internal (executor driver) (1/1)
2022-08-02 14:44:58.710  INFO   57 --- [result-getter-1] org.apache.spark.internal.Logging        : Removed TaskSet 10.0, whose tasks have all completed, from pool 
2022-08-02 14:44:58.713  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ShuffleMapStage 10 (count at Application.java:164) finished in 0.440 s
2022-08-02 14:44:58.713  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : looking for newly runnable stages
2022-08-02 14:44:58.714  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : running: Set(ResultStage 0)
2022-08-02 14:44:58.715  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : waiting: Set()
2022-08-02 14:44:58.716  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : failed: Set()
2022-08-02 14:44:58.749  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:164
2022-08-02 14:44:58.751  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 7 (count at Application.java:164) with 1 output partitions
2022-08-02 14:44:58.751  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 12 (count at Application.java:164)
2022-08-02 14:44:58.752  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 11)
2022-08-02 14:44:58.752  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-08-02 14:44:58.753  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 12 (MapPartitionsRDD[71] at count at Application.java:164), which has no missing parents
2022-08-02 14:44:58.761  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_7 stored as values in memory (estimated size 11.0 KiB, free 892.4 MiB)
2022-08-02 14:44:58.764  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_7_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 892.4 MiB)
2022-08-02 14:44:58.767  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_7_piece0 in memory on host.docker.internal:61449 (size: 5.5 KiB, free: 892.5 MiB)
2022-08-02 14:44:58.768  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 7 from broadcast at DAGScheduler.scala:1478
2022-08-02 14:44:58.769  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[71] at count at Application.java:164) (first 15 tasks are for partitions Vector(0))
2022-08-02 14:44:58.769  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 12.0 with 1 tasks resource profile 0
2022-08-02 14:44:58.786  INFO   57 --- [er-event-loop-2] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 12.0 (TID 7) (host.docker.internal, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-08-02 14:44:58.788  INFO   57 --- [ge 12.0 (TID 7)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 12.0 (TID 7)
2022-08-02 14:44:58.793  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_6_piece0 on host.docker.internal:61449 in memory (size: 6.7 KiB, free: 892.5 MiB)
2022-08-02 14:44:58.798  INFO   57 --- [ge 12.0 (TID 7)] org.apache.spark.internal.Logging        : Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-08-02 14:44:58.799  INFO   57 --- [ge 12.0 (TID 7)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 4 ms
2022-08-02 14:44:58.821  INFO   57 --- [ge 12.0 (TID 7)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 12.0 (TID 7). 2605 bytes result sent to driver
2022-08-02 14:44:58.822  INFO   57 --- [result-getter-2] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 12.0 (TID 7) in 36 ms on host.docker.internal (executor driver) (1/1)
2022-08-02 14:44:58.822  INFO   57 --- [result-getter-2] org.apache.spark.internal.Logging        : Removed TaskSet 12.0, whose tasks have all completed, from pool 
2022-08-02 14:44:58.823  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 12 (count at Application.java:164) finished in 0.064 s
2022-08-02 14:44:58.823  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
2022-08-02 14:44:58.823  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 12: Stage finished
2022-08-02 14:44:58.824  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 7 finished: count at Application.java:164, took 0.074674 s
2022-08-02 14:44:59.005  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659447899000 ms
2022-08-02 14:44:59.108  INFO  142 --- [-job-executor-0] mapreduce.lib.output.FileOutputCommitter : File Output Committer Algorithm version is 1
2022-08-02 14:44:59.109  INFO  157 --- [-job-executor-0] mapreduce.lib.output.FileOutputCommitter : FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2022-08-02 14:44:59.111  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2022-08-02 14:44:59.147  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Code generated in 25.8998 ms
2022-08-02 14:44:59.217  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: csv at Application.java:165
2022-08-02 14:44:59.219  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 8 (csv at Application.java:165) with 1 output partitions
2022-08-02 14:44:59.219  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 13 (csv at Application.java:165)
2022-08-02 14:44:59.219  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List()
2022-08-02 14:44:59.219  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-08-02 14:44:59.221  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 13 (MapPartitionsRDD[74] at csv at Application.java:165), which has no missing parents
2022-08-02 14:44:59.276  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_8 stored as values in memory (estimated size 207.0 KiB, free 892.2 MiB)
2022-08-02 14:44:59.280  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_8_piece0 stored as bytes in memory (estimated size 73.9 KiB, free 892.1 MiB)
2022-08-02 14:44:59.285  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_8_piece0 in memory on host.docker.internal:61449 (size: 73.9 KiB, free: 892.4 MiB)
2022-08-02 14:44:59.288  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 8 from broadcast at DAGScheduler.scala:1478
2022-08-02 14:44:59.289  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[74] at csv at Application.java:165) (first 15 tasks are for partitions Vector(0))
2022-08-02 14:44:59.289  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 13.0 with 1 tasks resource profile 0
2022-08-02 14:44:59.293  INFO   57 --- [er-event-loop-1] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 13.0 (TID 8) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
2022-08-02 14:44:59.294  INFO   57 --- [ge 13.0 (TID 8)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 13.0 (TID 8)
2022-08-02 14:44:59.342  INFO   57 --- [ge 13.0 (TID 8)] org.apache.spark.internal.Logging        : Found block input-0-1659447887266 locally
2022-08-02 14:44:59.346  INFO  142 --- [ge 13.0 (TID 8)] mapreduce.lib.output.FileOutputCommitter : File Output Committer Algorithm version is 1
2022-08-02 14:44:59.346  INFO  157 --- [ge 13.0 (TID 8)] mapreduce.lib.output.FileOutputCommitter : FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2022-08-02 14:44:59.347  INFO   57 --- [ge 13.0 (TID 8)] org.apache.spark.internal.Logging        : Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2022-08-02 14:44:59.757  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_7_piece0 on host.docker.internal:61449 in memory (size: 5.5 KiB, free: 892.4 MiB)
2022-08-02 14:44:59.979  INFO  604 --- [ge 13.0 (TID 8)] mapreduce.lib.output.FileOutputCommitter : Saved output of task 'attempt_202208021444591813202705876609762_0013_m_000000_8' to file:/C:/IntelliJOutput/StreamingOut/_temporary/0/task_202208021444591813202705876609762_0013_m_000000
2022-08-02 14:44:59.980  INFO   57 --- [ge 13.0 (TID 8)] org.apache.spark.internal.Logging        : attempt_202208021444591813202705876609762_0013_m_000000_8: Committed
2022-08-02 14:44:59.990  INFO   57 --- [ge 13.0 (TID 8)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 13.0 (TID 8). 2515 bytes result sent to driver
2022-08-02 14:44:59.992  INFO   57 --- [result-getter-3] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 13.0 (TID 8) in 701 ms on host.docker.internal (executor driver) (1/1)
2022-08-02 14:44:59.993  INFO   57 --- [result-getter-3] org.apache.spark.internal.Logging        : Removed TaskSet 13.0, whose tasks have all completed, from pool 
2022-08-02 14:44:59.995  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 13 (csv at Application.java:165) finished in 0.772 s
2022-08-02 14:44:59.996  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
2022-08-02 14:44:59.996  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 13: Stage finished
2022-08-02 14:45:00.002  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 8 finished: csv at Application.java:165, took 0.784329 s
2022-08-02 14:45:00.004  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Start to commit write Job 411a2040-ba14-4b48-bacf-882ad1d285f1.
2022-08-02 14:45:00.011  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659447900000 ms
2022-08-02 14:45:00.115  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Write Job 411a2040-ba14-4b48-bacf-882ad1d285f1 committed. Elapsed time: 109 ms.
2022-08-02 14:45:00.157  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Finished processing stats for write job 411a2040-ba14-4b48-bacf-882ad1d285f1.
2022-08-02 14:45:00.163  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659447890000 ms.0 from job set of time 1659447890000 ms
2022-08-02 14:45:00.163  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 10.163 s for time 1659447890000 ms (execution: 2.936 s)
2022-08-02 14:45:00.164  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659447891000 ms.0 from job set of time 1659447891000 ms
2022-08-02 14:45:00.164  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 10 from persistence list
2022-08-02 14:45:00.167  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 9 from persistence list
2022-08-02 14:45:00.168  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-08-02 14:45:00.169  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-08-02 14:45:00.169  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[9] at receiverStream at Application.java:127 of time 1659447890000 ms
2022-08-02 14:45:00.170  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659447888000 ms
2022-08-02 14:45:00.170  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659447888000 ms
2022-08-02 14:45:00.171  INFO   57 --- [-thread-pool-54] org.apache.spark.internal.Logging        : Removing RDD 10
2022-08-02 14:45:00.171  INFO   57 --- [-thread-pool-55] org.apache.spark.internal.Logging        : Removing RDD 9
2022-08-02 14:45:00.382  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:164
2022-08-02 14:45:00.385  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 82 (count at Application.java:164) as input to shuffle 5
2022-08-02 14:45:00.386  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 9 (count at Application.java:164) with 1 output partitions
2022-08-02 14:45:00.386  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 15 (count at Application.java:164)
2022-08-02 14:45:00.386  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 14)
2022-08-02 14:45:00.387  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-08-02 14:45:00.388  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 15 (MapPartitionsRDD[85] at count at Application.java:164), which has no missing parents
2022-08-02 14:45:00.392  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_9 stored as values in memory (estimated size 11.0 KiB, free 892.1 MiB)
2022-08-02 14:45:00.394  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_9_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 892.1 MiB)
2022-08-02 14:45:00.395  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_9_piece0 in memory on host.docker.internal:61449 (size: 5.4 KiB, free: 892.4 MiB)
2022-08-02 14:45:00.396  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 9 from broadcast at DAGScheduler.scala:1478
2022-08-02 14:45:00.396  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[85] at count at Application.java:164) (first 15 tasks are for partitions Vector(0))
2022-08-02 14:45:00.397  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 15.0 with 1 tasks resource profile 0
2022-08-02 14:45:00.398  INFO   57 --- [er-event-loop-1] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 15.0 (TID 9) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-08-02 14:45:00.399  INFO   57 --- [ge 15.0 (TID 9)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 15.0 (TID 9)
2022-08-02 14:45:00.403  INFO   57 --- [ge 15.0 (TID 9)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-08-02 14:45:00.404  INFO   57 --- [ge 15.0 (TID 9)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 1 ms
2022-08-02 14:45:00.410  INFO   57 --- [ge 15.0 (TID 9)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 15.0 (TID 9). 2598 bytes result sent to driver
2022-08-02 14:45:00.411  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 15.0 (TID 9) in 13 ms on host.docker.internal (executor driver) (1/1)
2022-08-02 14:45:00.412  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Removed TaskSet 15.0, whose tasks have all completed, from pool 
2022-08-02 14:45:00.413  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 15 (count at Application.java:164) finished in 0.024 s
2022-08-02 14:45:00.414  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 9 is finished. Cancelling potential speculative or zombie tasks for this job
2022-08-02 14:45:00.415  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 15: Stage finished
2022-08-02 14:45:00.416  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 9 finished: count at Application.java:164, took 0.032946 s
2022-08-02 14:45:00.424  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-08-02 14:45:00.424  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-08-02 14:45:00.438  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659447891000 ms.0 from job set of time 1659447891000 ms
2022-08-02 14:45:00.438  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 9.438 s for time 1659447891000 ms (execution: 0.275 s)
2022-08-02 14:45:00.439  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659447892000 ms.0 from job set of time 1659447892000 ms
2022-08-02 14:45:00.440  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 12 from persistence list
2022-08-02 14:45:00.446  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 11 from persistence list
2022-08-02 14:45:00.467  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[11] at receiverStream at Application.java:127 of time 1659447891000 ms
2022-08-02 14:45:00.475  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659447889000 ms
2022-08-02 14:45:00.476  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659447889000 ms
2022-08-02 14:45:00.551  INFO   57 --- [-thread-pool-60] org.apache.spark.internal.Logging        : Removing RDD 12
2022-08-02 14:45:00.575  INFO   57 --- [-thread-pool-61] org.apache.spark.internal.Logging        : Removing RDD 11
2022-08-02 14:45:00.581  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed input-0-1659447887266 on host.docker.internal:61449 in memory (size: 5.1 MiB, free: 897.5 MiB)
2022-08-02 14:45:00.680  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:164
2022-08-02 14:45:00.682  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 91 (count at Application.java:164) as input to shuffle 6
2022-08-02 14:45:00.683  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 10 (count at Application.java:164) with 1 output partitions
2022-08-02 14:45:00.684  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 17 (count at Application.java:164)
2022-08-02 14:45:00.684  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 16)
2022-08-02 14:45:00.684  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-08-02 14:45:00.687  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 17 (MapPartitionsRDD[94] at count at Application.java:164), which has no missing parents
2022-08-02 14:45:00.692  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_10 stored as values in memory (estimated size 11.0 KiB, free 897.2 MiB)
2022-08-02 14:45:00.712  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_10_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.2 MiB)
2022-08-02 14:45:00.717  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_10_piece0 in memory on host.docker.internal:61449 (size: 5.4 KiB, free: 897.5 MiB)
2022-08-02 14:45:00.718  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 10 from broadcast at DAGScheduler.scala:1478
2022-08-02 14:45:00.718  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[94] at count at Application.java:164) (first 15 tasks are for partitions Vector(0))
2022-08-02 14:45:00.719  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 17.0 with 1 tasks resource profile 0
2022-08-02 14:45:00.720  INFO   57 --- [er-event-loop-0] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 17.0 (TID 10) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-08-02 14:45:00.721  INFO   57 --- [e 17.0 (TID 10)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 17.0 (TID 10)
2022-08-02 14:45:00.726  INFO   57 --- [e 17.0 (TID 10)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-08-02 14:45:00.726  INFO   57 --- [e 17.0 (TID 10)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-08-02 14:45:00.728  INFO   57 --- [e 17.0 (TID 10)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 17.0 (TID 10). 2555 bytes result sent to driver
2022-08-02 14:45:00.730  INFO   57 --- [result-getter-1] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 17.0 (TID 10) in 10 ms on host.docker.internal (executor driver) (1/1)
2022-08-02 14:45:00.730  INFO   57 --- [result-getter-1] org.apache.spark.internal.Logging        : Removed TaskSet 17.0, whose tasks have all completed, from pool 
2022-08-02 14:45:00.731  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 17 (count at Application.java:164) finished in 0.043 s
2022-08-02 14:45:00.732  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 10 is finished. Cancelling potential speculative or zombie tasks for this job
2022-08-02 14:45:00.732  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 17: Stage finished
2022-08-02 14:45:00.735  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 10 finished: count at Application.java:164, took 0.053984 s
2022-08-02 14:45:00.737  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659447892000 ms.0 from job set of time 1659447892000 ms
2022-08-02 14:45:00.737  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 8.737 s for time 1659447892000 ms (execution: 0.298 s)
2022-08-02 14:45:00.738  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659447893000 ms.0 from job set of time 1659447893000 ms
2022-08-02 14:45:00.739  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 14 from persistence list
2022-08-02 14:45:00.741  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-08-02 14:45:00.741  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-08-02 14:45:00.742  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 13 from persistence list
2022-08-02 14:45:00.746  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[13] at receiverStream at Application.java:127 of time 1659447892000 ms
2022-08-02 14:45:00.746  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659447890000 ms
2022-08-02 14:45:00.746  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659447890000 ms
2022-08-02 14:45:00.802  INFO   57 --- [-thread-pool-69] org.apache.spark.internal.Logging        : Removing RDD 14
2022-08-02 14:45:00.812  INFO   57 --- [-thread-pool-70] org.apache.spark.internal.Logging        : Removing RDD 13
2022-08-02 14:45:00.972  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:164
2022-08-02 14:45:00.974  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 100 (count at Application.java:164) as input to shuffle 7
2022-08-02 14:45:00.975  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 11 (count at Application.java:164) with 1 output partitions
2022-08-02 14:45:00.975  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 19 (count at Application.java:164)
2022-08-02 14:45:00.975  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 18)
2022-08-02 14:45:00.976  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-08-02 14:45:00.977  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 19 (MapPartitionsRDD[103] at count at Application.java:164), which has no missing parents
2022-08-02 14:45:00.980  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_11 stored as values in memory (estimated size 11.0 KiB, free 897.2 MiB)
2022-08-02 14:45:00.987  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_11_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.1 MiB)
2022-08-02 14:45:00.990  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_11_piece0 in memory on host.docker.internal:61449 (size: 5.4 KiB, free: 897.5 MiB)
2022-08-02 14:45:00.992  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 11 from broadcast at DAGScheduler.scala:1478
2022-08-02 14:45:00.993  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[103] at count at Application.java:164) (first 15 tasks are for partitions Vector(0))
2022-08-02 14:45:00.993  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 19.0 with 1 tasks resource profile 0
2022-08-02 14:45:00.995  INFO   57 --- [er-event-loop-3] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 19.0 (TID 11) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-08-02 14:45:00.997  INFO   57 --- [e 19.0 (TID 11)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 19.0 (TID 11)
2022-08-02 14:45:01.002  INFO   57 --- [e 19.0 (TID 11)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-08-02 14:45:01.003  INFO   57 --- [e 19.0 (TID 11)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 1 ms
2022-08-02 14:45:01.005  INFO   57 --- [e 19.0 (TID 11)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 19.0 (TID 11). 2555 bytes result sent to driver
2022-08-02 14:45:01.008  INFO   57 --- [result-getter-2] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 19.0 (TID 11) in 13 ms on host.docker.internal (executor driver) (1/1)
2022-08-02 14:45:01.008  INFO   57 --- [result-getter-2] org.apache.spark.internal.Logging        : Removed TaskSet 19.0, whose tasks have all completed, from pool 
2022-08-02 14:45:01.010  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 19 (count at Application.java:164) finished in 0.032 s
2022-08-02 14:45:01.011  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 11 is finished. Cancelling potential speculative or zombie tasks for this job
2022-08-02 14:45:01.011  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 19: Stage finished
2022-08-02 14:45:01.012  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 11 finished: count at Application.java:164, took 0.039343 s
2022-08-02 14:45:01.014  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659447893000 ms.0 from job set of time 1659447893000 ms
2022-08-02 14:45:01.014  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 8.014 s for time 1659447893000 ms (execution: 0.276 s)
2022-08-02 14:45:01.015  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659447894000 ms.0 from job set of time 1659447894000 ms
2022-08-02 14:45:01.016  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-08-02 14:45:01.017  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-08-02 14:45:01.018  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 16 from persistence list
2022-08-02 14:45:01.042  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 15 from persistence list
2022-08-02 14:45:01.062  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[15] at receiverStream at Application.java:127 of time 1659447893000 ms
2022-08-02 14:45:01.062  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659447891000 ms
2022-08-02 14:45:01.063  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659447891000 ms
2022-08-02 14:45:01.068  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659447901000 ms
2022-08-02 14:45:01.153  INFO   57 --- [-thread-pool-75] org.apache.spark.internal.Logging        : Removing RDD 16
2022-08-02 14:45:01.161  INFO   57 --- [-thread-pool-76] org.apache.spark.internal.Logging        : Removing RDD 15
2022-08-02 14:45:01.251  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:164
2022-08-02 14:45:01.255  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 111 (count at Application.java:164) as input to shuffle 8
2022-08-02 14:45:01.255  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 12 (count at Application.java:164) with 1 output partitions
2022-08-02 14:45:01.259  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 21 (count at Application.java:164)
2022-08-02 14:45:01.259  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 20)
2022-08-02 14:45:01.259  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-08-02 14:45:01.260  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 21 (MapPartitionsRDD[114] at count at Application.java:164), which has no missing parents
2022-08-02 14:45:01.264  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_12 stored as values in memory (estimated size 11.0 KiB, free 897.1 MiB)
2022-08-02 14:45:01.273  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_12_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.1 MiB)
2022-08-02 14:45:01.285  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_12_piece0 in memory on host.docker.internal:61449 (size: 5.4 KiB, free: 897.5 MiB)
2022-08-02 14:45:01.286  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 12 from broadcast at DAGScheduler.scala:1478
2022-08-02 14:45:01.287  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 21 (MapPartitionsRDD[114] at count at Application.java:164) (first 15 tasks are for partitions Vector(0))
2022-08-02 14:45:01.287  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 21.0 with 1 tasks resource profile 0
2022-08-02 14:45:01.293  INFO   57 --- [er-event-loop-2] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 21.0 (TID 12) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-08-02 14:45:01.294  INFO   57 --- [e 21.0 (TID 12)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 21.0 (TID 12)
2022-08-02 14:45:01.301  INFO   57 --- [e 21.0 (TID 12)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-08-02 14:45:01.302  INFO   57 --- [e 21.0 (TID 12)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 1 ms
2022-08-02 14:45:01.309  INFO   57 --- [e 21.0 (TID 12)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 21.0 (TID 12). 2555 bytes result sent to driver
2022-08-02 14:45:01.314  INFO   57 --- [result-getter-3] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 21.0 (TID 12) in 22 ms on host.docker.internal (executor driver) (1/1)
2022-08-02 14:45:01.315  INFO   57 --- [result-getter-3] org.apache.spark.internal.Logging        : Removed TaskSet 21.0, whose tasks have all completed, from pool 
2022-08-02 14:45:01.319  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 21 (count at Application.java:164) finished in 0.056 s
2022-08-02 14:45:01.319  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 12 is finished. Cancelling potential speculative or zombie tasks for this job
2022-08-02 14:45:01.319  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 21: Stage finished
2022-08-02 14:45:01.325  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 12 finished: count at Application.java:164, took 0.073113 s
2022-08-02 14:45:01.329  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659447894000 ms.0 from job set of time 1659447894000 ms
2022-08-02 14:45:01.330  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 7.329 s for time 1659447894000 ms (execution: 0.314 s)
2022-08-02 14:45:01.331  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659447895000 ms.0 from job set of time 1659447895000 ms
2022-08-02 14:45:01.334  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 18 from persistence list
2022-08-02 14:45:01.330  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-08-02 14:45:01.335  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-08-02 14:45:01.338  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 17 from persistence list
2022-08-02 14:45:01.370  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[17] at receiverStream at Application.java:127 of time 1659447894000 ms
2022-08-02 14:45:01.371  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659447892000 ms
2022-08-02 14:45:01.371  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659447892000 ms
2022-08-02 14:45:01.408  INFO   57 --- [-thread-pool-81] org.apache.spark.internal.Logging        : Removing RDD 18
2022-08-02 14:45:01.410  INFO   57 --- [-thread-pool-82] org.apache.spark.internal.Logging        : Removing RDD 17
2022-08-02 14:45:01.518  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:164
2022-08-02 14:45:01.519  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 120 (count at Application.java:164) as input to shuffle 9
2022-08-02 14:45:01.520  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 13 (count at Application.java:164) with 1 output partitions
2022-08-02 14:45:01.520  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 23 (count at Application.java:164)
2022-08-02 14:45:01.520  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 22)
2022-08-02 14:45:01.520  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-08-02 14:45:01.521  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 23 (MapPartitionsRDD[123] at count at Application.java:164), which has no missing parents
2022-08-02 14:45:01.527  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_13 stored as values in memory (estimated size 11.0 KiB, free 897.1 MiB)
2022-08-02 14:45:01.541  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_13_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.1 MiB)
2022-08-02 14:45:01.546  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_13_piece0 in memory on host.docker.internal:61449 (size: 5.4 KiB, free: 897.5 MiB)
2022-08-02 14:45:01.548  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 13 from broadcast at DAGScheduler.scala:1478
2022-08-02 14:45:01.548  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 23 (MapPartitionsRDD[123] at count at Application.java:164) (first 15 tasks are for partitions Vector(0))
2022-08-02 14:45:01.550  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 23.0 with 1 tasks resource profile 0
2022-08-02 14:45:01.552  INFO   57 --- [er-event-loop-1] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 23.0 (TID 13) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-08-02 14:45:01.553  INFO   57 --- [e 23.0 (TID 13)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 23.0 (TID 13)
2022-08-02 14:45:01.561  INFO   57 --- [e 23.0 (TID 13)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-08-02 14:45:01.562  INFO   57 --- [e 23.0 (TID 13)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 1 ms
2022-08-02 14:45:01.569  INFO   57 --- [e 23.0 (TID 13)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 23.0 (TID 13). 2555 bytes result sent to driver
2022-08-02 14:45:01.571  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 23.0 (TID 13) in 19 ms on host.docker.internal (executor driver) (1/1)
2022-08-02 14:45:01.571  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Removed TaskSet 23.0, whose tasks have all completed, from pool 
2022-08-02 14:45:01.576  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 23 (count at Application.java:164) finished in 0.053 s
2022-08-02 14:45:01.578  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 13 is finished. Cancelling potential speculative or zombie tasks for this job
2022-08-02 14:45:01.578  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 23: Stage finished
2022-08-02 14:45:01.579  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 13 finished: count at Application.java:164, took 0.060135 s
2022-08-02 14:45:01.580  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659447895000 ms.0 from job set of time 1659447895000 ms
2022-08-02 14:45:01.580  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 6.580 s for time 1659447895000 ms (execution: 0.249 s)
2022-08-02 14:45:01.581  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659447896000 ms.0 from job set of time 1659447896000 ms
2022-08-02 14:45:01.585  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-08-02 14:45:01.585  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 20 from persistence list
2022-08-02 14:45:01.585  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-08-02 14:45:01.604  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 19 from persistence list
2022-08-02 14:45:01.606  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[19] at receiverStream at Application.java:127 of time 1659447895000 ms
2022-08-02 14:45:01.607  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659447893000 ms
2022-08-02 14:45:01.608  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659447893000 ms
2022-08-02 14:45:01.631  INFO   57 --- [-thread-pool-87] org.apache.spark.internal.Logging        : Removing RDD 20
2022-08-02 14:45:01.634  INFO   57 --- [-thread-pool-88] org.apache.spark.internal.Logging        : Removing RDD 19
2022-08-02 14:45:01.740  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:164
2022-08-02 14:45:01.744  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 129 (count at Application.java:164) as input to shuffle 10
2022-08-02 14:45:01.745  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 14 (count at Application.java:164) with 1 output partitions
2022-08-02 14:45:01.745  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 25 (count at Application.java:164)
2022-08-02 14:45:01.745  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 24)
2022-08-02 14:45:01.746  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-08-02 14:45:01.746  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 25 (MapPartitionsRDD[132] at count at Application.java:164), which has no missing parents
2022-08-02 14:45:01.753  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_14 stored as values in memory (estimated size 11.0 KiB, free 897.1 MiB)
2022-08-02 14:45:01.758  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_14_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.1 MiB)
2022-08-02 14:45:01.760  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_14_piece0 in memory on host.docker.internal:61449 (size: 5.4 KiB, free: 897.5 MiB)
2022-08-02 14:45:01.761  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 14 from broadcast at DAGScheduler.scala:1478
2022-08-02 14:45:01.761  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 25 (MapPartitionsRDD[132] at count at Application.java:164) (first 15 tasks are for partitions Vector(0))
2022-08-02 14:45:01.762  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 25.0 with 1 tasks resource profile 0
2022-08-02 14:45:01.765  INFO   57 --- [er-event-loop-0] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 25.0 (TID 14) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-08-02 14:45:01.768  INFO   57 --- [e 25.0 (TID 14)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 25.0 (TID 14)
2022-08-02 14:45:01.777  INFO   57 --- [e 25.0 (TID 14)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-08-02 14:45:01.777  INFO   57 --- [e 25.0 (TID 14)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 1 ms
2022-08-02 14:45:01.780  INFO   57 --- [e 25.0 (TID 14)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 25.0 (TID 14). 2598 bytes result sent to driver
2022-08-02 14:45:01.781  INFO   57 --- [result-getter-1] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 25.0 (TID 14) in 16 ms on host.docker.internal (executor driver) (1/1)
2022-08-02 14:45:01.782  INFO   57 --- [result-getter-1] org.apache.spark.internal.Logging        : Removed TaskSet 25.0, whose tasks have all completed, from pool 
2022-08-02 14:45:01.785  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 25 (count at Application.java:164) finished in 0.038 s
2022-08-02 14:45:01.786  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 14 is finished. Cancelling potential speculative or zombie tasks for this job
2022-08-02 14:45:01.786  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 25: Stage finished
2022-08-02 14:45:01.787  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 14 finished: count at Application.java:164, took 0.045355 s
2022-08-02 14:45:01.798  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-08-02 14:45:01.799  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-08-02 14:45:01.811  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659447896000 ms.0 from job set of time 1659447896000 ms
2022-08-02 14:45:01.812  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 5.811 s for time 1659447896000 ms (execution: 0.230 s)
2022-08-02 14:45:01.812  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659447897000 ms.0 from job set of time 1659447897000 ms
2022-08-02 14:45:01.815  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 22 from persistence list
2022-08-02 14:45:01.827  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 21 from persistence list
2022-08-02 14:45:01.858  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[21] at receiverStream at Application.java:127 of time 1659447896000 ms
2022-08-02 14:45:01.859  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659447894000 ms
2022-08-02 14:45:01.859  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659447894000 ms
2022-08-02 14:45:01.913  INFO   57 --- [-thread-pool-93] org.apache.spark.internal.Logging        : Removing RDD 22
2022-08-02 14:45:01.915  INFO   57 --- [-thread-pool-94] org.apache.spark.internal.Logging        : Removing RDD 21
2022-08-02 14:45:01.997  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:164
2022-08-02 14:45:01.998  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 138 (count at Application.java:164) as input to shuffle 11
2022-08-02 14:45:01.999  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 15 (count at Application.java:164) with 1 output partitions
2022-08-02 14:45:02.000  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 27 (count at Application.java:164)
2022-08-02 14:45:02.000  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 26)
2022-08-02 14:45:02.000  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-08-02 14:45:02.001  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 27 (MapPartitionsRDD[141] at count at Application.java:164), which has no missing parents
2022-08-02 14:45:02.004  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_15 stored as values in memory (estimated size 11.0 KiB, free 897.1 MiB)
2022-08-02 14:45:02.004  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659447902000 ms
2022-08-02 14:45:02.007  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_15_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.1 MiB)
2022-08-02 14:45:02.008  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_15_piece0 in memory on host.docker.internal:61449 (size: 5.4 KiB, free: 897.5 MiB)
2022-08-02 14:45:02.010  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 15 from broadcast at DAGScheduler.scala:1478
2022-08-02 14:45:02.012  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 27 (MapPartitionsRDD[141] at count at Application.java:164) (first 15 tasks are for partitions Vector(0))
2022-08-02 14:45:02.013  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 27.0 with 1 tasks resource profile 0
2022-08-02 14:45:02.015  INFO   57 --- [er-event-loop-3] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 27.0 (TID 15) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-08-02 14:45:02.019  INFO   57 --- [e 27.0 (TID 15)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 27.0 (TID 15)
2022-08-02 14:45:02.024  INFO   57 --- [e 27.0 (TID 15)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-08-02 14:45:02.031  INFO   57 --- [e 27.0 (TID 15)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 7 ms
2022-08-02 14:45:02.036  INFO   57 --- [e 27.0 (TID 15)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 27.0 (TID 15). 2555 bytes result sent to driver
2022-08-02 14:45:02.038  INFO   57 --- [result-getter-2] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 27.0 (TID 15) in 23 ms on host.docker.internal (executor driver) (1/1)
2022-08-02 14:45:02.038  INFO   57 --- [result-getter-2] org.apache.spark.internal.Logging        : Removed TaskSet 27.0, whose tasks have all completed, from pool 
2022-08-02 14:45:02.039  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 27 (count at Application.java:164) finished in 0.036 s
2022-08-02 14:45:02.039  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 15 is finished. Cancelling potential speculative or zombie tasks for this job
2022-08-02 14:45:02.039  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 27: Stage finished
2022-08-02 14:45:02.040  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 15 finished: count at Application.java:164, took 0.043477 s
2022-08-02 14:45:02.050  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659447897000 ms.0 from job set of time 1659447897000 ms
2022-08-02 14:45:02.051  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-08-02 14:45:02.051  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-08-02 14:45:02.053  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 26 from persistence list
2022-08-02 14:45:02.051  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 5.050 s for time 1659447897000 ms (execution: 0.238 s)
2022-08-02 14:45:02.055  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659447898000 ms.0 from job set of time 1659447898000 ms
2022-08-02 14:45:02.056  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 25 from persistence list
2022-08-02 14:45:02.060  INFO   57 --- [c-thread-pool-0] org.apache.spark.internal.Logging        : Removing RDD 25
2022-08-02 14:45:02.060  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[25] at receiverStream at Application.java:127 of time 1659447897000 ms
2022-08-02 14:45:02.061  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659447895000 ms
2022-08-02 14:45:02.062  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659447895000 ms
2022-08-02 14:45:02.063  INFO   57 --- [-thread-pool-99] org.apache.spark.internal.Logging        : Removing RDD 26
2022-08-02 14:45:02.159  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:164
2022-08-02 14:45:02.161  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 149 (count at Application.java:164) as input to shuffle 12
2022-08-02 14:45:02.162  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 16 (count at Application.java:164) with 1 output partitions
2022-08-02 14:45:02.162  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 29 (count at Application.java:164)
2022-08-02 14:45:02.162  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 28)
2022-08-02 14:45:02.163  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-08-02 14:45:02.164  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 29 (MapPartitionsRDD[152] at count at Application.java:164), which has no missing parents
2022-08-02 14:45:02.168  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_16 stored as values in memory (estimated size 11.0 KiB, free 897.1 MiB)
2022-08-02 14:45:02.175  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_16_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.1 MiB)
2022-08-02 14:45:02.176  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_16_piece0 in memory on host.docker.internal:61449 (size: 5.4 KiB, free: 897.5 MiB)
2022-08-02 14:45:02.177  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 16 from broadcast at DAGScheduler.scala:1478
2022-08-02 14:45:02.178  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 29 (MapPartitionsRDD[152] at count at Application.java:164) (first 15 tasks are for partitions Vector(0))
2022-08-02 14:45:02.178  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 29.0 with 1 tasks resource profile 0
2022-08-02 14:45:02.179  INFO   57 --- [er-event-loop-2] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 29.0 (TID 16) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-08-02 14:45:02.181  INFO   57 --- [e 29.0 (TID 16)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 29.0 (TID 16)
2022-08-02 14:45:02.187  INFO   57 --- [e 29.0 (TID 16)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-08-02 14:45:02.187  INFO   57 --- [e 29.0 (TID 16)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 1 ms
2022-08-02 14:45:02.189  INFO   57 --- [e 29.0 (TID 16)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 29.0 (TID 16). 2555 bytes result sent to driver
2022-08-02 14:45:02.192  INFO   57 --- [result-getter-3] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 29.0 (TID 16) in 13 ms on host.docker.internal (executor driver) (1/1)
2022-08-02 14:45:02.192  INFO   57 --- [result-getter-3] org.apache.spark.internal.Logging        : Removed TaskSet 29.0, whose tasks have all completed, from pool 
2022-08-02 14:45:02.193  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 29 (count at Application.java:164) finished in 0.027 s
2022-08-02 14:45:02.194  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 16 is finished. Cancelling potential speculative or zombie tasks for this job
2022-08-02 14:45:02.194  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 29: Stage finished
2022-08-02 14:45:02.197  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 16 finished: count at Application.java:164, took 0.036550 s
2022-08-02 14:45:02.206  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659447898000 ms.0 from job set of time 1659447898000 ms
2022-08-02 14:45:02.206  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 4.206 s for time 1659447898000 ms (execution: 0.151 s)
2022-08-02 14:45:02.207  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659447899000 ms.0 from job set of time 1659447899000 ms
2022-08-02 14:45:02.208  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-08-02 14:45:02.208  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-08-02 14:45:02.211  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 51 from persistence list
2022-08-02 14:45:02.211  INFO   57 --- [c-thread-pool-5] org.apache.spark.internal.Logging        : Removing RDD 51
2022-08-02 14:45:02.212  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 50 from persistence list
2022-08-02 14:45:02.214  INFO   57 --- [c-thread-pool-8] org.apache.spark.internal.Logging        : Removing RDD 50
2022-08-02 14:45:02.215  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[50] at receiverStream at Application.java:127 of time 1659447898000 ms
2022-08-02 14:45:02.216  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659447896000 ms
2022-08-02 14:45:02.217  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659447896000 ms
2022-08-02 14:45:02.354  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:164
2022-08-02 14:45:02.354  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 158 (count at Application.java:164) as input to shuffle 13
2022-08-02 14:45:02.355  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 17 (count at Application.java:164) with 1 output partitions
2022-08-02 14:45:02.355  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 31 (count at Application.java:164)
2022-08-02 14:45:02.355  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 30)
2022-08-02 14:45:02.356  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-08-02 14:45:02.356  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 31 (MapPartitionsRDD[161] at count at Application.java:164), which has no missing parents
2022-08-02 14:45:02.358  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_17 stored as values in memory (estimated size 11.0 KiB, free 897.1 MiB)
2022-08-02 14:45:02.362  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_17_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.1 MiB)
2022-08-02 14:45:02.363  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_17_piece0 in memory on host.docker.internal:61449 (size: 5.4 KiB, free: 897.4 MiB)
2022-08-02 14:45:02.364  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 17 from broadcast at DAGScheduler.scala:1478
2022-08-02 14:45:02.364  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 31 (MapPartitionsRDD[161] at count at Application.java:164) (first 15 tasks are for partitions Vector(0))
2022-08-02 14:45:02.364  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 31.0 with 1 tasks resource profile 0
2022-08-02 14:45:02.365  INFO   57 --- [er-event-loop-1] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 31.0 (TID 17) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-08-02 14:45:02.366  INFO   57 --- [e 31.0 (TID 17)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 31.0 (TID 17)
2022-08-02 14:45:02.370  INFO   57 --- [e 31.0 (TID 17)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-08-02 14:45:02.370  INFO   57 --- [e 31.0 (TID 17)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-08-02 14:45:02.371  INFO   57 --- [e 31.0 (TID 17)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 31.0 (TID 17). 2598 bytes result sent to driver
2022-08-02 14:45:02.372  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 31.0 (TID 17) in 7 ms on host.docker.internal (executor driver) (1/1)
2022-08-02 14:45:02.373  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Removed TaskSet 31.0, whose tasks have all completed, from pool 
2022-08-02 14:45:02.373  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 31 (count at Application.java:164) finished in 0.016 s
2022-08-02 14:45:02.374  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 17 is finished. Cancelling potential speculative or zombie tasks for this job
2022-08-02 14:45:02.374  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 31: Stage finished
2022-08-02 14:45:02.375  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 17 finished: count at Application.java:164, took 0.020700 s
2022-08-02 14:45:02.376  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659447899000 ms.0 from job set of time 1659447899000 ms
2022-08-02 14:45:02.377  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 3.376 s for time 1659447899000 ms (execution: 0.169 s)
2022-08-02 14:45:02.377  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659447900000 ms.0 from job set of time 1659447900000 ms
2022-08-02 14:45:02.379  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 66 from persistence list
2022-08-02 14:45:02.379  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-08-02 14:45:02.380  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-08-02 14:45:02.382  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 65 from persistence list
2022-08-02 14:45:02.382  INFO   57 --- [-thread-pool-10] org.apache.spark.internal.Logging        : Removing RDD 66
2022-08-02 14:45:02.386  INFO   57 --- [-thread-pool-10] org.apache.spark.internal.Logging        : Removing RDD 65
2022-08-02 14:45:02.391  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[65] at receiverStream at Application.java:127 of time 1659447899000 ms
2022-08-02 14:45:02.392  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659447897000 ms
2022-08-02 14:45:02.392  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659447897000 ms
2022-08-02 14:45:02.581  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:164
2022-08-02 14:45:02.583  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 167 (count at Application.java:164) as input to shuffle 14
2022-08-02 14:45:02.584  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 18 (count at Application.java:164) with 1 output partitions
2022-08-02 14:45:02.585  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 33 (count at Application.java:164)
2022-08-02 14:45:02.585  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 32)
2022-08-02 14:45:02.586  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-08-02 14:45:02.587  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 33 (MapPartitionsRDD[170] at count at Application.java:164), which has no missing parents
2022-08-02 14:45:02.590  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_18 stored as values in memory (estimated size 11.0 KiB, free 897.0 MiB)
2022-08-02 14:45:02.601  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_18_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.0 MiB)
2022-08-02 14:45:02.602  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_18_piece0 in memory on host.docker.internal:61449 (size: 5.4 KiB, free: 897.4 MiB)
2022-08-02 14:45:02.603  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 18 from broadcast at DAGScheduler.scala:1478
2022-08-02 14:45:02.608  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 33 (MapPartitionsRDD[170] at count at Application.java:164) (first 15 tasks are for partitions Vector(0))
2022-08-02 14:45:02.608  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 33.0 with 1 tasks resource profile 0
2022-08-02 14:45:02.610  INFO   57 --- [er-event-loop-0] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 33.0 (TID 18) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-08-02 14:45:02.612  INFO   57 --- [e 33.0 (TID 18)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 33.0 (TID 18)
2022-08-02 14:45:02.619  INFO   57 --- [e 33.0 (TID 18)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-08-02 14:45:02.619  INFO   57 --- [e 33.0 (TID 18)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-08-02 14:45:02.622  INFO   57 --- [e 33.0 (TID 18)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 33.0 (TID 18). 2598 bytes result sent to driver
2022-08-02 14:45:02.625  INFO   57 --- [result-getter-1] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 33.0 (TID 18) in 15 ms on host.docker.internal (executor driver) (1/1)
2022-08-02 14:45:02.626  INFO   57 --- [result-getter-1] org.apache.spark.internal.Logging        : Removed TaskSet 33.0, whose tasks have all completed, from pool 
2022-08-02 14:45:02.626  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 33 (count at Application.java:164) finished in 0.038 s
2022-08-02 14:45:02.628  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 18 is finished. Cancelling potential speculative or zombie tasks for this job
2022-08-02 14:45:02.628  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 33: Stage finished
2022-08-02 14:45:02.631  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 18 finished: count at Application.java:164, took 0.049019 s
2022-08-02 14:45:02.633  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659447900000 ms.0 from job set of time 1659447900000 ms
2022-08-02 14:45:02.634  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 2.633 s for time 1659447900000 ms (execution: 0.256 s)
2022-08-02 14:45:02.634  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659447901000 ms.0 from job set of time 1659447901000 ms
2022-08-02 14:45:02.639  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-08-02 14:45:02.639  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-08-02 14:45:02.640  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 73 from persistence list
2022-08-02 14:45:02.646  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 72 from persistence list
2022-08-02 14:45:02.650  INFO   57 --- [-thread-pool-17] org.apache.spark.internal.Logging        : Removing RDD 73
2022-08-02 14:45:02.654  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[72] at receiverStream at Application.java:127 of time 1659447900000 ms
2022-08-02 14:45:02.655  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659447898000 ms
2022-08-02 14:45:02.684  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659447898000 ms
2022-08-02 14:45:02.685  INFO   57 --- [-thread-pool-21] org.apache.spark.internal.Logging        : Removing RDD 72
2022-08-02 14:45:02.800  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_9_piece0 on host.docker.internal:61449 in memory (size: 5.4 KiB, free: 897.4 MiB)
2022-08-02 14:45:02.821  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_18_piece0 on host.docker.internal:61449 in memory (size: 5.4 KiB, free: 897.5 MiB)
2022-08-02 14:45:02.838  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_8_piece0 on host.docker.internal:61449 in memory (size: 73.9 KiB, free: 897.5 MiB)
2022-08-02 14:45:02.845  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_15_piece0 on host.docker.internal:61449 in memory (size: 5.4 KiB, free: 897.5 MiB)
2022-08-02 14:45:02.848  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:164
2022-08-02 14:45:02.850  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 176 (count at Application.java:164) as input to shuffle 15
2022-08-02 14:45:02.851  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 19 (count at Application.java:164) with 1 output partitions
2022-08-02 14:45:02.851  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 35 (count at Application.java:164)
2022-08-02 14:45:02.851  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 34)
2022-08-02 14:45:02.851  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-08-02 14:45:02.852  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 35 (MapPartitionsRDD[179] at count at Application.java:164), which has no missing parents
2022-08-02 14:45:02.854  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_19 stored as values in memory (estimated size 11.0 KiB, free 897.3 MiB)
2022-08-02 14:45:02.861  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_19_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.4 MiB)
2022-08-02 14:45:02.862  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_14_piece0 on host.docker.internal:61449 in memory (size: 5.4 KiB, free: 897.5 MiB)
2022-08-02 14:45:02.864  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_19_piece0 in memory on host.docker.internal:61449 (size: 5.4 KiB, free: 897.5 MiB)
2022-08-02 14:45:02.865  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 19 from broadcast at DAGScheduler.scala:1478
2022-08-02 14:45:02.866  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 35 (MapPartitionsRDD[179] at count at Application.java:164) (first 15 tasks are for partitions Vector(0))
2022-08-02 14:45:02.866  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 35.0 with 1 tasks resource profile 0
2022-08-02 14:45:02.868  INFO   57 --- [er-event-loop-3] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 35.0 (TID 19) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-08-02 14:45:02.869  INFO   57 --- [e 35.0 (TID 19)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 35.0 (TID 19)
2022-08-02 14:45:02.872  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_17_piece0 on host.docker.internal:61449 in memory (size: 5.4 KiB, free: 897.5 MiB)
2022-08-02 14:45:02.876  INFO   57 --- [e 35.0 (TID 19)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-08-02 14:45:02.877  INFO   57 --- [e 35.0 (TID 19)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 1 ms
2022-08-02 14:45:02.879  INFO   57 --- [e 35.0 (TID 19)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 35.0 (TID 19). 2555 bytes result sent to driver
2022-08-02 14:45:02.880  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_13_piece0 on host.docker.internal:61449 in memory (size: 5.4 KiB, free: 897.5 MiB)
2022-08-02 14:45:02.881  INFO   57 --- [result-getter-2] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 35.0 (TID 19) in 13 ms on host.docker.internal (executor driver) (1/1)
2022-08-02 14:45:02.882  INFO   57 --- [result-getter-2] org.apache.spark.internal.Logging        : Removed TaskSet 35.0, whose tasks have all completed, from pool 
2022-08-02 14:45:02.883  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 35 (count at Application.java:164) finished in 0.030 s
2022-08-02 14:45:02.884  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 19 is finished. Cancelling potential speculative or zombie tasks for this job
2022-08-02 14:45:02.884  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 35: Stage finished
2022-08-02 14:45:02.885  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 19 finished: count at Application.java:164, took 0.036864 s
2022-08-02 14:45:02.889  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659447901000 ms.0 from job set of time 1659447901000 ms
2022-08-02 14:45:02.889  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 1.889 s for time 1659447901000 ms (execution: 0.255 s)
2022-08-02 14:45:02.890  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659447902000 ms.0 from job set of time 1659447902000 ms
2022-08-02 14:45:02.890  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_11_piece0 on host.docker.internal:61449 in memory (size: 5.4 KiB, free: 897.5 MiB)
2022-08-02 14:45:02.902  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 76 from persistence list
2022-08-02 14:45:02.890  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-08-02 14:45:02.903  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-08-02 14:45:02.910  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 75 from persistence list
2022-08-02 14:45:02.911  INFO   57 --- [-thread-pool-61] org.apache.spark.internal.Logging        : Removing RDD 76
2022-08-02 14:45:02.917  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[75] at receiverStream at Application.java:127 of time 1659447901000 ms
2022-08-02 14:45:02.917  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659447899000 ms
2022-08-02 14:45:02.917  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659447899000 ms
2022-08-02 14:45:02.918  INFO   57 --- [-thread-pool-63] org.apache.spark.internal.Logging        : Removing RDD 75
2022-08-02 14:45:02.960  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_16_piece0 on host.docker.internal:61449 in memory (size: 5.4 KiB, free: 897.6 MiB)
2022-08-02 14:45:03.019  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_10_piece0 on host.docker.internal:61449 in memory (size: 5.4 KiB, free: 897.6 MiB)
2022-08-02 14:45:03.048  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_12_piece0 on host.docker.internal:61449 in memory (size: 5.4 KiB, free: 897.6 MiB)
2022-08-02 14:45:03.054  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659447903000 ms
2022-08-02 14:45:03.094  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:164
2022-08-02 14:45:03.096  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 187 (count at Application.java:164) as input to shuffle 16
2022-08-02 14:45:03.097  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 20 (count at Application.java:164) with 1 output partitions
2022-08-02 14:45:03.097  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 37 (count at Application.java:164)
2022-08-02 14:45:03.097  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 36)
2022-08-02 14:45:03.097  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-08-02 14:45:03.100  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 37 (MapPartitionsRDD[190] at count at Application.java:164), which has no missing parents
2022-08-02 14:45:03.104  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_20 stored as values in memory (estimated size 11.0 KiB, free 897.4 MiB)
2022-08-02 14:45:03.107  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_20_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.4 MiB)
2022-08-02 14:45:03.109  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_20_piece0 in memory on host.docker.internal:61449 (size: 5.4 KiB, free: 897.6 MiB)
2022-08-02 14:45:03.109  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 20 from broadcast at DAGScheduler.scala:1478
2022-08-02 14:45:03.110  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 37 (MapPartitionsRDD[190] at count at Application.java:164) (first 15 tasks are for partitions Vector(0))
2022-08-02 14:45:03.110  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 37.0 with 1 tasks resource profile 0
2022-08-02 14:45:03.111  INFO   57 --- [er-event-loop-2] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 37.0 (TID 20) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-08-02 14:45:03.113  INFO   57 --- [e 37.0 (TID 20)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 37.0 (TID 20)
2022-08-02 14:45:03.135  INFO   57 --- [e 37.0 (TID 20)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-08-02 14:45:03.136  INFO   57 --- [e 37.0 (TID 20)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 1 ms
2022-08-02 14:45:03.138  INFO   57 --- [e 37.0 (TID 20)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 37.0 (TID 20). 2598 bytes result sent to driver
2022-08-02 14:45:03.154  INFO   57 --- [result-getter-3] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 37.0 (TID 20) in 43 ms on host.docker.internal (executor driver) (1/1)
2022-08-02 14:45:03.155  INFO   57 --- [result-getter-3] org.apache.spark.internal.Logging        : Removed TaskSet 37.0, whose tasks have all completed, from pool 
2022-08-02 14:45:03.158  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 37 (count at Application.java:164) finished in 0.055 s
2022-08-02 14:45:03.159  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 20 is finished. Cancelling potential speculative or zombie tasks for this job
2022-08-02 14:45:03.159  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 37: Stage finished
2022-08-02 14:45:03.173  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 20 finished: count at Application.java:164, took 0.077823 s
2022-08-02 14:45:03.186  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-08-02 14:45:03.187  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-08-02 14:45:03.189  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659447902000 ms.0 from job set of time 1659447902000 ms
2022-08-02 14:45:03.189  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 1.189 s for time 1659447902000 ms (execution: 0.299 s)
2022-08-02 14:45:03.190  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659447903000 ms.0 from job set of time 1659447903000 ms
2022-08-02 14:45:03.195  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 107 from persistence list
2022-08-02 14:45:03.219  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 106 from persistence list
2022-08-02 14:45:03.231  INFO   57 --- [-thread-pool-92] org.apache.spark.internal.Logging        : Removing RDD 107
2022-08-02 14:45:03.232  INFO   57 --- [-thread-pool-95] org.apache.spark.internal.Logging        : Removing RDD 106
2022-08-02 14:45:03.232  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[106] at receiverStream at Application.java:127 of time 1659447902000 ms
2022-08-02 14:45:03.235  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659447900000 ms
2022-08-02 14:45:03.235  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659447900000 ms
2022-08-02 14:45:03.360  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:164
2022-08-02 14:45:03.361  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 196 (count at Application.java:164) as input to shuffle 17
2022-08-02 14:45:03.362  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 21 (count at Application.java:164) with 1 output partitions
2022-08-02 14:45:03.362  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 39 (count at Application.java:164)
2022-08-02 14:45:03.363  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 38)
2022-08-02 14:45:03.363  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-08-02 14:45:03.364  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 39 (MapPartitionsRDD[199] at count at Application.java:164), which has no missing parents
2022-08-02 14:45:03.371  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_21 stored as values in memory (estimated size 11.0 KiB, free 897.4 MiB)
2022-08-02 14:45:03.373  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_21_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.4 MiB)
2022-08-02 14:45:03.375  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_21_piece0 in memory on host.docker.internal:61449 (size: 5.4 KiB, free: 897.6 MiB)
2022-08-02 14:45:03.376  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 21 from broadcast at DAGScheduler.scala:1478
2022-08-02 14:45:03.376  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 39 (MapPartitionsRDD[199] at count at Application.java:164) (first 15 tasks are for partitions Vector(0))
2022-08-02 14:45:03.377  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 39.0 with 1 tasks resource profile 0
2022-08-02 14:45:03.379  INFO   57 --- [er-event-loop-1] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 39.0 (TID 21) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-08-02 14:45:03.380  INFO   57 --- [e 39.0 (TID 21)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 39.0 (TID 21)
2022-08-02 14:45:03.396  INFO   57 --- [e 39.0 (TID 21)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-08-02 14:45:03.396  INFO   57 --- [e 39.0 (TID 21)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-08-02 14:45:03.407  INFO   57 --- [e 39.0 (TID 21)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 39.0 (TID 21). 2641 bytes result sent to driver
2022-08-02 14:45:03.409  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 39.0 (TID 21) in 31 ms on host.docker.internal (executor driver) (1/1)
2022-08-02 14:45:03.409  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Removed TaskSet 39.0, whose tasks have all completed, from pool 
2022-08-02 14:45:03.411  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 39 (count at Application.java:164) finished in 0.043 s
2022-08-02 14:45:03.411  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 21 is finished. Cancelling potential speculative or zombie tasks for this job
2022-08-02 14:45:03.411  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 39: Stage finished
2022-08-02 14:45:03.412  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 21 finished: count at Application.java:164, took 0.051587 s
2022-08-02 14:45:03.415  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659447903000 ms.0 from job set of time 1659447903000 ms
2022-08-02 14:45:03.415  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 0.415 s for time 1659447903000 ms (execution: 0.225 s)
2022-08-02 14:45:03.423  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 143 from persistence list
2022-08-02 14:45:03.424  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 142 from persistence list
2022-08-02 14:45:03.425  INFO   57 --- [-thread-pool-98] org.apache.spark.internal.Logging        : Removing RDD 143
2022-08-02 14:45:03.426  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[142] at receiverStream at Application.java:127 of time 1659447903000 ms
2022-08-02 14:45:03.427  INFO   57 --- [c-thread-pool-1] org.apache.spark.internal.Logging        : Removing RDD 142
2022-08-02 14:45:03.427  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659447901000 ms
2022-08-02 14:45:03.427  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659447901000 ms
2022-08-02 14:45:03.864  INFO   57 --- [shutdown-hook-0] org.apache.spark.internal.Logging        : Invoking stop(stopGracefully=false) from shutdown hook
2022-08-02 14:45:03.873  INFO   57 --- [er-event-loop-0] org.apache.spark.internal.Logging        : Sent stop signal to all 1 receivers
2022-08-02 14:45:03.874  INFO   57 --- [er-event-loop-1] org.apache.spark.internal.Logging        : Received stop signal
2022-08-02 14:45:03.876  INFO   57 --- [er-event-loop-1] org.apache.spark.internal.Logging        : Stopping receiver with message: Stopped by driver: 
2022-08-02 14:45:03.876  INFO   57 --- [er-event-loop-1] org.apache.spark.internal.Logging        : Called receiver onStop
2022-08-02 14:45:03.877  INFO   57 --- [er-event-loop-1] org.apache.spark.internal.Logging        : Deregistering receiver 0
2022-08-02 14:45:03.879  ERROR   73 --- [er-event-loop-2] org.apache.spark.internal.Logging        : Deregistered receiver for stream 0: Stopped by driver
2022-08-02 14:45:03.880  INFO   57 --- [er-event-loop-1] org.apache.spark.internal.Logging        : Stopped receiver 0
2022-08-02 14:45:03.881  INFO   57 --- [er-event-loop-1] org.apache.spark.internal.Logging        : Stopping BlockGenerator
2022-08-02 14:45:04.001  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659447904000 ms
2022-08-02 14:45:04.001  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659447904000 ms.0 from job set of time 1659447904000 ms
2022-08-02 14:45:04.004  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-08-02 14:45:04.004  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-08-02 14:45:04.190  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:164
2022-08-02 14:45:04.190  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 207 (count at Application.java:164) as input to shuffle 18
2022-08-02 14:45:04.190  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 22 (count at Application.java:164) with 1 output partitions
2022-08-02 14:45:04.190  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 41 (count at Application.java:164)
2022-08-02 14:45:04.190  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 40)
2022-08-02 14:45:04.190  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-08-02 14:45:04.190  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 41 (MapPartitionsRDD[210] at count at Application.java:164), which has no missing parents
2022-08-02 14:45:04.190  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_22 stored as values in memory (estimated size 11.0 KiB, free 897.4 MiB)
2022-08-02 14:45:04.190  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_22_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.4 MiB)
2022-08-02 14:45:04.190  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_22_piece0 in memory on host.docker.internal:61449 (size: 5.4 KiB, free: 897.5 MiB)
2022-08-02 14:45:04.190  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 22 from broadcast at DAGScheduler.scala:1478
2022-08-02 14:45:04.190  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 41 (MapPartitionsRDD[210] at count at Application.java:164) (first 15 tasks are for partitions Vector(0))
2022-08-02 14:45:04.190  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 41.0 with 1 tasks resource profile 0
2022-08-02 14:45:04.190  INFO   57 --- [er-event-loop-3] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 41.0 (TID 22) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-08-02 14:45:04.190  ERROR   94 --- [er-event-loop-3] org.apache.spark.internal.Logging        : Ignoring error
java.util.concurrent.RejectedExecutionException: Task org.apache.spark.executor.Executor$TaskRunner@3db0ef56 rejected from java.util.concurrent.ThreadPoolExecutor@2e71d381[Shutting down, pool size = 1, active threads = 1, queued tasks = 0, completed tasks = 21]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2063)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:830)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1379)
	at org.apache.spark.executor.Executor.launchTask(Executor.scala:270)
	at org.apache.spark.scheduler.local.LocalEndpoint.$anonfun$reviveOffers$1(LocalSchedulerBackend.scala:93)
	at org.apache.spark.scheduler.local.LocalEndpoint.$anonfun$reviveOffers$1$adapted(LocalSchedulerBackend.scala:91)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at org.apache.spark.scheduler.local.LocalEndpoint.reviveOffers(LocalSchedulerBackend.scala:91)
	at org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$receive$1.applyOrElse(LocalSchedulerBackend.scala:68)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:115)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2022-08-02 14:45:04.205  INFO   57 --- [er-event-loop-1] org.apache.spark.internal.Logging        : Stopped timer for BlockGenerator after time 1659447904200
2022-08-02 14:45:04.205  INFO   57 --- [er-event-loop-1] org.apache.spark.internal.Logging        : Waiting for block pushing thread to terminate
2022-08-02 14:45:04.221  INFO   57 --- [      Thread-14] org.apache.spark.internal.Logging        : Pushing out the last 0 blocks
2022-08-02 14:45:04.221  INFO   57 --- [      Thread-14] org.apache.spark.internal.Logging        : Stopped block pushing thread
2022-08-02 14:45:04.221  INFO   57 --- [er-event-loop-1] org.apache.spark.internal.Logging        : Stopped BlockGenerator
2022-08-02 14:45:04.221  INFO   57 --- [age 0.0 (TID 0)] org.apache.spark.internal.Logging        : Stopped receiver without error
2022-08-02 14:45:04.221  INFO   57 --- [age 0.0 (TID 0)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 0.0 (TID 0). 880 bytes result sent to driver
2022-08-02 14:45:04.221  INFO   57 --- [result-getter-1] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 0.0 (TID 0) in 17500 ms on host.docker.internal (executor driver) (1/1)
2022-08-02 14:45:04.221  INFO   57 --- [result-getter-1] org.apache.spark.internal.Logging        : Removed TaskSet 0.0, whose tasks have all completed, from pool 
2022-08-02 14:45:04.221  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 0 (start at Application.java:188) finished in 18.066 s
2022-08-02 14:45:04.221  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2022-08-02 14:45:04.221  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 0: Stage finished
2022-08-02 14:45:04.221  INFO   57 --- [shutdown-hook-0] org.apache.spark.internal.Logging        : All of the receivers have deregistered successfully
2022-08-02 14:45:04.221  INFO   57 --- [shutdown-hook-0] org.apache.spark.internal.Logging        : ReceiverTracker stopped
2022-08-02 14:45:04.221  INFO   57 --- [shutdown-hook-0] org.apache.spark.internal.Logging        : Stopping JobGenerator immediately
2022-08-02 14:45:04.221  INFO   57 --- [shutdown-hook-0] org.apache.spark.internal.Logging        : Stopped timer for JobGenerator after time 1659447904000
2022-08-02 14:45:04.221  INFO   57 --- [shutdown-hook-0] org.apache.spark.internal.Logging        : Stopped JobGenerator
2022-08-02 14:45:06.243  INFO   57 --- [shutdown-hook-0] org.apache.spark.internal.Logging        : Stopped JobScheduler
2022-08-02 14:45:06.243  INFO 1153 --- [shutdown-hook-0] ject.jetty.server.handler.ContextHandler : Stopped o.s.j.s.ServletContextHandler@2125ad3{/streaming,null,STOPPED,@Spark}
2022-08-02 14:45:06.243  INFO 1153 --- [shutdown-hook-0] ject.jetty.server.handler.ContextHandler : Stopped o.s.j.s.ServletContextHandler@f4c0e4e{/streaming/json,null,STOPPED,@Spark}
2022-08-02 14:45:06.258  INFO 1153 --- [shutdown-hook-0] ject.jetty.server.handler.ContextHandler : Stopped o.s.j.s.ServletContextHandler@6eb82908{/streaming/batch,null,STOPPED,@Spark}
2022-08-02 14:45:06.258  INFO 1153 --- [shutdown-hook-0] ject.jetty.server.handler.ContextHandler : Stopped o.s.j.s.ServletContextHandler@3d98d138{/streaming/batch/json,null,STOPPED,@Spark}
2022-08-02 14:45:06.258  INFO 1153 --- [shutdown-hook-0] ject.jetty.server.handler.ContextHandler : Stopped o.s.j.s.ServletContextHandler@5e2f3be5{/static/streaming,null,STOPPED,@Spark}
2022-08-02 14:45:06.258  INFO  199 --- [           main] com.elite.cdr.validator.Application      : ****************************************************
2022-08-02 14:45:06.258  INFO  200 --- [           main] com.elite.cdr.validator.Application      : Duration: 0.0 seconds
2022-08-02 14:45:06.258  INFO  201 --- [           main] com.elite.cdr.validator.Application      : Batch executed with success
2022-08-02 14:45:06.258  INFO   57 --- [shutdown-hook-0] org.apache.spark.internal.Logging        : StreamingContext stopped successfully
2022-08-02 14:45:06.258  INFO  202 --- [           main] com.elite.cdr.validator.Application      : ****************************************************
2022-08-02 14:45:06.258  INFO   57 --- [shutdown-hook-0] org.apache.spark.internal.Logging        : Invoking stop() from shutdown hook
2022-08-02 14:45:06.274  INFO  381 --- [shutdown-hook-0] rkproject.jetty.server.AbstractConnector : Stopped Spark@476aac9{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2022-08-02 14:45:06.274  INFO   57 --- [shutdown-hook-0] org.apache.spark.internal.Logging        : Stopped Spark web UI at http://host.docker.internal:4040
2022-08-02 14:45:06.274  INFO   57 --- [shutdown-hook-0] org.apache.spark.internal.Logging        : ResultStage 41 (count at Application.java:164) failed in 2.084 s due to Stage cancelled because SparkContext was shut down
2022-08-02 14:45:06.321  INFO   57 --- [er-event-loop-3] org.apache.spark.internal.Logging        : MapOutputTrackerMasterEndpoint stopped!
2022-08-02 14:45:06.399  INFO   57 --- [shutdown-hook-0] org.apache.spark.internal.Logging        : MemoryStore cleared
2022-08-02 14:45:06.399  INFO   57 --- [shutdown-hook-0] org.apache.spark.internal.Logging        : BlockManager stopped
2022-08-02 14:45:06.399  INFO   57 --- [shutdown-hook-0] org.apache.spark.internal.Logging        : BlockManagerMaster stopped
2022-08-02 14:45:06.414  INFO   57 --- [er-event-loop-0] org.apache.spark.internal.Logging        : OutputCommitCoordinator stopped!
2022-08-02 14:45:06.414  INFO   57 --- [shutdown-hook-0] org.apache.spark.internal.Logging        : Successfully stopped SparkContext
2022-08-02 14:45:06.414  INFO   57 --- [shutdown-hook-0] org.apache.spark.internal.Logging        : Shutdown hook called
2022-08-02 14:45:06.414  INFO   57 --- [shutdown-hook-0] org.apache.spark.internal.Logging        : Deleting directory C:\Users\Wael Hamdi\AppData\Local\Temp\spark-f77cb9c1-197b-476f-8905-8d28f96808eb
