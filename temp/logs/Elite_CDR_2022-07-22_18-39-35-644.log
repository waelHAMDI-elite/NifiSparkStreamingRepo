2022-07-22 18:39:35.730  INFO   47 --- [           main] com.elite.cdr.validator.Application      : Starting ASN1 Reader 
2022-07-22 18:39:35.737  INFO   49 --- [           main] com.elite.cdr.validator.Application      : ############### Run with the args [--env, local, --file, C:\IntelliJProjects\FraudDetectionSpark3\src\main\resources\data\simpleTypes.ber, --prop, C:\IntelliJProjects\NifiSparkStreaming\src\main\resources\myapp.properties]
2022-07-22 18:39:35.824  INFO   55 --- [           main] com.elite.cdr.validator.Application      : ############### Run in local mode
2022-07-22 18:39:40.576  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Running Spark version 3.2.1
2022-07-22 18:39:41.667  INFO   57 --- [           main] org.apache.spark.internal.Logging        : ==============================================================
2022-07-22 18:39:41.670  INFO   57 --- [           main] org.apache.spark.internal.Logging        : No custom resources configured for spark.driver.
2022-07-22 18:39:41.670  INFO   57 --- [           main] org.apache.spark.internal.Logging        : ==============================================================
2022-07-22 18:39:41.671  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Submitted application: NiFi Spark Streaming example
2022-07-22 18:39:41.788  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2022-07-22 18:39:41.816  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Limiting resource is cpu
2022-07-22 18:39:41.823  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Added ResourceProfile id: 0
2022-07-22 18:39:42.215  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Changing view acls to: Wael Hamdi
2022-07-22 18:39:42.216  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Changing modify acls to: Wael Hamdi
2022-07-22 18:39:42.217  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Changing view acls groups to: 
2022-07-22 18:39:42.218  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Changing modify acls groups to: 
2022-07-22 18:39:42.219  INFO   57 --- [           main] org.apache.spark.internal.Logging        : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Wael Hamdi); groups with view permissions: Set(); users  with modify permissions: Set(Wael Hamdi); groups with modify permissions: Set()
2022-07-22 18:39:45.641  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Successfully started service 'sparkDriver' on port 62983.
2022-07-22 18:39:45.749  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Registering MapOutputTracker
2022-07-22 18:39:45.894  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Registering BlockManagerMaster
2022-07-22 18:39:45.947  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2022-07-22 18:39:45.949  INFO   57 --- [           main] org.apache.spark.internal.Logging        : BlockManagerMasterEndpoint up
2022-07-22 18:39:45.954  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Registering BlockManagerMasterHeartbeat
2022-07-22 18:39:46.058  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Created local directory at C:\Users\Wael Hamdi\AppData\Local\Temp\blockmgr-98c95b04-f032-4ef7-8b63-b400ed3a0c22
2022-07-22 18:39:46.173  INFO   57 --- [           main] org.apache.spark.internal.Logging        : MemoryStore started with capacity 897.6 MiB
2022-07-22 18:39:46.220  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Registering OutputCommitCoordinator
2022-07-22 18:39:46.624  INFO  170 --- [           main] org.sparkproject.jetty.util.log.Log      : Logging initialized @12047ms to org.sparkproject.jetty.util.log.Slf4jLog
2022-07-22 18:39:46.803  INFO  375 --- [           main] org.sparkproject.jetty.server.Server     : jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_301-b09
2022-07-22 18:39:46.870  INFO  415 --- [           main] org.sparkproject.jetty.server.Server     : Started @12294ms
2022-07-22 18:39:46.944  INFO  331 --- [           main] rkproject.jetty.server.AbstractConnector : Started ServerConnector@7caa550{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2022-07-22 18:39:46.944  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Successfully started service 'SparkUI' on port 4040.
2022-07-22 18:39:46.985  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@388ffbc2{/jobs,null,AVAILABLE,@Spark}
2022-07-22 18:39:46.988  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@61a002b1{/jobs/json,null,AVAILABLE,@Spark}
2022-07-22 18:39:46.989  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@780ec4a5{/jobs/job,null,AVAILABLE,@Spark}
2022-07-22 18:39:46.991  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@548e76f1{/jobs/job/json,null,AVAILABLE,@Spark}
2022-07-22 18:39:46.992  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@72c927f1{/stages,null,AVAILABLE,@Spark}
2022-07-22 18:39:46.993  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3dd69f5a{/stages/json,null,AVAILABLE,@Spark}
2022-07-22 18:39:46.995  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1ee4730{/stages/stage,null,AVAILABLE,@Spark}
2022-07-22 18:39:46.997  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@16fb356{/stages/stage/json,null,AVAILABLE,@Spark}
2022-07-22 18:39:46.999  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@23a9ba52{/stages/pool,null,AVAILABLE,@Spark}
2022-07-22 18:39:47.000  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@70ab80e3{/stages/pool/json,null,AVAILABLE,@Spark}
2022-07-22 18:39:47.002  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@67427b69{/storage,null,AVAILABLE,@Spark}
2022-07-22 18:39:47.003  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@544630b7{/storage/json,null,AVAILABLE,@Spark}
2022-07-22 18:39:47.005  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1095f122{/storage/rdd,null,AVAILABLE,@Spark}
2022-07-22 18:39:47.006  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3d6300e8{/storage/rdd/json,null,AVAILABLE,@Spark}
2022-07-22 18:39:47.008  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@24a1c17f{/environment,null,AVAILABLE,@Spark}
2022-07-22 18:39:47.009  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@73511076{/environment/json,null,AVAILABLE,@Spark}
2022-07-22 18:39:47.010  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@532721fd{/executors,null,AVAILABLE,@Spark}
2022-07-22 18:39:47.012  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7fb9f71f{/executors/json,null,AVAILABLE,@Spark}
2022-07-22 18:39:47.013  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@51f49060{/executors/threadDump,null,AVAILABLE,@Spark}
2022-07-22 18:39:47.014  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@617fe9e1{/executors/threadDump/json,null,AVAILABLE,@Spark}
2022-07-22 18:39:47.062  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1cf2fed4{/static,null,AVAILABLE,@Spark}
2022-07-22 18:39:47.063  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4b629f13{/,null,AVAILABLE,@Spark}
2022-07-22 18:39:47.065  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1b9ea3e3{/api,null,AVAILABLE,@Spark}
2022-07-22 18:39:47.066  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4263b080{/jobs/job/kill,null,AVAILABLE,@Spark}
2022-07-22 18:39:47.067  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@71f67a79{/stages/stage/kill,null,AVAILABLE,@Spark}
2022-07-22 18:39:47.070  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Bound SparkUI to 0.0.0.0, and started at http://host.docker.internal:4040
2022-07-22 18:39:47.728  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Starting executor ID driver on host host.docker.internal
2022-07-22 18:39:47.880  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 63008.
2022-07-22 18:39:47.880  INFO   82 --- [           main] .network.netty.NettyBlockTransferService : Server created on host.docker.internal:63008
2022-07-22 18:39:47.882  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2022-07-22 18:39:47.912  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Registering BlockManager BlockManagerId(driver, host.docker.internal, 63008, None)
2022-07-22 18:39:47.917  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Registering block manager host.docker.internal:63008 with 897.6 MiB RAM, BlockManagerId(driver, host.docker.internal, 63008, None)
2022-07-22 18:39:47.924  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Registered BlockManager BlockManagerId(driver, host.docker.internal, 63008, None)
2022-07-22 18:39:47.926  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Initialized BlockManager: BlockManagerId(driver, host.docker.internal, 63008, None)
2022-07-22 18:39:48.286  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@378bd86d{/metrics/json,null,AVAILABLE,@Spark}
2022-07-22 18:39:49.254  INFO   57 --- [streaming-start] org.apache.spark.internal.Logging        : Starting 1 receivers
2022-07-22 18:39:49.257  INFO   57 --- [streaming-start] org.apache.spark.internal.Logging        : ReceiverTracker started
2022-07-22 18:39:49.265  INFO   57 --- [streaming-start] org.apache.spark.internal.Logging        : Slide time = 1000 ms
2022-07-22 18:39:49.266  INFO   57 --- [streaming-start] org.apache.spark.internal.Logging        : Storage level = Serialized 1x Replicated
2022-07-22 18:39:49.267  INFO   57 --- [streaming-start] org.apache.spark.internal.Logging        : Checkpoint interval = null
2022-07-22 18:39:49.268  INFO   57 --- [streaming-start] org.apache.spark.internal.Logging        : Remember interval = 1000 ms
2022-07-22 18:39:49.268  INFO   57 --- [streaming-start] org.apache.spark.internal.Logging        : Initialized and validated org.apache.spark.streaming.dstream.PluggableInputDStream@6a76d7d9
2022-07-22 18:39:49.269  INFO   57 --- [streaming-start] org.apache.spark.internal.Logging        : Slide time = 1000 ms
2022-07-22 18:39:49.269  INFO   57 --- [streaming-start] org.apache.spark.internal.Logging        : Storage level = Serialized 1x Replicated
2022-07-22 18:39:49.269  INFO   57 --- [streaming-start] org.apache.spark.internal.Logging        : Checkpoint interval = null
2022-07-22 18:39:49.270  INFO   57 --- [streaming-start] org.apache.spark.internal.Logging        : Remember interval = 1000 ms
2022-07-22 18:39:49.270  INFO   57 --- [streaming-start] org.apache.spark.internal.Logging        : Initialized and validated org.apache.spark.streaming.dstream.MappedDStream@78e62de4
2022-07-22 18:39:49.270  INFO   57 --- [streaming-start] org.apache.spark.internal.Logging        : Slide time = 1000 ms
2022-07-22 18:39:49.270  INFO   57 --- [streaming-start] org.apache.spark.internal.Logging        : Storage level = Serialized 1x Replicated
2022-07-22 18:39:49.271  INFO   57 --- [streaming-start] org.apache.spark.internal.Logging        : Checkpoint interval = null
2022-07-22 18:39:49.272  INFO   57 --- [streaming-start] org.apache.spark.internal.Logging        : Remember interval = 1000 ms
2022-07-22 18:39:49.272  INFO   57 --- [streaming-start] org.apache.spark.internal.Logging        : Initialized and validated org.apache.spark.streaming.dstream.ForEachDStream@4939df8d
2022-07-22 18:39:50.048  INFO   57 --- [er-event-loop-3] org.apache.spark.internal.Logging        : Receiver 0 started
2022-07-22 18:39:50.054  INFO   57 --- [streaming-start] org.apache.spark.internal.Logging        : Started timer for JobGenerator at time 1658511590000
2022-07-22 18:39:50.055  INFO   57 --- [streaming-start] org.apache.spark.internal.Logging        : Started JobGenerator at 1658511590000 ms
2022-07-22 18:39:50.057  INFO   57 --- [streaming-start] org.apache.spark.internal.Logging        : Started JobScheduler
2022-07-22 18:39:50.062  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 0 (start at Application.java:143) with 1 output partitions
2022-07-22 18:39:50.062  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6fd77352{/streaming,null,AVAILABLE,@Spark}
2022-07-22 18:39:50.062  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 0 (start at Application.java:143)
2022-07-22 18:39:50.064  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List()
2022-07-22 18:39:50.064  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3f672204{/streaming/json,null,AVAILABLE,@Spark}
2022-07-22 18:39:50.067  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-22 18:39:50.067  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6c65860d{/streaming/batch,null,AVAILABLE,@Spark}
2022-07-22 18:39:50.069  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7cf283e1{/streaming/batch/json,null,AVAILABLE,@Spark}
2022-07-22 18:39:50.074  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 0 (Receiver 0 ParallelCollectionRDD[0] at makeRDD at ReceiverTracker.scala:609), which has no missing parents
2022-07-22 18:39:50.089  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@252f626c{/static/streaming,null,AVAILABLE,@Spark}
2022-07-22 18:39:50.090  INFO   57 --- [           main] org.apache.spark.internal.Logging        : StreamingContext started
2022-07-22 18:39:50.205  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1658511590000 ms
2022-07-22 18:39:50.209  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1658511590000 ms.0 from job set of time 1658511590000 ms
2022-07-22 18:39:50.514  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkContext; some configuration may not take effect.
2022-07-22 18:39:50.819  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_0 stored as values in memory (estimated size 97.5 KiB, free 897.5 MiB)
2022-07-22 18:39:51.004  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1658511591000 ms
2022-07-22 18:39:52.007  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1658511592000 ms
2022-07-22 18:39:53.033  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1658511593000 ms
2022-07-22 18:39:54.006  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1658511594000 ms
2022-07-22 18:39:54.293  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2022-07-22 18:39:54.327  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_0_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 897.5 MiB)
2022-07-22 18:39:54.331  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_0_piece0 in memory on host.docker.internal:63008 (size: 34.2 KiB, free: 897.6 MiB)
2022-07-22 18:39:54.368  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 0 from broadcast at DAGScheduler.scala:1478
2022-07-22 18:39:54.391  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 0 (Receiver 0 ParallelCollectionRDD[0] at makeRDD at ReceiverTracker.scala:609) (first 15 tasks are for partitions Vector(0))
2022-07-22 18:39:54.394  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 0.0 with 1 tasks resource profile 0
2022-07-22 18:39:54.575  INFO   57 --- [er-event-loop-0] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 0.0 (TID 0) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 5950 bytes) taskResourceAssignments Map()
2022-07-22 18:39:54.614  INFO   57 --- [age 0.0 (TID 0)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 0.0 (TID 0)
2022-07-22 18:39:55.063  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1658511595000 ms
2022-07-22 18:39:55.167  INFO   57 --- [age 0.0 (TID 0)] org.apache.spark.internal.Logging        : Started timer for BlockGenerator at time 1658511595200
2022-07-22 18:39:55.169  INFO   57 --- [age 0.0 (TID 0)] org.apache.spark.internal.Logging        : Started BlockGenerator
2022-07-22 18:39:55.171  INFO   57 --- [      Thread-14] org.apache.spark.internal.Logging        : Started block pushing thread
2022-07-22 18:39:55.186  INFO   57 --- [er-event-loop-0] org.apache.spark.internal.Logging        : Registered receiver for stream 0 from host.docker.internal:62983
2022-07-22 18:39:55.187  INFO   57 --- [age 0.0 (TID 0)] org.apache.spark.internal.Logging        : Starting receiver 0
2022-07-22 18:39:55.190  INFO   57 --- [age 0.0 (TID 0)] org.apache.spark.internal.Logging        : Called receiver 0 onStart
2022-07-22 18:39:55.191  INFO   57 --- [age 0.0 (TID 0)] org.apache.spark.internal.Logging        : Waiting for receiver to be stopped
2022-07-22 18:39:55.481  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Warehouse path is 'file:/C:/IntelliJProjects/NifiSparkStreaming/spark-warehouse'.
2022-07-22 18:39:55.763  INFO  915 --- [-job-executor-0] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@77348365{/SQL,null,AVAILABLE,@Spark}
2022-07-22 18:39:55.768  INFO  915 --- [-job-executor-0] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@824474e{/SQL/json,null,AVAILABLE,@Spark}
2022-07-22 18:39:55.772  INFO  915 --- [-job-executor-0] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2bbfc4c8{/SQL/execution,null,AVAILABLE,@Spark}
2022-07-22 18:39:55.775  INFO  915 --- [-job-executor-0] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4fe1aded{/SQL/execution/json,null,AVAILABLE,@Spark}
2022-07-22 18:39:55.779  INFO  915 --- [-job-executor-0] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3be00e18{/static/sql,null,AVAILABLE,@Spark}
2022-07-22 18:39:56.006  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1658511596000 ms
2022-07-22 18:39:57.003  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1658511597000 ms
2022-07-22 18:39:58.004  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1658511598000 ms
2022-07-22 18:39:58.829  INFO  571 --- [  NiFi Receiver] g.apache.nifi.remote.client.PeerSelector : Successfully refreshed peer status cache; remote group consists of 1 peers
2022-07-22 18:39:58.829  INFO  571 --- [ool Maintenance] g.apache.nifi.remote.client.PeerSelector : Successfully refreshed peer status cache; remote group consists of 1 peers
2022-07-22 18:39:59.006  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1658511599000 ms
2022-07-22 18:39:59.088  INFO   57 --- [  NiFi Receiver] org.apache.spark.internal.Logging        : Block input-0-1658511595130 stored as values in memory (estimated size 5.1 MiB, free 892.4 MiB)
2022-07-22 18:39:59.089  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added input-0-1658511595130 in memory on host.docker.internal:63008 (size: 5.1 MiB, free: 892.5 MiB)
2022-07-22 18:40:00.008  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1658511600000 ms
2022-07-22 18:40:01.005  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1658511601000 ms
2022-07-22 18:40:01.917  WARN   69 --- [ver-heartbeater] org.apache.spark.internal.Logging        : Exception when trying to compute pagesize, as a result reporting of ProcessTree metrics is stopped
2022-07-22 18:40:02.011  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1658511602000 ms
2022-07-22 18:40:03.006  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1658511603000 ms
2022-07-22 18:40:04.003  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1658511604000 ms
2022-07-22 18:40:05.003  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1658511605000 ms
2022-07-22 18:40:06.003  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1658511606000 ms
2022-07-22 18:40:06.584  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Code generated in 413.8428 ms
2022-07-22 18:40:07.002  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1658511607000 ms
2022-07-22 18:40:07.108  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Code generated in 21.328 ms
2022-07-22 18:40:07.170  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Code generated in 15.8046 ms
2022-07-22 18:40:07.372  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:136
2022-07-22 18:40:07.380  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 42 (count at Application.java:136) as input to shuffle 0
2022-07-22 18:40:07.384  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 1 (count at Application.java:136) with 1 output partitions
2022-07-22 18:40:07.385  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 2 (count at Application.java:136)
2022-07-22 18:40:07.385  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 1)
2022-07-22 18:40:07.386  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-22 18:40:07.388  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 2 (MapPartitionsRDD[45] at count at Application.java:136), which has no missing parents
2022-07-22 18:40:07.396  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_1 stored as values in memory (estimated size 11.0 KiB, free 892.4 MiB)
2022-07-22 18:40:07.400  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 892.4 MiB)
2022-07-22 18:40:07.401  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_1_piece0 in memory on host.docker.internal:63008 (size: 5.4 KiB, free: 892.5 MiB)
2022-07-22 18:40:07.401  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 1 from broadcast at DAGScheduler.scala:1478
2022-07-22 18:40:07.402  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[45] at count at Application.java:136) (first 15 tasks are for partitions Vector(0))
2022-07-22 18:40:07.402  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 2.0 with 1 tasks resource profile 0
2022-07-22 18:40:07.405  INFO   57 --- [er-event-loop-0] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 2.0 (TID 1) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-22 18:40:07.406  INFO   57 --- [age 2.0 (TID 1)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 2.0 (TID 1)
2022-07-22 18:40:07.598  INFO   57 --- [age 2.0 (TID 1)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-22 18:40:07.602  INFO   57 --- [age 2.0 (TID 1)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 14 ms
2022-07-22 18:40:07.650  INFO   57 --- [age 2.0 (TID 1)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 2.0 (TID 1). 2684 bytes result sent to driver
2022-07-22 18:40:07.662  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 2.0 (TID 1) in 256 ms on host.docker.internal (executor driver) (1/1)
2022-07-22 18:40:07.667  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Removed TaskSet 2.0, whose tasks have all completed, from pool 
2022-07-22 18:40:07.677  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 2 (count at Application.java:136) finished in 0.283 s
2022-07-22 18:40:07.689  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-22 18:40:07.690  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 2: Stage finished
2022-07-22 18:40:07.693  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 1 finished: count at Application.java:136, took 0.319887 s
2022-07-22 18:40:07.710  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1658511590000 ms.0 from job set of time 1658511590000 ms
2022-07-22 18:40:07.713  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 17.709 s for time 1658511590000 ms (execution: 17.501 s)
2022-07-22 18:40:07.714  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1658511591000 ms.0 from job set of time 1658511591000 ms
2022-07-22 18:40:07.715  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-22 18:40:07.715  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-22 18:40:07.723  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 
2022-07-22 18:40:07.743  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 
2022-07-22 18:40:07.864  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:136
2022-07-22 18:40:07.866  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 51 (count at Application.java:136) as input to shuffle 1
2022-07-22 18:40:07.867  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 2 (count at Application.java:136) with 1 output partitions
2022-07-22 18:40:07.867  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 4 (count at Application.java:136)
2022-07-22 18:40:07.867  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 3)
2022-07-22 18:40:07.868  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-22 18:40:07.870  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 4 (MapPartitionsRDD[54] at count at Application.java:136), which has no missing parents
2022-07-22 18:40:07.878  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_2 stored as values in memory (estimated size 11.0 KiB, free 892.4 MiB)
2022-07-22 18:40:07.882  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 892.4 MiB)
2022-07-22 18:40:07.884  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_2_piece0 in memory on host.docker.internal:63008 (size: 5.4 KiB, free: 892.5 MiB)
2022-07-22 18:40:07.885  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 2 from broadcast at DAGScheduler.scala:1478
2022-07-22 18:40:07.887  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[54] at count at Application.java:136) (first 15 tasks are for partitions Vector(0))
2022-07-22 18:40:07.887  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 4.0 with 1 tasks resource profile 0
2022-07-22 18:40:07.890  INFO   57 --- [er-event-loop-3] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 4.0 (TID 2) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-22 18:40:07.891  INFO   57 --- [age 4.0 (TID 2)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 4.0 (TID 2)
2022-07-22 18:40:07.902  INFO   57 --- [age 4.0 (TID 2)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-22 18:40:07.903  INFO   57 --- [age 4.0 (TID 2)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 1 ms
2022-07-22 18:40:07.906  INFO   57 --- [age 4.0 (TID 2)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 4.0 (TID 2). 2555 bytes result sent to driver
2022-07-22 18:40:07.910  INFO   57 --- [result-getter-1] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 4.0 (TID 2) in 21 ms on host.docker.internal (executor driver) (1/1)
2022-07-22 18:40:07.911  INFO   57 --- [result-getter-1] org.apache.spark.internal.Logging        : Removed TaskSet 4.0, whose tasks have all completed, from pool 
2022-07-22 18:40:07.913  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 4 (count at Application.java:136) finished in 0.040 s
2022-07-22 18:40:07.914  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-22 18:40:07.915  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 4: Stage finished
2022-07-22 18:40:07.915  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 2 finished: count at Application.java:136, took 0.050359 s
2022-07-22 18:40:07.917  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1658511591000 ms.0 from job set of time 1658511591000 ms
2022-07-22 18:40:07.918  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 16.917 s for time 1658511591000 ms (execution: 0.203 s)
2022-07-22 18:40:07.918  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1658511592000 ms.0 from job set of time 1658511592000 ms
2022-07-22 18:40:07.920  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 2 from persistence list
2022-07-22 18:40:07.921  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-22 18:40:07.921  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-22 18:40:07.966  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 1 from persistence list
2022-07-22 18:40:07.974  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[1] at receiverStream at Application.java:116 of time 1658511591000 ms
2022-07-22 18:40:07.975  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 
2022-07-22 18:40:07.976  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 
2022-07-22 18:40:07.976  INFO   57 --- [c-thread-pool-0] org.apache.spark.internal.Logging        : Removing RDD 2
2022-07-22 18:40:07.981  INFO   57 --- [c-thread-pool-1] org.apache.spark.internal.Logging        : Removing RDD 1
2022-07-22 18:40:08.022  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1658511608000 ms
2022-07-22 18:40:08.082  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:136
2022-07-22 18:40:08.084  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 62 (count at Application.java:136) as input to shuffle 2
2022-07-22 18:40:08.085  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 3 (count at Application.java:136) with 1 output partitions
2022-07-22 18:40:08.086  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 6 (count at Application.java:136)
2022-07-22 18:40:08.086  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 5)
2022-07-22 18:40:08.087  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-22 18:40:08.088  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 6 (MapPartitionsRDD[65] at count at Application.java:136), which has no missing parents
2022-07-22 18:40:08.093  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_3 stored as values in memory (estimated size 11.0 KiB, free 892.3 MiB)
2022-07-22 18:40:08.140  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_3_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 892.3 MiB)
2022-07-22 18:40:08.141  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_3_piece0 in memory on host.docker.internal:63008 (size: 5.4 KiB, free: 892.5 MiB)
2022-07-22 18:40:08.142  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 3 from broadcast at DAGScheduler.scala:1478
2022-07-22 18:40:08.143  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[65] at count at Application.java:136) (first 15 tasks are for partitions Vector(0))
2022-07-22 18:40:08.143  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 6.0 with 1 tasks resource profile 0
2022-07-22 18:40:08.145  INFO   57 --- [er-event-loop-2] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 6.0 (TID 3) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-22 18:40:08.153  INFO   57 --- [age 6.0 (TID 3)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 6.0 (TID 3)
2022-07-22 18:40:08.168  INFO   57 --- [age 6.0 (TID 3)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-22 18:40:08.169  INFO   57 --- [age 6.0 (TID 3)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 8 ms
2022-07-22 18:40:08.172  INFO   57 --- [age 6.0 (TID 3)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 6.0 (TID 3). 2598 bytes result sent to driver
2022-07-22 18:40:08.174  INFO   57 --- [result-getter-2] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 6.0 (TID 3) in 29 ms on host.docker.internal (executor driver) (1/1)
2022-07-22 18:40:08.175  INFO   57 --- [result-getter-2] org.apache.spark.internal.Logging        : Removed TaskSet 6.0, whose tasks have all completed, from pool 
2022-07-22 18:40:08.178  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 6 (count at Application.java:136) finished in 0.088 s
2022-07-22 18:40:08.181  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-22 18:40:08.182  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 6: Stage finished
2022-07-22 18:40:08.184  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 3 finished: count at Application.java:136, took 0.101318 s
2022-07-22 18:40:08.186  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1658511592000 ms.0 from job set of time 1658511592000 ms
2022-07-22 18:40:08.187  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 16.186 s for time 1658511592000 ms (execution: 0.268 s)
2022-07-22 18:40:08.187  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1658511593000 ms.0 from job set of time 1658511593000 ms
2022-07-22 18:40:08.188  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 5 from persistence list
2022-07-22 18:40:08.189  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 4 from persistence list
2022-07-22 18:40:08.190  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-22 18:40:08.190  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-22 18:40:08.190  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[4] at receiverStream at Application.java:116 of time 1658511592000 ms
2022-07-22 18:40:08.191  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1658511590000 ms
2022-07-22 18:40:08.191  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1658511590000 ms
2022-07-22 18:40:08.193  INFO   57 --- [c-thread-pool-6] org.apache.spark.internal.Logging        : Removing RDD 5
2022-07-22 18:40:08.194  INFO   57 --- [c-thread-pool-7] org.apache.spark.internal.Logging        : Removing RDD 4
2022-07-22 18:40:08.359  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:136
2022-07-22 18:40:08.361  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 71 (count at Application.java:136) as input to shuffle 3
2022-07-22 18:40:08.363  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 4 (count at Application.java:136) with 1 output partitions
2022-07-22 18:40:08.365  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 8 (count at Application.java:136)
2022-07-22 18:40:08.365  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 7)
2022-07-22 18:40:08.368  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-22 18:40:08.369  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 8 (MapPartitionsRDD[74] at count at Application.java:136), which has no missing parents
2022-07-22 18:40:08.375  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_4 stored as values in memory (estimated size 11.0 KiB, free 892.3 MiB)
2022-07-22 18:40:08.378  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_4_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 892.3 MiB)
2022-07-22 18:40:08.379  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_4_piece0 in memory on host.docker.internal:63008 (size: 5.4 KiB, free: 892.5 MiB)
2022-07-22 18:40:08.381  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 4 from broadcast at DAGScheduler.scala:1478
2022-07-22 18:40:08.383  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[74] at count at Application.java:136) (first 15 tasks are for partitions Vector(0))
2022-07-22 18:40:08.383  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 8.0 with 1 tasks resource profile 0
2022-07-22 18:40:08.385  INFO   57 --- [er-event-loop-1] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 8.0 (TID 4) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-22 18:40:08.386  INFO   57 --- [age 8.0 (TID 4)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 8.0 (TID 4)
2022-07-22 18:40:08.394  INFO   57 --- [age 8.0 (TID 4)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-22 18:40:08.394  INFO   57 --- [age 8.0 (TID 4)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 1 ms
2022-07-22 18:40:08.404  INFO   57 --- [age 8.0 (TID 4)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 8.0 (TID 4). 2598 bytes result sent to driver
2022-07-22 18:40:08.408  INFO   57 --- [result-getter-3] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 8.0 (TID 4) in 24 ms on host.docker.internal (executor driver) (1/1)
2022-07-22 18:40:08.408  INFO   57 --- [result-getter-3] org.apache.spark.internal.Logging        : Removed TaskSet 8.0, whose tasks have all completed, from pool 
2022-07-22 18:40:08.410  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 8 (count at Application.java:136) finished in 0.039 s
2022-07-22 18:40:08.410  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-22 18:40:08.410  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 8: Stage finished
2022-07-22 18:40:08.414  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 4 finished: count at Application.java:136, took 0.051723 s
2022-07-22 18:40:08.416  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1658511593000 ms.0 from job set of time 1658511593000 ms
2022-07-22 18:40:08.417  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 15.416 s for time 1658511593000 ms (execution: 0.229 s)
2022-07-22 18:40:08.417  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1658511594000 ms.0 from job set of time 1658511594000 ms
2022-07-22 18:40:08.419  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-22 18:40:08.419  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-22 18:40:08.426  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 7 from persistence list
2022-07-22 18:40:08.438  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 6 from persistence list
2022-07-22 18:40:08.442  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[6] at receiverStream at Application.java:116 of time 1658511593000 ms
2022-07-22 18:40:08.443  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1658511591000 ms
2022-07-22 18:40:08.443  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1658511591000 ms
2022-07-22 18:40:08.446  INFO   57 --- [-thread-pool-12] org.apache.spark.internal.Logging        : Removing RDD 7
2022-07-22 18:40:08.446  INFO   57 --- [-thread-pool-13] org.apache.spark.internal.Logging        : Removing RDD 6
2022-07-22 18:40:08.579  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:136
2022-07-22 18:40:08.582  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 80 (count at Application.java:136) as input to shuffle 4
2022-07-22 18:40:08.583  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 5 (count at Application.java:136) with 1 output partitions
2022-07-22 18:40:08.583  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 10 (count at Application.java:136)
2022-07-22 18:40:08.583  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 9)
2022-07-22 18:40:08.584  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-22 18:40:08.585  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 10 (MapPartitionsRDD[83] at count at Application.java:136), which has no missing parents
2022-07-22 18:40:08.594  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_5 stored as values in memory (estimated size 11.0 KiB, free 892.3 MiB)
2022-07-22 18:40:08.607  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_5_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 892.3 MiB)
2022-07-22 18:40:08.609  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_1_piece0 on host.docker.internal:63008 in memory (size: 5.4 KiB, free: 892.5 MiB)
2022-07-22 18:40:08.610  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_5_piece0 in memory on host.docker.internal:63008 (size: 5.4 KiB, free: 892.5 MiB)
2022-07-22 18:40:08.611  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 5 from broadcast at DAGScheduler.scala:1478
2022-07-22 18:40:08.614  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[83] at count at Application.java:136) (first 15 tasks are for partitions Vector(0))
2022-07-22 18:40:08.615  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 10.0 with 1 tasks resource profile 0
2022-07-22 18:40:08.617  INFO   57 --- [er-event-loop-0] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 10.0 (TID 5) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-22 18:40:08.619  INFO   57 --- [ge 10.0 (TID 5)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 10.0 (TID 5)
2022-07-22 18:40:08.628  INFO   57 --- [ge 10.0 (TID 5)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-22 18:40:08.632  INFO   57 --- [ge 10.0 (TID 5)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 5 ms
2022-07-22 18:40:08.635  INFO   57 --- [ge 10.0 (TID 5)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 10.0 (TID 5). 2555 bytes result sent to driver
2022-07-22 18:40:08.638  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 10.0 (TID 5) in 22 ms on host.docker.internal (executor driver) (1/1)
2022-07-22 18:40:08.639  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Removed TaskSet 10.0, whose tasks have all completed, from pool 
2022-07-22 18:40:08.640  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 10 (count at Application.java:136) finished in 0.053 s
2022-07-22 18:40:08.640  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-22 18:40:08.641  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 10: Stage finished
2022-07-22 18:40:08.641  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 5 finished: count at Application.java:136, took 0.061224 s
2022-07-22 18:40:08.651  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1658511594000 ms.0 from job set of time 1658511594000 ms
2022-07-22 18:40:08.652  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 14.651 s for time 1658511594000 ms (execution: 0.234 s)
2022-07-22 18:40:08.653  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1658511595000 ms.0 from job set of time 1658511595000 ms
2022-07-22 18:40:08.655  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-22 18:40:08.655  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-22 18:40:08.691  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 9 from persistence list
2022-07-22 18:40:08.704  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 8 from persistence list
2022-07-22 18:40:08.707  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[8] at receiverStream at Application.java:116 of time 1658511594000 ms
2022-07-22 18:40:08.708  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1658511592000 ms
2022-07-22 18:40:08.708  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1658511592000 ms
2022-07-22 18:40:08.711  INFO   57 --- [-thread-pool-21] org.apache.spark.internal.Logging        : Removing RDD 9
2022-07-22 18:40:08.715  INFO   57 --- [-thread-pool-22] org.apache.spark.internal.Logging        : Removing RDD 8
2022-07-22 18:40:08.737  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_4_piece0 on host.docker.internal:63008 in memory (size: 5.4 KiB, free: 892.5 MiB)
2022-07-22 18:40:08.754  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_3_piece0 on host.docker.internal:63008 in memory (size: 5.4 KiB, free: 892.5 MiB)
2022-07-22 18:40:08.799  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_2_piece0 on host.docker.internal:63008 in memory (size: 5.4 KiB, free: 892.5 MiB)
2022-07-22 18:40:08.904  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:136
2022-07-22 18:40:08.906  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 89 (count at Application.java:136) as input to shuffle 5
2022-07-22 18:40:08.907  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 6 (count at Application.java:136) with 1 output partitions
2022-07-22 18:40:08.907  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 12 (count at Application.java:136)
2022-07-22 18:40:08.907  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 11)
2022-07-22 18:40:08.909  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-22 18:40:08.915  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 12 (MapPartitionsRDD[92] at count at Application.java:136), which has no missing parents
2022-07-22 18:40:08.920  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_6 stored as values in memory (estimated size 11.0 KiB, free 892.4 MiB)
2022-07-22 18:40:08.926  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_6_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 892.4 MiB)
2022-07-22 18:40:08.927  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_6_piece0 in memory on host.docker.internal:63008 (size: 5.4 KiB, free: 892.5 MiB)
2022-07-22 18:40:08.928  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 6 from broadcast at DAGScheduler.scala:1478
2022-07-22 18:40:08.929  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[92] at count at Application.java:136) (first 15 tasks are for partitions Vector(0))
2022-07-22 18:40:08.930  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 12.0 with 1 tasks resource profile 0
2022-07-22 18:40:08.932  INFO   57 --- [er-event-loop-3] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 12.0 (TID 6) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-22 18:40:08.933  INFO   57 --- [ge 12.0 (TID 6)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 12.0 (TID 6)
2022-07-22 18:40:08.939  INFO   57 --- [ge 12.0 (TID 6)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-22 18:40:08.940  INFO   57 --- [ge 12.0 (TID 6)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 1 ms
2022-07-22 18:40:08.942  INFO   57 --- [ge 12.0 (TID 6)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 12.0 (TID 6). 2598 bytes result sent to driver
2022-07-22 18:40:08.943  INFO   57 --- [result-getter-1] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 12.0 (TID 6) in 12 ms on host.docker.internal (executor driver) (1/1)
2022-07-22 18:40:08.943  INFO   57 --- [result-getter-1] org.apache.spark.internal.Logging        : Removed TaskSet 12.0, whose tasks have all completed, from pool 
2022-07-22 18:40:08.945  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 12 (count at Application.java:136) finished in 0.027 s
2022-07-22 18:40:08.945  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-22 18:40:08.946  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 12: Stage finished
2022-07-22 18:40:08.947  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 6 finished: count at Application.java:136, took 0.041811 s
2022-07-22 18:40:08.950  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1658511595000 ms.0 from job set of time 1658511595000 ms
2022-07-22 18:40:08.950  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 13.950 s for time 1658511595000 ms (execution: 0.297 s)
2022-07-22 18:40:08.951  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1658511596000 ms.0 from job set of time 1658511596000 ms
2022-07-22 18:40:08.952  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-22 18:40:08.952  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-22 18:40:08.971  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 12 from persistence list
2022-07-22 18:40:08.973  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 11 from persistence list
2022-07-22 18:40:08.974  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[11] at receiverStream at Application.java:116 of time 1658511595000 ms
2022-07-22 18:40:08.974  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1658511593000 ms
2022-07-22 18:40:08.975  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1658511593000 ms
2022-07-22 18:40:08.986  INFO   57 --- [-thread-pool-48] org.apache.spark.internal.Logging        : Removing RDD 12
2022-07-22 18:40:08.988  INFO   57 --- [-thread-pool-49] org.apache.spark.internal.Logging        : Removing RDD 11
2022-07-22 18:40:09.044  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1658511609000 ms
2022-07-22 18:40:09.159  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:136
2022-07-22 18:40:09.160  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 100 (count at Application.java:136) as input to shuffle 6
2022-07-22 18:40:09.161  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 7 (count at Application.java:136) with 1 output partitions
2022-07-22 18:40:09.161  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 14 (count at Application.java:136)
2022-07-22 18:40:09.161  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 13)
2022-07-22 18:40:09.161  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-22 18:40:09.164  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 14 (MapPartitionsRDD[103] at count at Application.java:136), which has no missing parents
2022-07-22 18:40:09.168  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_7 stored as values in memory (estimated size 11.0 KiB, free 892.3 MiB)
2022-07-22 18:40:09.171  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_7_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 892.3 MiB)
2022-07-22 18:40:09.172  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_7_piece0 in memory on host.docker.internal:63008 (size: 5.4 KiB, free: 892.5 MiB)
2022-07-22 18:40:09.173  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 7 from broadcast at DAGScheduler.scala:1478
2022-07-22 18:40:09.173  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[103] at count at Application.java:136) (first 15 tasks are for partitions Vector(0))
2022-07-22 18:40:09.173  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 14.0 with 1 tasks resource profile 0
2022-07-22 18:40:09.175  INFO   57 --- [er-event-loop-2] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 14.0 (TID 7) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-22 18:40:09.184  INFO   57 --- [ge 14.0 (TID 7)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 14.0 (TID 7)
2022-07-22 18:40:09.188  INFO   57 --- [ge 14.0 (TID 7)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-22 18:40:09.188  INFO   57 --- [ge 14.0 (TID 7)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-22 18:40:09.190  INFO   57 --- [ge 14.0 (TID 7)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 14.0 (TID 7). 2598 bytes result sent to driver
2022-07-22 18:40:09.191  INFO   57 --- [result-getter-2] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 14.0 (TID 7) in 16 ms on host.docker.internal (executor driver) (1/1)
2022-07-22 18:40:09.192  INFO   57 --- [result-getter-2] org.apache.spark.internal.Logging        : Removed TaskSet 14.0, whose tasks have all completed, from pool 
2022-07-22 18:40:09.192  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 14 (count at Application.java:136) finished in 0.027 s
2022-07-22 18:40:09.193  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-22 18:40:09.193  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 14: Stage finished
2022-07-22 18:40:09.194  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 7 finished: count at Application.java:136, took 0.034803 s
2022-07-22 18:40:09.199  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-22 18:40:09.199  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-22 18:40:09.201  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1658511596000 ms.0 from job set of time 1658511596000 ms
2022-07-22 18:40:09.201  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 13.201 s for time 1658511596000 ms (execution: 0.250 s)
2022-07-22 18:40:09.202  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1658511597000 ms.0 from job set of time 1658511597000 ms
2022-07-22 18:40:09.204  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 14 from persistence list
2022-07-22 18:40:09.212  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 13 from persistence list
2022-07-22 18:40:09.218  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[13] at receiverStream at Application.java:116 of time 1658511596000 ms
2022-07-22 18:40:09.219  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1658511594000 ms
2022-07-22 18:40:09.219  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1658511594000 ms
2022-07-22 18:40:09.234  INFO   57 --- [-thread-pool-55] org.apache.spark.internal.Logging        : Removing RDD 13
2022-07-22 18:40:09.236  INFO   57 --- [-thread-pool-54] org.apache.spark.internal.Logging        : Removing RDD 14
2022-07-22 18:40:09.365  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:136
2022-07-22 18:40:09.367  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 109 (count at Application.java:136) as input to shuffle 7
2022-07-22 18:40:09.367  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 8 (count at Application.java:136) with 1 output partitions
2022-07-22 18:40:09.368  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 16 (count at Application.java:136)
2022-07-22 18:40:09.368  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 15)
2022-07-22 18:40:09.368  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-22 18:40:09.369  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 16 (MapPartitionsRDD[112] at count at Application.java:136), which has no missing parents
2022-07-22 18:40:09.375  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_8 stored as values in memory (estimated size 11.0 KiB, free 892.3 MiB)
2022-07-22 18:40:09.378  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_8_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 892.3 MiB)
2022-07-22 18:40:09.380  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_8_piece0 in memory on host.docker.internal:63008 (size: 5.4 KiB, free: 892.5 MiB)
2022-07-22 18:40:09.381  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 8 from broadcast at DAGScheduler.scala:1478
2022-07-22 18:40:09.382  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[112] at count at Application.java:136) (first 15 tasks are for partitions Vector(0))
2022-07-22 18:40:09.382  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 16.0 with 1 tasks resource profile 0
2022-07-22 18:40:09.383  INFO   57 --- [er-event-loop-1] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 16.0 (TID 8) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-22 18:40:09.385  INFO   57 --- [ge 16.0 (TID 8)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 16.0 (TID 8)
2022-07-22 18:40:09.389  INFO   57 --- [ge 16.0 (TID 8)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-22 18:40:09.390  INFO   57 --- [ge 16.0 (TID 8)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-22 18:40:09.392  INFO   57 --- [ge 16.0 (TID 8)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 16.0 (TID 8). 2598 bytes result sent to driver
2022-07-22 18:40:09.393  INFO   57 --- [result-getter-3] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 16.0 (TID 8) in 10 ms on host.docker.internal (executor driver) (1/1)
2022-07-22 18:40:09.394  INFO   57 --- [result-getter-3] org.apache.spark.internal.Logging        : Removed TaskSet 16.0, whose tasks have all completed, from pool 
2022-07-22 18:40:09.395  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 16 (count at Application.java:136) finished in 0.024 s
2022-07-22 18:40:09.396  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-22 18:40:09.396  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 16: Stage finished
2022-07-22 18:40:09.397  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 8 finished: count at Application.java:136, took 0.030924 s
2022-07-22 18:40:09.402  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-22 18:40:09.402  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-22 18:40:09.405  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1658511597000 ms.0 from job set of time 1658511597000 ms
2022-07-22 18:40:09.406  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 12.405 s for time 1658511597000 ms (execution: 0.203 s)
2022-07-22 18:40:09.406  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1658511598000 ms.0 from job set of time 1658511598000 ms
2022-07-22 18:40:09.410  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 16 from persistence list
2022-07-22 18:40:09.417  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 15 from persistence list
2022-07-22 18:40:09.420  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[15] at receiverStream at Application.java:116 of time 1658511597000 ms
2022-07-22 18:40:09.420  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1658511595000 ms
2022-07-22 18:40:09.420  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1658511595000 ms
2022-07-22 18:40:09.433  INFO   57 --- [-thread-pool-60] org.apache.spark.internal.Logging        : Removing RDD 16
2022-07-22 18:40:09.434  INFO   57 --- [-thread-pool-61] org.apache.spark.internal.Logging        : Removing RDD 15
2022-07-22 18:40:09.534  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:136
2022-07-22 18:40:09.538  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 118 (count at Application.java:136) as input to shuffle 8
2022-07-22 18:40:09.539  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 9 (count at Application.java:136) with 1 output partitions
2022-07-22 18:40:09.539  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 18 (count at Application.java:136)
2022-07-22 18:40:09.539  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 17)
2022-07-22 18:40:09.539  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-22 18:40:09.540  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 18 (MapPartitionsRDD[121] at count at Application.java:136), which has no missing parents
2022-07-22 18:40:09.544  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_9 stored as values in memory (estimated size 11.0 KiB, free 892.3 MiB)
2022-07-22 18:40:09.560  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_9_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 892.3 MiB)
2022-07-22 18:40:09.561  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_9_piece0 in memory on host.docker.internal:63008 (size: 5.4 KiB, free: 892.5 MiB)
2022-07-22 18:40:09.564  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 9 from broadcast at DAGScheduler.scala:1478
2022-07-22 18:40:09.565  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[121] at count at Application.java:136) (first 15 tasks are for partitions Vector(0))
2022-07-22 18:40:09.565  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 18.0 with 1 tasks resource profile 0
2022-07-22 18:40:09.574  INFO   57 --- [er-event-loop-0] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 18.0 (TID 9) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-22 18:40:09.576  INFO   57 --- [ge 18.0 (TID 9)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 18.0 (TID 9)
2022-07-22 18:40:09.584  INFO   57 --- [ge 18.0 (TID 9)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-22 18:40:09.585  INFO   57 --- [ge 18.0 (TID 9)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 3 ms
2022-07-22 18:40:09.591  INFO   57 --- [ge 18.0 (TID 9)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 18.0 (TID 9). 2598 bytes result sent to driver
2022-07-22 18:40:09.593  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 18.0 (TID 9) in 26 ms on host.docker.internal (executor driver) (1/1)
2022-07-22 18:40:09.593  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Removed TaskSet 18.0, whose tasks have all completed, from pool 
2022-07-22 18:40:09.594  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 18 (count at Application.java:136) finished in 0.052 s
2022-07-22 18:40:09.595  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 9 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-22 18:40:09.599  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 18: Stage finished
2022-07-22 18:40:09.601  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 9 finished: count at Application.java:136, took 0.065173 s
2022-07-22 18:40:09.608  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-22 18:40:09.608  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-22 18:40:09.614  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1658511598000 ms.0 from job set of time 1658511598000 ms
2022-07-22 18:40:09.615  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 11.614 s for time 1658511598000 ms (execution: 0.208 s)
2022-07-22 18:40:09.625  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1658511599000 ms.0 from job set of time 1658511599000 ms
2022-07-22 18:40:09.633  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 18 from persistence list
2022-07-22 18:40:09.639  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 17 from persistence list
2022-07-22 18:40:09.641  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[17] at receiverStream at Application.java:116 of time 1658511598000 ms
2022-07-22 18:40:09.641  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1658511596000 ms
2022-07-22 18:40:09.641  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1658511596000 ms
2022-07-22 18:40:09.645  INFO   57 --- [-thread-pool-66] org.apache.spark.internal.Logging        : Removing RDD 18
2022-07-22 18:40:09.646  INFO   57 --- [-thread-pool-67] org.apache.spark.internal.Logging        : Removing RDD 17
2022-07-22 18:40:09.736  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:136
2022-07-22 18:40:09.737  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 127 (count at Application.java:136) as input to shuffle 9
2022-07-22 18:40:09.739  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 10 (count at Application.java:136) with 1 output partitions
2022-07-22 18:40:09.739  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 20 (count at Application.java:136)
2022-07-22 18:40:09.739  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 19)
2022-07-22 18:40:09.740  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-22 18:40:09.742  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 20 (MapPartitionsRDD[130] at count at Application.java:136), which has no missing parents
2022-07-22 18:40:09.751  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_10 stored as values in memory (estimated size 11.0 KiB, free 892.3 MiB)
2022-07-22 18:40:09.758  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_10_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 892.3 MiB)
2022-07-22 18:40:09.761  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_10_piece0 in memory on host.docker.internal:63008 (size: 5.4 KiB, free: 892.5 MiB)
2022-07-22 18:40:09.762  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 10 from broadcast at DAGScheduler.scala:1478
2022-07-22 18:40:09.763  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[130] at count at Application.java:136) (first 15 tasks are for partitions Vector(0))
2022-07-22 18:40:09.764  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 20.0 with 1 tasks resource profile 0
2022-07-22 18:40:09.765  INFO   57 --- [er-event-loop-3] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 20.0 (TID 10) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-22 18:40:09.766  INFO   57 --- [e 20.0 (TID 10)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 20.0 (TID 10)
2022-07-22 18:40:09.771  INFO   57 --- [e 20.0 (TID 10)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-22 18:40:09.772  INFO   57 --- [e 20.0 (TID 10)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 1 ms
2022-07-22 18:40:09.775  INFO   57 --- [e 20.0 (TID 10)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 20.0 (TID 10). 2555 bytes result sent to driver
2022-07-22 18:40:09.777  INFO   57 --- [result-getter-1] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 20.0 (TID 10) in 11 ms on host.docker.internal (executor driver) (1/1)
2022-07-22 18:40:09.777  INFO   57 --- [result-getter-1] org.apache.spark.internal.Logging        : Removed TaskSet 20.0, whose tasks have all completed, from pool 
2022-07-22 18:40:09.780  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 20 (count at Application.java:136) finished in 0.034 s
2022-07-22 18:40:09.781  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 10 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-22 18:40:09.782  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 20: Stage finished
2022-07-22 18:40:09.782  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 10 finished: count at Application.java:136, took 0.045393 s
2022-07-22 18:40:09.791  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-22 18:40:09.791  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-22 18:40:09.795  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1658511599000 ms.0 from job set of time 1658511599000 ms
2022-07-22 18:40:09.796  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 10.795 s for time 1658511599000 ms (execution: 0.180 s)
2022-07-22 18:40:09.797  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1658511600000 ms.0 from job set of time 1658511600000 ms
2022-07-22 18:40:09.799  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 20 from persistence list
2022-07-22 18:40:09.814  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 19 from persistence list
2022-07-22 18:40:09.821  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[19] at receiverStream at Application.java:116 of time 1658511599000 ms
2022-07-22 18:40:09.822  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1658511597000 ms
2022-07-22 18:40:09.822  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1658511597000 ms
2022-07-22 18:40:09.843  INFO   57 --- [-thread-pool-72] org.apache.spark.internal.Logging        : Removing RDD 20
2022-07-22 18:40:09.847  INFO   57 --- [-thread-pool-73] org.apache.spark.internal.Logging        : Removing RDD 19
2022-07-22 18:40:09.882  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: show at Application.java:135
2022-07-22 18:40:09.883  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 11 (show at Application.java:135) with 1 output partitions
2022-07-22 18:40:09.883  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 21 (show at Application.java:135)
2022-07-22 18:40:09.883  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List()
2022-07-22 18:40:09.884  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-22 18:40:09.900  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 21 (MapPartitionsRDD[134] at show at Application.java:135), which has no missing parents
2022-07-22 18:40:09.913  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_6_piece0 on host.docker.internal:63008 in memory (size: 5.4 KiB, free: 892.5 MiB)
2022-07-22 18:40:09.920  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_11 stored as values in memory (estimated size 12.9 KiB, free 892.3 MiB)
2022-07-22 18:40:09.951  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_9_piece0 on host.docker.internal:63008 in memory (size: 5.4 KiB, free: 892.5 MiB)
2022-07-22 18:40:09.957  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_11_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 892.3 MiB)
2022-07-22 18:40:09.958  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_11_piece0 in memory on host.docker.internal:63008 (size: 5.8 KiB, free: 892.5 MiB)
2022-07-22 18:40:09.959  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 11 from broadcast at DAGScheduler.scala:1478
2022-07-22 18:40:09.960  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 21 (MapPartitionsRDD[134] at show at Application.java:135) (first 15 tasks are for partitions Vector(0))
2022-07-22 18:40:09.960  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 21.0 with 1 tasks resource profile 0
2022-07-22 18:40:09.965  INFO   57 --- [er-event-loop-2] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 21.0 (TID 11) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
2022-07-22 18:40:09.966  INFO   57 --- [e 21.0 (TID 11)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 21.0 (TID 11)
2022-07-22 18:40:09.966  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_8_piece0 on host.docker.internal:63008 in memory (size: 5.4 KiB, free: 892.5 MiB)
2022-07-22 18:40:09.983  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_10_piece0 on host.docker.internal:63008 in memory (size: 5.4 KiB, free: 892.5 MiB)
2022-07-22 18:40:10.017  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1658511610000 ms
2022-07-22 18:40:10.021  INFO   57 --- [e 21.0 (TID 11)] org.apache.spark.internal.Logging        : Found block input-0-1658511595130 locally
2022-07-22 18:40:10.032  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_5_piece0 on host.docker.internal:63008 in memory (size: 5.4 KiB, free: 892.5 MiB)
2022-07-22 18:40:10.064  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_7_piece0 on host.docker.internal:63008 in memory (size: 5.4 KiB, free: 892.5 MiB)
2022-07-22 18:40:10.809  INFO   57 --- [e 21.0 (TID 11)] org.apache.spark.internal.Logging        : 1 block locks were not released by task 0.0 in stage 21.0 (TID 11)
[input-0-1658511595130]
2022-07-22 18:40:10.810  INFO   57 --- [e 21.0 (TID 11)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 21.0 (TID 11). 2167 bytes result sent to driver
2022-07-22 18:40:10.811  INFO   57 --- [result-getter-2] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 21.0 (TID 11) in 849 ms on host.docker.internal (executor driver) (1/1)
2022-07-22 18:40:10.812  INFO   57 --- [result-getter-2] org.apache.spark.internal.Logging        : Removed TaskSet 21.0, whose tasks have all completed, from pool 
2022-07-22 18:40:10.813  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 21 (show at Application.java:135) finished in 0.907 s
2022-07-22 18:40:10.813  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 11 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-22 18:40:10.813  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 21: Stage finished
2022-07-22 18:40:10.814  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 11 finished: show at Application.java:135, took 0.931524 s
2022-07-22 18:40:10.917  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Code generated in 46.2689 ms
2022-07-22 18:40:10.976  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 138 (count at Application.java:136) as input to shuffle 10
2022-07-22 18:40:10.977  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got map stage job 12 (count at Application.java:136) with 1 output partitions
2022-07-22 18:40:10.978  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ShuffleMapStage 22 (count at Application.java:136)
2022-07-22 18:40:10.978  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List()
2022-07-22 18:40:10.979  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-22 18:40:10.980  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ShuffleMapStage 22 (MapPartitionsRDD[138] at count at Application.java:136), which has no missing parents
2022-07-22 18:40:10.992  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_12 stored as values in memory (estimated size 13.6 KiB, free 892.4 MiB)
2022-07-22 18:40:11.002  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1658511611000 ms
2022-07-22 18:40:11.005  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_12_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 892.4 MiB)
2022-07-22 18:40:11.006  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_12_piece0 in memory on host.docker.internal:63008 (size: 6.7 KiB, free: 892.5 MiB)
2022-07-22 18:40:11.007  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 12 from broadcast at DAGScheduler.scala:1478
2022-07-22 18:40:11.008  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ShuffleMapStage 22 (MapPartitionsRDD[138] at count at Application.java:136) (first 15 tasks are for partitions Vector(0))
2022-07-22 18:40:11.009  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 22.0 with 1 tasks resource profile 0
2022-07-22 18:40:11.016  INFO   57 --- [er-event-loop-1] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 22.0 (TID 12) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4383 bytes) taskResourceAssignments Map()
2022-07-22 18:40:11.017  INFO   57 --- [e 22.0 (TID 12)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 22.0 (TID 12)
2022-07-22 18:40:11.062  INFO   57 --- [e 22.0 (TID 12)] org.apache.spark.internal.Logging        : Found block input-0-1658511595130 locally
2022-07-22 18:40:11.163  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_11_piece0 on host.docker.internal:63008 in memory (size: 5.8 KiB, free: 892.5 MiB)
2022-07-22 18:40:11.408  INFO   57 --- [e 22.0 (TID 12)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 22.0 (TID 12). 1924 bytes result sent to driver
2022-07-22 18:40:11.410  INFO   57 --- [result-getter-3] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 22.0 (TID 12) in 400 ms on host.docker.internal (executor driver) (1/1)
2022-07-22 18:40:11.410  INFO   57 --- [result-getter-3] org.apache.spark.internal.Logging        : Removed TaskSet 22.0, whose tasks have all completed, from pool 
2022-07-22 18:40:11.412  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ShuffleMapStage 22 (count at Application.java:136) finished in 0.428 s
2022-07-22 18:40:11.413  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : looking for newly runnable stages
2022-07-22 18:40:11.414  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : running: Set(ResultStage 0)
2022-07-22 18:40:11.415  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : waiting: Set()
2022-07-22 18:40:11.415  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : failed: Set()
2022-07-22 18:40:11.447  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:136
2022-07-22 18:40:11.449  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 13 (count at Application.java:136) with 1 output partitions
2022-07-22 18:40:11.449  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 24 (count at Application.java:136)
2022-07-22 18:40:11.449  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 23)
2022-07-22 18:40:11.449  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-22 18:40:11.450  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 24 (MapPartitionsRDD[143] at count at Application.java:136), which has no missing parents
2022-07-22 18:40:11.459  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_13 stored as values in memory (estimated size 11.0 KiB, free 892.4 MiB)
2022-07-22 18:40:11.462  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_13_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 892.4 MiB)
2022-07-22 18:40:11.464  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_13_piece0 in memory on host.docker.internal:63008 (size: 5.5 KiB, free: 892.5 MiB)
2022-07-22 18:40:11.464  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 13 from broadcast at DAGScheduler.scala:1478
2022-07-22 18:40:11.465  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 24 (MapPartitionsRDD[143] at count at Application.java:136) (first 15 tasks are for partitions Vector(0))
2022-07-22 18:40:11.465  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 24.0 with 1 tasks resource profile 0
2022-07-22 18:40:11.468  INFO   57 --- [er-event-loop-0] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 24.0 (TID 13) (host.docker.internal, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-22 18:40:11.469  INFO   57 --- [e 24.0 (TID 13)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 24.0 (TID 13)
2022-07-22 18:40:11.477  INFO   57 --- [e 24.0 (TID 13)] org.apache.spark.internal.Logging        : Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-22 18:40:11.478  INFO   57 --- [e 24.0 (TID 13)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 3 ms
2022-07-22 18:40:11.517  INFO   57 --- [e 24.0 (TID 13)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 24.0 (TID 13). 2605 bytes result sent to driver
2022-07-22 18:40:11.519  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 24.0 (TID 13) in 52 ms on host.docker.internal (executor driver) (1/1)
2022-07-22 18:40:11.519  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Removed TaskSet 24.0, whose tasks have all completed, from pool 
2022-07-22 18:40:11.521  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 24 (count at Application.java:136) finished in 0.063 s
2022-07-22 18:40:11.521  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 13 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-22 18:40:11.521  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 24: Stage finished
2022-07-22 18:40:11.522  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 13 finished: count at Application.java:136, took 0.074071 s
2022-07-22 18:40:12.002  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1658511612000 ms
2022-07-22 18:40:12.561  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_12_piece0 on host.docker.internal:63008 in memory (size: 6.7 KiB, free: 892.5 MiB)
2022-07-22 18:40:12.570  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_13_piece0 on host.docker.internal:63008 in memory (size: 5.5 KiB, free: 892.5 MiB)
2022-07-22 18:40:13.003  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1658511613000 ms
2022-07-22 18:40:14.002  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1658511614000 ms
2022-07-22 18:40:15.001  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1658511615000 ms
2022-07-22 18:40:15.133  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
2022-07-22 18:40:15.290  INFO  142 --- [-job-executor-0] mapreduce.lib.output.FileOutputCommitter : File Output Committer Algorithm version is 1
2022-07-22 18:40:15.291  INFO  157 --- [-job-executor-0] mapreduce.lib.output.FileOutputCommitter : FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2022-07-22 18:40:15.292  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2022-07-22 18:40:15.293  INFO  142 --- [-job-executor-0] mapreduce.lib.output.FileOutputCommitter : File Output Committer Algorithm version is 1
2022-07-22 18:40:15.293  INFO  157 --- [-job-executor-0] mapreduce.lib.output.FileOutputCommitter : FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2022-07-22 18:40:15.295  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2022-07-22 18:40:15.528  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: parquet at Application.java:137
2022-07-22 18:40:15.531  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 14 (parquet at Application.java:137) with 1 output partitions
2022-07-22 18:40:15.532  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 25 (parquet at Application.java:137)
2022-07-22 18:40:15.532  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List()
2022-07-22 18:40:15.532  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-22 18:40:15.534  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 25 (MapPartitionsRDD[152] at parquet at Application.java:137), which has no missing parents
2022-07-22 18:40:15.577  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_14 stored as values in memory (estimated size 206.8 KiB, free 892.2 MiB)
2022-07-22 18:40:15.583  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_14_piece0 stored as bytes in memory (estimated size 73.6 KiB, free 892.1 MiB)
2022-07-22 18:40:15.584  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_14_piece0 in memory on host.docker.internal:63008 (size: 73.6 KiB, free: 892.4 MiB)
2022-07-22 18:40:15.594  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 14 from broadcast at DAGScheduler.scala:1478
2022-07-22 18:40:15.598  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 25 (MapPartitionsRDD[152] at parquet at Application.java:137) (first 15 tasks are for partitions Vector(0))
2022-07-22 18:40:15.598  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 25.0 with 1 tasks resource profile 0
2022-07-22 18:40:15.600  INFO   57 --- [er-event-loop-3] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 25.0 (TID 14) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
2022-07-22 18:40:15.602  INFO   57 --- [e 25.0 (TID 14)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 25.0 (TID 14)
2022-07-22 18:40:15.662  INFO   57 --- [e 25.0 (TID 14)] org.apache.spark.internal.Logging        : Found block input-0-1658511595130 locally
2022-07-22 18:40:15.665  INFO  142 --- [e 25.0 (TID 14)] mapreduce.lib.output.FileOutputCommitter : File Output Committer Algorithm version is 1
2022-07-22 18:40:15.666  INFO  157 --- [e 25.0 (TID 14)] mapreduce.lib.output.FileOutputCommitter : FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2022-07-22 18:40:15.666  INFO   57 --- [e 25.0 (TID 14)] org.apache.spark.internal.Logging        : Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2022-07-22 18:40:15.667  INFO  142 --- [e 25.0 (TID 14)] mapreduce.lib.output.FileOutputCommitter : File Output Committer Algorithm version is 1
2022-07-22 18:40:15.668  INFO  157 --- [e 25.0 (TID 14)] mapreduce.lib.output.FileOutputCommitter : FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2022-07-22 18:40:15.668  INFO   57 --- [e 25.0 (TID 14)] org.apache.spark.internal.Logging        : Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2022-07-22 18:40:15.688  INFO   95 --- [e 25.0 (TID 14)] .apache.parquet.hadoop.codec.CodecConfig : Compression: SNAPPY
2022-07-22 18:40:15.692  INFO   95 --- [e 25.0 (TID 14)] .apache.parquet.hadoop.codec.CodecConfig : Compression: SNAPPY
2022-07-22 18:40:15.774  INFO  470 --- [e 25.0 (TID 14)] pache.parquet.hadoop.ParquetOutputFormat : Parquet block size to 134217728
2022-07-22 18:40:15.775  INFO  471 --- [e 25.0 (TID 14)] pache.parquet.hadoop.ParquetOutputFormat : Validation is off
2022-07-22 18:40:15.775  INFO  472 --- [e 25.0 (TID 14)] pache.parquet.hadoop.ParquetOutputFormat : Maximum row group padding size is 8388608 bytes
2022-07-22 18:40:15.775  INFO  473 --- [e 25.0 (TID 14)] pache.parquet.hadoop.ParquetOutputFormat : Parquet properties are:
Parquet page size to 1048576
Parquet dictionary page size to 1048576
Dictionary is true
Writer version is: PARQUET_1_0
Page size checking is: estimated
Min row count for page size check is: 100
Max row count for page size check is: 10000
Truncate length for column indexes is: 64
Truncate length for statistics min/max  is: 2147483647
Bloom filter enabled: false
Max Bloom filter size for a column is 1048576
Bloom filter expected number of distinct values are: null
Page row count limit to 20000
Writing page checksums is: on
2022-07-22 18:40:15.903  INFO   57 --- [e 25.0 (TID 14)] org.apache.spark.internal.Logging        : Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "answerTime",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "callType",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "calledNumber",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "callingNumber",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "imei",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "imsi",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "location",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "mscIncoming",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "mscOutgoing",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "msisdn",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary answerTime (STRING);
  optional binary callType (STRING);
  optional binary calledNumber (STRING);
  optional binary callingNumber (STRING);
  optional binary imei (STRING);
  optional binary imsi (STRING);
  optional binary location (STRING);
  optional binary mscIncoming (STRING);
  optional binary mscOutgoing (STRING);
  optional binary msisdn (STRING);
}

       
2022-07-22 18:40:16.004  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1658511616000 ms
2022-07-22 18:40:16.537  INFO  153 --- [e 25.0 (TID 14)] org.apache.hadoop.io.compress.CodecPool  : Got brand-new compressor [.snappy]
2022-07-22 18:40:17.001  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1658511617000 ms
2022-07-22 18:40:18.002  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1658511618000 ms
2022-07-22 18:40:19.015  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1658511619000 ms
2022-07-22 18:40:20.002  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1658511620000 ms
2022-07-22 18:40:21.002  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1658511621000 ms
2022-07-22 18:40:22.003  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1658511622000 ms
2022-07-22 18:40:22.878  INFO  604 --- [e 25.0 (TID 14)] mapreduce.lib.output.FileOutputCommitter : Saved output of task 'attempt_202207221840159099956321871008260_0025_m_000000_14' to hdfs://localhost:9000/user/dataFromSpark/file1/_temporary/0/task_202207221840159099956321871008260_0025_m_000000
2022-07-22 18:40:22.879  INFO   57 --- [e 25.0 (TID 14)] org.apache.spark.internal.Logging        : attempt_202207221840159099956321871008260_0025_m_000000_14: Committed
2022-07-22 18:40:22.974  INFO   57 --- [e 25.0 (TID 14)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 25.0 (TID 14). 2515 bytes result sent to driver
2022-07-22 18:40:22.976  INFO   57 --- [result-getter-1] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 25.0 (TID 14) in 7376 ms on host.docker.internal (executor driver) (1/1)
2022-07-22 18:40:22.977  INFO   57 --- [result-getter-1] org.apache.spark.internal.Logging        : Removed TaskSet 25.0, whose tasks have all completed, from pool 
2022-07-22 18:40:22.978  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 25 (parquet at Application.java:137) finished in 7.441 s
2022-07-22 18:40:22.978  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 14 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-22 18:40:22.979  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 25: Stage finished
2022-07-22 18:40:22.980  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 14 finished: parquet at Application.java:137, took 7.449544 s
2022-07-22 18:40:22.983  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Start to commit write Job 9d87795d-0762-499f-83cb-9b8a52ade501.
2022-07-22 18:40:23.003  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1658511623000 ms
2022-07-22 18:40:23.754  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Write Job 9d87795d-0762-499f-83cb-9b8a52ade501 committed. Elapsed time: 769 ms.
2022-07-22 18:40:23.758  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Finished processing stats for write job 9d87795d-0762-499f-83cb-9b8a52ade501.
2022-07-22 18:40:23.761  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1658511600000 ms.0 from job set of time 1658511600000 ms
2022-07-22 18:40:23.761  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 23.761 s for time 1658511600000 ms (execution: 13.964 s)
2022-07-22 18:40:23.762  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1658511601000 ms.0 from job set of time 1658511601000 ms
2022-07-22 18:40:23.762  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 22 from persistence list
2022-07-22 18:40:23.763  INFO   57 --- [-thread-pool-26] org.apache.spark.internal.Logging        : Removing RDD 22
2022-07-22 18:40:23.764  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 21 from persistence list
2022-07-22 18:40:23.765  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-22 18:40:23.765  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-22 18:40:23.766  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[21] at receiverStream at Application.java:116 of time 1658511600000 ms
2022-07-22 18:40:23.767  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1658511598000 ms
2022-07-22 18:40:23.767  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1658511598000 ms
2022-07-22 18:40:23.767  INFO   57 --- [-thread-pool-29] org.apache.spark.internal.Logging        : Removing RDD 21
2022-07-22 18:40:23.867  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:136
2022-07-22 18:40:23.869  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 174 (count at Application.java:136) as input to shuffle 11
2022-07-22 18:40:23.869  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 15 (count at Application.java:136) with 1 output partitions
2022-07-22 18:40:23.870  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 27 (count at Application.java:136)
2022-07-22 18:40:23.870  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 26)
2022-07-22 18:40:23.870  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-22 18:40:23.871  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 27 (MapPartitionsRDD[177] at count at Application.java:136), which has no missing parents
2022-07-22 18:40:23.874  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_15 stored as values in memory (estimated size 11.0 KiB, free 892.1 MiB)
2022-07-22 18:40:23.875  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_15_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 892.1 MiB)
2022-07-22 18:40:23.876  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_15_piece0 in memory on host.docker.internal:63008 (size: 5.4 KiB, free: 892.4 MiB)
2022-07-22 18:40:23.877  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 15 from broadcast at DAGScheduler.scala:1478
2022-07-22 18:40:23.878  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 27 (MapPartitionsRDD[177] at count at Application.java:136) (first 15 tasks are for partitions Vector(0))
2022-07-22 18:40:23.878  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 27.0 with 1 tasks resource profile 0
2022-07-22 18:40:23.880  INFO   57 --- [er-event-loop-1] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 27.0 (TID 15) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-22 18:40:23.881  INFO   57 --- [e 27.0 (TID 15)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 27.0 (TID 15)
2022-07-22 18:40:23.885  INFO   57 --- [e 27.0 (TID 15)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-22 18:40:23.885  INFO   57 --- [e 27.0 (TID 15)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-22 18:40:23.886  INFO   57 --- [e 27.0 (TID 15)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 27.0 (TID 15). 2555 bytes result sent to driver
2022-07-22 18:40:23.887  INFO   57 --- [result-getter-2] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 27.0 (TID 15) in 7 ms on host.docker.internal (executor driver) (1/1)
2022-07-22 18:40:23.887  INFO   57 --- [result-getter-2] org.apache.spark.internal.Logging        : Removed TaskSet 27.0, whose tasks have all completed, from pool 
2022-07-22 18:40:23.889  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 27 (count at Application.java:136) finished in 0.016 s
2022-07-22 18:40:23.889  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 15 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-22 18:40:23.889  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 27: Stage finished
2022-07-22 18:40:23.890  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 15 finished: count at Application.java:136, took 0.021762 s
2022-07-22 18:40:23.891  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1658511601000 ms.0 from job set of time 1658511601000 ms
2022-07-22 18:40:23.891  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 22.891 s for time 1658511601000 ms (execution: 0.129 s)
2022-07-22 18:40:23.892  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1658511602000 ms.0 from job set of time 1658511602000 ms
2022-07-22 18:40:23.894  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-22 18:40:23.895  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-22 18:40:23.894  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 24 from persistence list
2022-07-22 18:40:23.896  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 23 from persistence list
2022-07-22 18:40:23.897  INFO   57 --- [-thread-pool-32] org.apache.spark.internal.Logging        : Removing RDD 24
2022-07-22 18:40:23.899  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[23] at receiverStream at Application.java:116 of time 1658511601000 ms
2022-07-22 18:40:23.900  INFO   57 --- [-thread-pool-34] org.apache.spark.internal.Logging        : Removing RDD 23
2022-07-22 18:40:23.923  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1658511599000 ms
2022-07-22 18:40:23.923  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1658511599000 ms
2022-07-22 18:40:23.926  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed input-0-1658511595130 on host.docker.internal:63008 in memory (size: 5.1 MiB, free: 897.5 MiB)
2022-07-22 18:40:24.007  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1658511624000 ms
2022-07-22 18:40:24.023  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:136
2022-07-22 18:40:24.024  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 183 (count at Application.java:136) as input to shuffle 12
2022-07-22 18:40:24.025  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 16 (count at Application.java:136) with 1 output partitions
2022-07-22 18:40:24.025  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 29 (count at Application.java:136)
2022-07-22 18:40:24.025  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 28)
2022-07-22 18:40:24.025  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-22 18:40:24.026  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 29 (MapPartitionsRDD[188] at count at Application.java:136), which has no missing parents
2022-07-22 18:40:24.033  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_16 stored as values in memory (estimated size 11.0 KiB, free 897.2 MiB)
2022-07-22 18:40:24.039  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_16_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.2 MiB)
2022-07-22 18:40:24.040  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_16_piece0 in memory on host.docker.internal:63008 (size: 5.4 KiB, free: 897.5 MiB)
2022-07-22 18:40:24.041  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 16 from broadcast at DAGScheduler.scala:1478
2022-07-22 18:40:24.042  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 29 (MapPartitionsRDD[188] at count at Application.java:136) (first 15 tasks are for partitions Vector(0))
2022-07-22 18:40:24.042  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 29.0 with 1 tasks resource profile 0
2022-07-22 18:40:24.044  INFO   57 --- [er-event-loop-0] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 29.0 (TID 16) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-22 18:40:24.053  INFO   57 --- [e 29.0 (TID 16)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 29.0 (TID 16)
2022-07-22 18:40:24.058  INFO   57 --- [e 29.0 (TID 16)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-22 18:40:24.059  INFO   57 --- [e 29.0 (TID 16)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 1 ms
2022-07-22 18:40:24.064  INFO   57 --- [e 29.0 (TID 16)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 29.0 (TID 16). 2555 bytes result sent to driver
2022-07-22 18:40:24.067  INFO   57 --- [result-getter-3] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 29.0 (TID 16) in 24 ms on host.docker.internal (executor driver) (1/1)
2022-07-22 18:40:24.068  INFO   57 --- [result-getter-3] org.apache.spark.internal.Logging        : Removed TaskSet 29.0, whose tasks have all completed, from pool 
2022-07-22 18:40:24.070  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 29 (count at Application.java:136) finished in 0.042 s
2022-07-22 18:40:24.070  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 16 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-22 18:40:24.070  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 29: Stage finished
2022-07-22 18:40:24.071  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 16 finished: count at Application.java:136, took 0.047587 s
2022-07-22 18:40:24.072  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1658511602000 ms.0 from job set of time 1658511602000 ms
2022-07-22 18:40:24.072  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 22.072 s for time 1658511602000 ms (execution: 0.180 s)
2022-07-22 18:40:24.073  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1658511603000 ms.0 from job set of time 1658511603000 ms
2022-07-22 18:40:24.073  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 26 from persistence list
2022-07-22 18:40:24.074  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 25 from persistence list
2022-07-22 18:40:24.074  INFO   57 --- [-thread-pool-39] org.apache.spark.internal.Logging        : Removing RDD 26
2022-07-22 18:40:24.075  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-22 18:40:24.075  INFO   57 --- [-thread-pool-43] org.apache.spark.internal.Logging        : Removing RDD 25
2022-07-22 18:40:24.075  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[25] at receiverStream at Application.java:116 of time 1658511602000 ms
2022-07-22 18:40:24.075  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-22 18:40:24.076  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1658511600000 ms
2022-07-22 18:40:24.076  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1658511600000 ms
2022-07-22 18:40:24.182  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:136
2022-07-22 18:40:24.183  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 194 (count at Application.java:136) as input to shuffle 13
2022-07-22 18:40:24.184  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 17 (count at Application.java:136) with 1 output partitions
2022-07-22 18:40:24.184  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 31 (count at Application.java:136)
2022-07-22 18:40:24.184  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 30)
2022-07-22 18:40:24.185  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-22 18:40:24.185  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 31 (MapPartitionsRDD[197] at count at Application.java:136), which has no missing parents
2022-07-22 18:40:24.187  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_17 stored as values in memory (estimated size 11.0 KiB, free 897.2 MiB)
2022-07-22 18:40:24.190  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_17_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.1 MiB)
2022-07-22 18:40:24.190  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_17_piece0 in memory on host.docker.internal:63008 (size: 5.4 KiB, free: 897.5 MiB)
2022-07-22 18:40:24.191  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 17 from broadcast at DAGScheduler.scala:1478
2022-07-22 18:40:24.192  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 31 (MapPartitionsRDD[197] at count at Application.java:136) (first 15 tasks are for partitions Vector(0))
2022-07-22 18:40:24.192  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 31.0 with 1 tasks resource profile 0
2022-07-22 18:40:24.193  INFO   57 --- [er-event-loop-3] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 31.0 (TID 17) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-22 18:40:24.194  INFO   57 --- [e 31.0 (TID 17)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 31.0 (TID 17)
2022-07-22 18:40:24.198  INFO   57 --- [e 31.0 (TID 17)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-22 18:40:24.199  INFO   57 --- [e 31.0 (TID 17)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-22 18:40:24.200  INFO   57 --- [e 31.0 (TID 17)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 31.0 (TID 17). 2555 bytes result sent to driver
2022-07-22 18:40:24.203  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 31.0 (TID 17) in 10 ms on host.docker.internal (executor driver) (1/1)
2022-07-22 18:40:24.203  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Removed TaskSet 31.0, whose tasks have all completed, from pool 
2022-07-22 18:40:24.204  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 31 (count at Application.java:136) finished in 0.018 s
2022-07-22 18:40:24.204  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 17 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-22 18:40:24.205  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 31: Stage finished
2022-07-22 18:40:24.206  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 17 finished: count at Application.java:136, took 0.023769 s
2022-07-22 18:40:24.207  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1658511603000 ms.0 from job set of time 1658511603000 ms
2022-07-22 18:40:24.208  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 21.207 s for time 1658511603000 ms (execution: 0.134 s)
2022-07-22 18:40:24.208  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1658511604000 ms.0 from job set of time 1658511604000 ms
2022-07-22 18:40:24.210  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-22 18:40:24.210  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-22 18:40:24.212  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 28 from persistence list
2022-07-22 18:40:24.213  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 27 from persistence list
2022-07-22 18:40:24.214  INFO   57 --- [-thread-pool-47] org.apache.spark.internal.Logging        : Removing RDD 28
2022-07-22 18:40:24.216  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[27] at receiverStream at Application.java:116 of time 1658511603000 ms
2022-07-22 18:40:24.229  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1658511601000 ms
2022-07-22 18:40:24.229  INFO   57 --- [-thread-pool-50] org.apache.spark.internal.Logging        : Removing RDD 27
2022-07-22 18:40:24.230  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1658511601000 ms
2022-07-22 18:40:24.385  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:136
2022-07-22 18:40:24.387  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 203 (count at Application.java:136) as input to shuffle 14
2022-07-22 18:40:24.388  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 18 (count at Application.java:136) with 1 output partitions
2022-07-22 18:40:24.388  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 33 (count at Application.java:136)
2022-07-22 18:40:24.388  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 32)
2022-07-22 18:40:24.388  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-22 18:40:24.389  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 33 (MapPartitionsRDD[206] at count at Application.java:136), which has no missing parents
2022-07-22 18:40:24.394  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_18 stored as values in memory (estimated size 11.0 KiB, free 897.1 MiB)
2022-07-22 18:40:24.397  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_18_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.1 MiB)
2022-07-22 18:40:24.398  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_18_piece0 in memory on host.docker.internal:63008 (size: 5.4 KiB, free: 897.5 MiB)
2022-07-22 18:40:24.399  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 18 from broadcast at DAGScheduler.scala:1478
2022-07-22 18:40:24.404  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 33 (MapPartitionsRDD[206] at count at Application.java:136) (first 15 tasks are for partitions Vector(0))
2022-07-22 18:40:24.404  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 33.0 with 1 tasks resource profile 0
2022-07-22 18:40:24.406  INFO   57 --- [er-event-loop-2] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 33.0 (TID 18) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-22 18:40:24.407  INFO   57 --- [e 33.0 (TID 18)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 33.0 (TID 18)
2022-07-22 18:40:24.411  INFO   57 --- [e 33.0 (TID 18)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-22 18:40:24.411  INFO   57 --- [e 33.0 (TID 18)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-22 18:40:24.413  INFO   57 --- [e 33.0 (TID 18)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 33.0 (TID 18). 2555 bytes result sent to driver
2022-07-22 18:40:24.415  INFO   57 --- [result-getter-1] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 33.0 (TID 18) in 9 ms on host.docker.internal (executor driver) (1/1)
2022-07-22 18:40:24.415  INFO   57 --- [result-getter-1] org.apache.spark.internal.Logging        : Removed TaskSet 33.0, whose tasks have all completed, from pool 
2022-07-22 18:40:24.416  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 33 (count at Application.java:136) finished in 0.026 s
2022-07-22 18:40:24.417  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 18 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-22 18:40:24.417  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 33: Stage finished
2022-07-22 18:40:24.418  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 18 finished: count at Application.java:136, took 0.032261 s
2022-07-22 18:40:24.428  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-22 18:40:24.428  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-22 18:40:24.437  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1658511604000 ms.0 from job set of time 1658511604000 ms
2022-07-22 18:40:24.440  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 20.433 s for time 1658511604000 ms (execution: 0.225 s)
2022-07-22 18:40:24.440  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1658511605000 ms.0 from job set of time 1658511605000 ms
2022-07-22 18:40:24.484  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 30 from persistence list
2022-07-22 18:40:24.493  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 29 from persistence list
2022-07-22 18:40:24.494  INFO   57 --- [-thread-pool-53] org.apache.spark.internal.Logging        : Removing RDD 30
2022-07-22 18:40:24.498  INFO   57 --- [-thread-pool-54] org.apache.spark.internal.Logging        : Removing RDD 29
2022-07-22 18:40:24.498  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[29] at receiverStream at Application.java:116 of time 1658511604000 ms
2022-07-22 18:40:24.499  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1658511602000 ms
2022-07-22 18:40:24.499  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1658511602000 ms
2022-07-22 18:40:24.586  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:136
2022-07-22 18:40:24.587  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 212 (count at Application.java:136) as input to shuffle 15
2022-07-22 18:40:24.588  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 19 (count at Application.java:136) with 1 output partitions
2022-07-22 18:40:24.588  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 35 (count at Application.java:136)
2022-07-22 18:40:24.588  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 34)
2022-07-22 18:40:24.588  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-22 18:40:24.589  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 35 (MapPartitionsRDD[215] at count at Application.java:136), which has no missing parents
2022-07-22 18:40:24.591  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_19 stored as values in memory (estimated size 11.0 KiB, free 897.1 MiB)
2022-07-22 18:40:24.597  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_19_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.1 MiB)
2022-07-22 18:40:24.598  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_19_piece0 in memory on host.docker.internal:63008 (size: 5.4 KiB, free: 897.5 MiB)
2022-07-22 18:40:24.599  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 19 from broadcast at DAGScheduler.scala:1478
2022-07-22 18:40:24.600  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 35 (MapPartitionsRDD[215] at count at Application.java:136) (first 15 tasks are for partitions Vector(0))
2022-07-22 18:40:24.600  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 35.0 with 1 tasks resource profile 0
2022-07-22 18:40:24.601  INFO   57 --- [er-event-loop-1] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 35.0 (TID 19) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-22 18:40:24.602  INFO   57 --- [e 35.0 (TID 19)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 35.0 (TID 19)
2022-07-22 18:40:24.607  INFO   57 --- [e 35.0 (TID 19)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-22 18:40:24.607  INFO   57 --- [e 35.0 (TID 19)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-22 18:40:24.608  INFO   57 --- [e 35.0 (TID 19)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 35.0 (TID 19). 2555 bytes result sent to driver
2022-07-22 18:40:24.609  INFO   57 --- [result-getter-2] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 35.0 (TID 19) in 8 ms on host.docker.internal (executor driver) (1/1)
2022-07-22 18:40:24.609  INFO   57 --- [result-getter-2] org.apache.spark.internal.Logging        : Removed TaskSet 35.0, whose tasks have all completed, from pool 
2022-07-22 18:40:24.612  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 35 (count at Application.java:136) finished in 0.022 s
2022-07-22 18:40:24.613  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 19 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-22 18:40:24.613  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 35: Stage finished
2022-07-22 18:40:24.616  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 19 finished: count at Application.java:136, took 0.029185 s
2022-07-22 18:40:24.622  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1658511605000 ms.0 from job set of time 1658511605000 ms
2022-07-22 18:40:24.623  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 19.622 s for time 1658511605000 ms (execution: 0.182 s)
2022-07-22 18:40:24.623  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1658511606000 ms.0 from job set of time 1658511606000 ms
2022-07-22 18:40:24.625  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 32 from persistence list
2022-07-22 18:40:24.625  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-22 18:40:24.625  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-22 18:40:24.626  INFO   57 --- [-thread-pool-59] org.apache.spark.internal.Logging        : Removing RDD 32
2022-07-22 18:40:24.626  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 31 from persistence list
2022-07-22 18:40:24.627  INFO   57 --- [-thread-pool-63] org.apache.spark.internal.Logging        : Removing RDD 31
2022-07-22 18:40:24.627  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[31] at receiverStream at Application.java:116 of time 1658511605000 ms
2022-07-22 18:40:24.628  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1658511603000 ms
2022-07-22 18:40:24.628  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1658511603000 ms
2022-07-22 18:40:24.756  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:136
2022-07-22 18:40:24.757  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 221 (count at Application.java:136) as input to shuffle 16
2022-07-22 18:40:24.758  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 20 (count at Application.java:136) with 1 output partitions
2022-07-22 18:40:24.758  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 37 (count at Application.java:136)
2022-07-22 18:40:24.758  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 36)
2022-07-22 18:40:24.758  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-22 18:40:24.759  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 37 (MapPartitionsRDD[224] at count at Application.java:136), which has no missing parents
2022-07-22 18:40:24.764  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_20 stored as values in memory (estimated size 11.0 KiB, free 897.1 MiB)
2022-07-22 18:40:24.767  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_20_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.1 MiB)
2022-07-22 18:40:24.768  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_20_piece0 in memory on host.docker.internal:63008 (size: 5.4 KiB, free: 897.5 MiB)
2022-07-22 18:40:24.769  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 20 from broadcast at DAGScheduler.scala:1478
2022-07-22 18:40:24.770  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 37 (MapPartitionsRDD[224] at count at Application.java:136) (first 15 tasks are for partitions Vector(0))
2022-07-22 18:40:24.770  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 37.0 with 1 tasks resource profile 0
2022-07-22 18:40:24.771  INFO   57 --- [er-event-loop-0] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 37.0 (TID 20) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-22 18:40:24.772  INFO   57 --- [e 37.0 (TID 20)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 37.0 (TID 20)
2022-07-22 18:40:24.776  INFO   57 --- [e 37.0 (TID 20)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-22 18:40:24.776  INFO   57 --- [e 37.0 (TID 20)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-22 18:40:24.778  INFO   57 --- [e 37.0 (TID 20)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 37.0 (TID 20). 2555 bytes result sent to driver
2022-07-22 18:40:24.782  INFO   57 --- [result-getter-3] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 37.0 (TID 20) in 11 ms on host.docker.internal (executor driver) (1/1)
2022-07-22 18:40:24.782  INFO   57 --- [result-getter-3] org.apache.spark.internal.Logging        : Removed TaskSet 37.0, whose tasks have all completed, from pool 
2022-07-22 18:40:24.783  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 37 (count at Application.java:136) finished in 0.023 s
2022-07-22 18:40:24.783  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 20 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-22 18:40:24.783  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 37: Stage finished
2022-07-22 18:40:24.785  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 20 finished: count at Application.java:136, took 0.028464 s
2022-07-22 18:40:24.786  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1658511606000 ms.0 from job set of time 1658511606000 ms
2022-07-22 18:40:24.786  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 18.786 s for time 1658511606000 ms (execution: 0.163 s)
2022-07-22 18:40:24.787  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1658511607000 ms.0 from job set of time 1658511607000 ms
2022-07-22 18:40:24.789  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-22 18:40:24.789  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-22 18:40:24.789  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 34 from persistence list
2022-07-22 18:40:24.794  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 33 from persistence list
2022-07-22 18:40:24.795  INFO   57 --- [-thread-pool-65] org.apache.spark.internal.Logging        : Removing RDD 34
2022-07-22 18:40:24.796  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[33] at receiverStream at Application.java:116 of time 1658511606000 ms
2022-07-22 18:40:24.797  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1658511604000 ms
2022-07-22 18:40:24.797  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1658511604000 ms
2022-07-22 18:40:24.797  INFO   57 --- [-thread-pool-69] org.apache.spark.internal.Logging        : Removing RDD 33
2022-07-22 18:40:24.869  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:136
2022-07-22 18:40:24.870  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 230 (count at Application.java:136) as input to shuffle 17
2022-07-22 18:40:24.871  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 21 (count at Application.java:136) with 1 output partitions
2022-07-22 18:40:24.871  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 39 (count at Application.java:136)
2022-07-22 18:40:24.871  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 38)
2022-07-22 18:40:24.871  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-22 18:40:24.872  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 39 (MapPartitionsRDD[233] at count at Application.java:136), which has no missing parents
2022-07-22 18:40:24.875  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_21 stored as values in memory (estimated size 11.0 KiB, free 897.1 MiB)
2022-07-22 18:40:24.878  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_21_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.1 MiB)
2022-07-22 18:40:24.886  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_21_piece0 in memory on host.docker.internal:63008 (size: 5.4 KiB, free: 897.5 MiB)
2022-07-22 18:40:24.887  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 21 from broadcast at DAGScheduler.scala:1478
2022-07-22 18:40:24.888  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 39 (MapPartitionsRDD[233] at count at Application.java:136) (first 15 tasks are for partitions Vector(0))
2022-07-22 18:40:24.889  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 39.0 with 1 tasks resource profile 0
2022-07-22 18:40:24.890  INFO   57 --- [er-event-loop-3] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 39.0 (TID 21) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-22 18:40:24.891  INFO   57 --- [e 39.0 (TID 21)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 39.0 (TID 21)
2022-07-22 18:40:24.895  INFO   57 --- [e 39.0 (TID 21)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-22 18:40:24.895  INFO   57 --- [e 39.0 (TID 21)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 1 ms
2022-07-22 18:40:24.897  INFO   57 --- [e 39.0 (TID 21)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 39.0 (TID 21). 2555 bytes result sent to driver
2022-07-22 18:40:24.898  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 39.0 (TID 21) in 8 ms on host.docker.internal (executor driver) (1/1)
2022-07-22 18:40:24.899  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Removed TaskSet 39.0, whose tasks have all completed, from pool 
2022-07-22 18:40:24.899  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 39 (count at Application.java:136) finished in 0.026 s
2022-07-22 18:40:24.900  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 21 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-22 18:40:24.900  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 39: Stage finished
2022-07-22 18:40:24.900  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 21 finished: count at Application.java:136, took 0.030906 s
2022-07-22 18:40:24.901  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1658511607000 ms.0 from job set of time 1658511607000 ms
2022-07-22 18:40:24.902  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 17.901 s for time 1658511607000 ms (execution: 0.115 s)
2022-07-22 18:40:24.902  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1658511608000 ms.0 from job set of time 1658511608000 ms
2022-07-22 18:40:24.903  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 36 from persistence list
2022-07-22 18:40:24.904  INFO   57 --- [-thread-pool-71] org.apache.spark.internal.Logging        : Removing RDD 36
2022-07-22 18:40:24.904  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 35 from persistence list
2022-07-22 18:40:24.905  INFO   57 --- [-thread-pool-75] org.apache.spark.internal.Logging        : Removing RDD 35
2022-07-22 18:40:24.905  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-22 18:40:24.905  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-22 18:40:24.905  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[35] at receiverStream at Application.java:116 of time 1658511607000 ms
2022-07-22 18:40:24.906  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1658511605000 ms
2022-07-22 18:40:24.906  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1658511605000 ms
2022-07-22 18:40:25.003  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1658511625000 ms
2022-07-22 18:40:25.035  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:136
2022-07-22 18:40:25.036  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 241 (count at Application.java:136) as input to shuffle 18
2022-07-22 18:40:25.037  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 22 (count at Application.java:136) with 1 output partitions
2022-07-22 18:40:25.037  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 41 (count at Application.java:136)
2022-07-22 18:40:25.037  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 40)
2022-07-22 18:40:25.038  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-22 18:40:25.038  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 41 (MapPartitionsRDD[244] at count at Application.java:136), which has no missing parents
2022-07-22 18:40:25.041  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_22 stored as values in memory (estimated size 11.0 KiB, free 897.1 MiB)
2022-07-22 18:40:25.044  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_22_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.1 MiB)
2022-07-22 18:40:25.045  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_22_piece0 in memory on host.docker.internal:63008 (size: 5.4 KiB, free: 897.5 MiB)
2022-07-22 18:40:25.046  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 22 from broadcast at DAGScheduler.scala:1478
2022-07-22 18:40:25.047  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 41 (MapPartitionsRDD[244] at count at Application.java:136) (first 15 tasks are for partitions Vector(0))
2022-07-22 18:40:25.047  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 41.0 with 1 tasks resource profile 0
2022-07-22 18:40:25.049  INFO   57 --- [er-event-loop-2] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 41.0 (TID 22) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-22 18:40:25.050  INFO   57 --- [e 41.0 (TID 22)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 41.0 (TID 22)
2022-07-22 18:40:25.053  INFO   57 --- [e 41.0 (TID 22)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-22 18:40:25.054  INFO   57 --- [e 41.0 (TID 22)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-22 18:40:25.055  INFO   57 --- [e 41.0 (TID 22)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 41.0 (TID 22). 2555 bytes result sent to driver
2022-07-22 18:40:25.056  INFO   57 --- [result-getter-1] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 41.0 (TID 22) in 8 ms on host.docker.internal (executor driver) (1/1)
2022-07-22 18:40:25.056  INFO   57 --- [result-getter-1] org.apache.spark.internal.Logging        : Removed TaskSet 41.0, whose tasks have all completed, from pool 
2022-07-22 18:40:25.057  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 41 (count at Application.java:136) finished in 0.018 s
2022-07-22 18:40:25.058  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 22 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-22 18:40:25.058  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 41: Stage finished
2022-07-22 18:40:25.058  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 22 finished: count at Application.java:136, took 0.022845 s
2022-07-22 18:40:25.059  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1658511608000 ms.0 from job set of time 1658511608000 ms
2022-07-22 18:40:25.060  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 17.059 s for time 1658511608000 ms (execution: 0.157 s)
2022-07-22 18:40:25.060  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1658511609000 ms.0 from job set of time 1658511609000 ms
2022-07-22 18:40:25.064  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-22 18:40:25.064  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-22 18:40:25.064  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 40 from persistence list
2022-07-22 18:40:25.066  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 39 from persistence list
2022-07-22 18:40:25.066  INFO   57 --- [-thread-pool-77] org.apache.spark.internal.Logging        : Removing RDD 40
2022-07-22 18:40:25.070  INFO   57 --- [-thread-pool-79] org.apache.spark.internal.Logging        : Removing RDD 39
2022-07-22 18:40:25.071  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[39] at receiverStream at Application.java:116 of time 1658511608000 ms
2022-07-22 18:40:25.071  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1658511606000 ms
2022-07-22 18:40:25.072  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1658511606000 ms
2022-07-22 18:40:25.200  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:136
2022-07-22 18:40:25.202  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 250 (count at Application.java:136) as input to shuffle 19
2022-07-22 18:40:25.202  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 23 (count at Application.java:136) with 1 output partitions
2022-07-22 18:40:25.203  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 43 (count at Application.java:136)
2022-07-22 18:40:25.203  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 42)
2022-07-22 18:40:25.203  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-22 18:40:25.205  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 43 (MapPartitionsRDD[253] at count at Application.java:136), which has no missing parents
2022-07-22 18:40:25.207  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_23 stored as values in memory (estimated size 11.0 KiB, free 897.1 MiB)
2022-07-22 18:40:25.211  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_23_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.1 MiB)
2022-07-22 18:40:25.215  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_23_piece0 in memory on host.docker.internal:63008 (size: 5.4 KiB, free: 897.4 MiB)
2022-07-22 18:40:25.217  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 23 from broadcast at DAGScheduler.scala:1478
2022-07-22 18:40:25.217  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 43 (MapPartitionsRDD[253] at count at Application.java:136) (first 15 tasks are for partitions Vector(0))
2022-07-22 18:40:25.218  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 43.0 with 1 tasks resource profile 0
2022-07-22 18:40:25.219  INFO   57 --- [er-event-loop-1] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 43.0 (TID 23) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-22 18:40:25.220  INFO   57 --- [e 43.0 (TID 23)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 43.0 (TID 23)
2022-07-22 18:40:25.223  INFO   57 --- [e 43.0 (TID 23)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-22 18:40:25.224  INFO   57 --- [e 43.0 (TID 23)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 1 ms
2022-07-22 18:40:25.226  INFO   57 --- [e 43.0 (TID 23)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 43.0 (TID 23). 2555 bytes result sent to driver
2022-07-22 18:40:25.228  INFO   57 --- [result-getter-2] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 43.0 (TID 23) in 10 ms on host.docker.internal (executor driver) (1/1)
2022-07-22 18:40:25.231  INFO   57 --- [result-getter-2] org.apache.spark.internal.Logging        : Removed TaskSet 43.0, whose tasks have all completed, from pool 
2022-07-22 18:40:25.232  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 43 (count at Application.java:136) finished in 0.025 s
2022-07-22 18:40:25.232  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 23 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-22 18:40:25.233  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 43: Stage finished
2022-07-22 18:40:25.233  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 23 finished: count at Application.java:136, took 0.032369 s
2022-07-22 18:40:25.234  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1658511609000 ms.0 from job set of time 1658511609000 ms
2022-07-22 18:40:25.235  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 16.234 s for time 1658511609000 ms (execution: 0.174 s)
2022-07-22 18:40:25.235  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1658511610000 ms.0 from job set of time 1658511610000 ms
2022-07-22 18:40:25.237  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-22 18:40:25.237  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-22 18:40:25.237  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 60 from persistence list
2022-07-22 18:40:25.239  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 59 from persistence list
2022-07-22 18:40:25.240  INFO   57 --- [-thread-pool-83] org.apache.spark.internal.Logging        : Removing RDD 60
2022-07-22 18:40:25.240  INFO   57 --- [-thread-pool-86] org.apache.spark.internal.Logging        : Removing RDD 59
2022-07-22 18:40:25.241  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[59] at receiverStream at Application.java:116 of time 1658511609000 ms
2022-07-22 18:40:25.249  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1658511607000 ms
2022-07-22 18:40:25.249  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1658511607000 ms
2022-07-22 18:40:25.380  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:136
2022-07-22 18:40:25.381  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 259 (count at Application.java:136) as input to shuffle 20
2022-07-22 18:40:25.383  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 24 (count at Application.java:136) with 1 output partitions
2022-07-22 18:40:25.384  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 45 (count at Application.java:136)
2022-07-22 18:40:25.384  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 44)
2022-07-22 18:40:25.385  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-22 18:40:25.386  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 45 (MapPartitionsRDD[262] at count at Application.java:136), which has no missing parents
2022-07-22 18:40:25.390  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_24 stored as values in memory (estimated size 11.0 KiB, free 897.0 MiB)
2022-07-22 18:40:25.406  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_24_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.0 MiB)
2022-07-22 18:40:25.408  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_24_piece0 in memory on host.docker.internal:63008 (size: 5.4 KiB, free: 897.4 MiB)
2022-07-22 18:40:25.409  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 24 from broadcast at DAGScheduler.scala:1478
2022-07-22 18:40:25.410  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 45 (MapPartitionsRDD[262] at count at Application.java:136) (first 15 tasks are for partitions Vector(0))
2022-07-22 18:40:25.411  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 45.0 with 1 tasks resource profile 0
2022-07-22 18:40:25.415  INFO   57 --- [er-event-loop-0] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 45.0 (TID 24) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-22 18:40:25.417  INFO   57 --- [e 45.0 (TID 24)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 45.0 (TID 24)
2022-07-22 18:40:25.428  INFO   57 --- [e 45.0 (TID 24)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-22 18:40:25.428  INFO   57 --- [e 45.0 (TID 24)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-22 18:40:25.434  INFO   57 --- [e 45.0 (TID 24)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 45.0 (TID 24). 2555 bytes result sent to driver
2022-07-22 18:40:25.437  INFO   57 --- [result-getter-3] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 45.0 (TID 24) in 22 ms on host.docker.internal (executor driver) (1/1)
2022-07-22 18:40:25.438  INFO   57 --- [result-getter-3] org.apache.spark.internal.Logging        : Removed TaskSet 45.0, whose tasks have all completed, from pool 
2022-07-22 18:40:25.438  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 45 (count at Application.java:136) finished in 0.051 s
2022-07-22 18:40:25.439  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 24 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-22 18:40:25.439  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 45: Stage finished
2022-07-22 18:40:25.440  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 24 finished: count at Application.java:136, took 0.058920 s
2022-07-22 18:40:25.450  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-22 18:40:25.451  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-22 18:40:25.452  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1658511610000 ms.0 from job set of time 1658511610000 ms
2022-07-22 18:40:25.456  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 15.452 s for time 1658511610000 ms (execution: 0.217 s)
2022-07-22 18:40:25.456  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1658511611000 ms.0 from job set of time 1658511611000 ms
2022-07-22 18:40:25.457  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 96 from persistence list
2022-07-22 18:40:25.457  INFO   57 --- [-thread-pool-89] org.apache.spark.internal.Logging        : Removing RDD 96
2022-07-22 18:40:25.458  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 95 from persistence list
2022-07-22 18:40:25.458  INFO   57 --- [-thread-pool-91] org.apache.spark.internal.Logging        : Removing RDD 95
2022-07-22 18:40:25.459  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[95] at receiverStream at Application.java:116 of time 1658511610000 ms
2022-07-22 18:40:25.459  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1658511608000 ms
2022-07-22 18:40:25.459  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1658511608000 ms
2022-07-22 18:40:25.555  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_16_piece0 on host.docker.internal:63008 in memory (size: 5.4 KiB, free: 897.4 MiB)
2022-07-22 18:40:25.558  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:136
2022-07-22 18:40:25.559  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 268 (count at Application.java:136) as input to shuffle 21
2022-07-22 18:40:25.560  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_23_piece0 on host.docker.internal:63008 in memory (size: 5.4 KiB, free: 897.5 MiB)
2022-07-22 18:40:25.560  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 25 (count at Application.java:136) with 1 output partitions
2022-07-22 18:40:25.560  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 47 (count at Application.java:136)
2022-07-22 18:40:25.561  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 46)
2022-07-22 18:40:25.561  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-22 18:40:25.561  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 47 (MapPartitionsRDD[271] at count at Application.java:136), which has no missing parents
2022-07-22 18:40:25.564  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_25 stored as values in memory (estimated size 11.0 KiB, free 897.1 MiB)
2022-07-22 18:40:25.568  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_25_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.1 MiB)
2022-07-22 18:40:25.568  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_18_piece0 on host.docker.internal:63008 in memory (size: 5.4 KiB, free: 897.5 MiB)
2022-07-22 18:40:25.569  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_25_piece0 in memory on host.docker.internal:63008 (size: 5.4 KiB, free: 897.5 MiB)
2022-07-22 18:40:25.569  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 25 from broadcast at DAGScheduler.scala:1478
2022-07-22 18:40:25.570  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 47 (MapPartitionsRDD[271] at count at Application.java:136) (first 15 tasks are for partitions Vector(0))
2022-07-22 18:40:25.570  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 47.0 with 1 tasks resource profile 0
2022-07-22 18:40:25.572  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_24_piece0 on host.docker.internal:63008 in memory (size: 5.4 KiB, free: 897.5 MiB)
2022-07-22 18:40:25.572  INFO   57 --- [er-event-loop-3] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 47.0 (TID 25) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-22 18:40:25.573  INFO   57 --- [e 47.0 (TID 25)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 47.0 (TID 25)
2022-07-22 18:40:25.575  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_17_piece0 on host.docker.internal:63008 in memory (size: 5.4 KiB, free: 897.5 MiB)
2022-07-22 18:40:25.577  INFO   57 --- [e 47.0 (TID 25)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-22 18:40:25.577  INFO   57 --- [e 47.0 (TID 25)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-22 18:40:25.580  INFO   57 --- [e 47.0 (TID 25)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 47.0 (TID 25). 2555 bytes result sent to driver
2022-07-22 18:40:25.580  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_20_piece0 on host.docker.internal:63008 in memory (size: 5.4 KiB, free: 897.5 MiB)
2022-07-22 18:40:25.582  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 47.0 (TID 25) in 10 ms on host.docker.internal (executor driver) (1/1)
2022-07-22 18:40:25.582  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Removed TaskSet 47.0, whose tasks have all completed, from pool 
2022-07-22 18:40:25.583  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 47 (count at Application.java:136) finished in 0.020 s
2022-07-22 18:40:25.583  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 25 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-22 18:40:25.583  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 47: Stage finished
2022-07-22 18:40:25.584  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 25 finished: count at Application.java:136, took 0.025797 s
2022-07-22 18:40:25.585  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_19_piece0 on host.docker.internal:63008 in memory (size: 5.4 KiB, free: 897.5 MiB)
2022-07-22 18:40:25.589  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-22 18:40:25.589  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-22 18:40:25.590  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1658511611000 ms.0 from job set of time 1658511611000 ms
2022-07-22 18:40:25.590  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 14.590 s for time 1658511611000 ms (execution: 0.134 s)
2022-07-22 18:40:25.625  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1658511612000 ms.0 from job set of time 1658511612000 ms
2022-07-22 18:40:25.642  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 136 from persistence list
2022-07-22 18:40:25.647  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 135 from persistence list
2022-07-22 18:40:25.657  INFO   57 --- [-thread-pool-34] org.apache.spark.internal.Logging        : Removing RDD 136
2022-07-22 18:40:25.659  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[135] at receiverStream at Application.java:116 of time 1658511611000 ms
2022-07-22 18:40:25.659  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1658511609000 ms
2022-07-22 18:40:25.660  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1658511609000 ms
2022-07-22 18:40:25.664  INFO   57 --- [-thread-pool-35] org.apache.spark.internal.Logging        : Removing RDD 135
2022-07-22 18:40:25.672  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_22_piece0 on host.docker.internal:63008 in memory (size: 5.4 KiB, free: 897.5 MiB)
2022-07-22 18:40:25.677  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_15_piece0 on host.docker.internal:63008 in memory (size: 5.4 KiB, free: 897.5 MiB)
2022-07-22 18:40:25.683  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_21_piece0 on host.docker.internal:63008 in memory (size: 5.4 KiB, free: 897.5 MiB)
2022-07-22 18:40:25.751  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:136
2022-07-22 18:40:25.752  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 277 (count at Application.java:136) as input to shuffle 22
2022-07-22 18:40:25.752  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 26 (count at Application.java:136) with 1 output partitions
2022-07-22 18:40:25.753  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 49 (count at Application.java:136)
2022-07-22 18:40:25.753  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 48)
2022-07-22 18:40:25.753  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-22 18:40:25.757  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 49 (MapPartitionsRDD[280] at count at Application.java:136), which has no missing parents
2022-07-22 18:40:25.760  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_26 stored as values in memory (estimated size 11.0 KiB, free 897.2 MiB)
2022-07-22 18:40:25.763  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_26_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.2 MiB)
2022-07-22 18:40:25.763  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_26_piece0 in memory on host.docker.internal:63008 (size: 5.4 KiB, free: 897.5 MiB)
2022-07-22 18:40:25.764  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 26 from broadcast at DAGScheduler.scala:1478
2022-07-22 18:40:25.764  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 49 (MapPartitionsRDD[280] at count at Application.java:136) (first 15 tasks are for partitions Vector(0))
2022-07-22 18:40:25.765  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 49.0 with 1 tasks resource profile 0
2022-07-22 18:40:25.766  INFO   57 --- [er-event-loop-2] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 49.0 (TID 26) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-22 18:40:25.767  INFO   57 --- [e 49.0 (TID 26)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 49.0 (TID 26)
2022-07-22 18:40:25.770  INFO   57 --- [e 49.0 (TID 26)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-22 18:40:25.771  INFO   57 --- [e 49.0 (TID 26)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-22 18:40:25.772  INFO   57 --- [e 49.0 (TID 26)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 49.0 (TID 26). 2555 bytes result sent to driver
2022-07-22 18:40:25.773  INFO   57 --- [result-getter-1] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 49.0 (TID 26) in 8 ms on host.docker.internal (executor driver) (1/1)
2022-07-22 18:40:25.773  INFO   57 --- [result-getter-1] org.apache.spark.internal.Logging        : Removed TaskSet 49.0, whose tasks have all completed, from pool 
2022-07-22 18:40:25.774  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 49 (count at Application.java:136) finished in 0.016 s
2022-07-22 18:40:25.774  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 26 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-22 18:40:25.774  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 49: Stage finished
2022-07-22 18:40:25.776  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 26 finished: count at Application.java:136, took 0.024762 s
2022-07-22 18:40:25.778  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1658511612000 ms.0 from job set of time 1658511612000 ms
2022-07-22 18:40:25.780  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 13.778 s for time 1658511612000 ms (execution: 0.153 s)
2022-07-22 18:40:25.780  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1658511613000 ms.0 from job set of time 1658511613000 ms
2022-07-22 18:40:25.781  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-22 18:40:25.781  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-22 18:40:25.781  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 140 from persistence list
2022-07-22 18:40:25.799  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 139 from persistence list
2022-07-22 18:40:25.800  INFO   57 --- [-thread-pool-62] org.apache.spark.internal.Logging        : Removing RDD 140
2022-07-22 18:40:25.801  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[139] at receiverStream at Application.java:116 of time 1658511612000 ms
2022-07-22 18:40:25.801  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1658511610000 ms
2022-07-22 18:40:25.802  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1658511610000 ms
2022-07-22 18:40:25.802  INFO   57 --- [-thread-pool-61] org.apache.spark.internal.Logging        : Removing RDD 139
2022-07-22 18:40:25.908  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:136
2022-07-22 18:40:25.909  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 286 (count at Application.java:136) as input to shuffle 23
2022-07-22 18:40:25.910  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 27 (count at Application.java:136) with 1 output partitions
2022-07-22 18:40:25.910  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 51 (count at Application.java:136)
2022-07-22 18:40:25.910  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 50)
2022-07-22 18:40:25.910  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-22 18:40:25.911  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 51 (MapPartitionsRDD[289] at count at Application.java:136), which has no missing parents
2022-07-22 18:40:25.916  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_27 stored as values in memory (estimated size 11.0 KiB, free 897.2 MiB)
2022-07-22 18:40:25.919  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_27_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.1 MiB)
2022-07-22 18:40:25.920  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_27_piece0 in memory on host.docker.internal:63008 (size: 5.4 KiB, free: 897.5 MiB)
2022-07-22 18:40:25.920  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 27 from broadcast at DAGScheduler.scala:1478
2022-07-22 18:40:25.921  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 51 (MapPartitionsRDD[289] at count at Application.java:136) (first 15 tasks are for partitions Vector(0))
2022-07-22 18:40:25.922  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 51.0 with 1 tasks resource profile 0
2022-07-22 18:40:25.924  INFO   57 --- [er-event-loop-1] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 51.0 (TID 27) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-22 18:40:25.924  INFO   57 --- [e 51.0 (TID 27)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 51.0 (TID 27)
2022-07-22 18:40:25.927  INFO   57 --- [e 51.0 (TID 27)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-22 18:40:25.928  INFO   57 --- [e 51.0 (TID 27)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-22 18:40:25.929  INFO   57 --- [e 51.0 (TID 27)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 51.0 (TID 27). 2555 bytes result sent to driver
2022-07-22 18:40:25.931  INFO   57 --- [result-getter-2] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 51.0 (TID 27) in 8 ms on host.docker.internal (executor driver) (1/1)
2022-07-22 18:40:25.931  INFO   57 --- [result-getter-2] org.apache.spark.internal.Logging        : Removed TaskSet 51.0, whose tasks have all completed, from pool 
2022-07-22 18:40:25.931  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 51 (count at Application.java:136) finished in 0.019 s
2022-07-22 18:40:25.932  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 27 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-22 18:40:25.932  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 51: Stage finished
2022-07-22 18:40:25.932  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 27 finished: count at Application.java:136, took 0.023756 s
2022-07-22 18:40:25.933  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1658511613000 ms.0 from job set of time 1658511613000 ms
2022-07-22 18:40:25.934  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 12.933 s for time 1658511613000 ms (execution: 0.153 s)
2022-07-22 18:40:25.934  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1658511614000 ms.0 from job set of time 1658511614000 ms
2022-07-22 18:40:25.935  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 145 from persistence list
2022-07-22 18:40:25.937  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-22 18:40:25.938  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-22 18:40:25.938  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 144 from persistence list
2022-07-22 18:40:25.938  INFO   57 --- [-thread-pool-69] org.apache.spark.internal.Logging        : Removing RDD 145
2022-07-22 18:40:25.939  INFO   57 --- [-thread-pool-67] org.apache.spark.internal.Logging        : Removing RDD 144
2022-07-22 18:40:25.939  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[144] at receiverStream at Application.java:116 of time 1658511613000 ms
2022-07-22 18:40:25.940  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1658511611000 ms
2022-07-22 18:40:25.940  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1658511611000 ms
2022-07-22 18:40:26.002  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1658511626000 ms
2022-07-22 18:40:26.021  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:136
2022-07-22 18:40:26.023  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 297 (count at Application.java:136) as input to shuffle 24
2022-07-22 18:40:26.024  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 28 (count at Application.java:136) with 1 output partitions
2022-07-22 18:40:26.024  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 53 (count at Application.java:136)
2022-07-22 18:40:26.024  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 52)
2022-07-22 18:40:26.024  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-22 18:40:26.025  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 53 (MapPartitionsRDD[300] at count at Application.java:136), which has no missing parents
2022-07-22 18:40:26.027  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_28 stored as values in memory (estimated size 11.0 KiB, free 897.1 MiB)
2022-07-22 18:40:26.030  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_28_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.1 MiB)
2022-07-22 18:40:26.031  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_28_piece0 in memory on host.docker.internal:63008 (size: 5.4 KiB, free: 897.5 MiB)
2022-07-22 18:40:26.031  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 28 from broadcast at DAGScheduler.scala:1478
2022-07-22 18:40:26.032  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 53 (MapPartitionsRDD[300] at count at Application.java:136) (first 15 tasks are for partitions Vector(0))
2022-07-22 18:40:26.032  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 53.0 with 1 tasks resource profile 0
2022-07-22 18:40:26.033  INFO   57 --- [er-event-loop-0] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 53.0 (TID 28) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-22 18:40:26.034  INFO   57 --- [e 53.0 (TID 28)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 53.0 (TID 28)
2022-07-22 18:40:26.040  INFO   57 --- [e 53.0 (TID 28)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-22 18:40:26.041  INFO   57 --- [e 53.0 (TID 28)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 1 ms
2022-07-22 18:40:26.043  INFO   57 --- [e 53.0 (TID 28)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 53.0 (TID 28). 2555 bytes result sent to driver
2022-07-22 18:40:26.047  INFO   57 --- [result-getter-3] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 53.0 (TID 28) in 14 ms on host.docker.internal (executor driver) (1/1)
2022-07-22 18:40:26.048  INFO   57 --- [result-getter-3] org.apache.spark.internal.Logging        : Removed TaskSet 53.0, whose tasks have all completed, from pool 
2022-07-22 18:40:26.049  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 53 (count at Application.java:136) finished in 0.024 s
2022-07-22 18:40:26.049  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 28 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-22 18:40:26.050  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 53: Stage finished
2022-07-22 18:40:26.051  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 28 finished: count at Application.java:136, took 0.028908 s
2022-07-22 18:40:26.052  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1658511614000 ms.0 from job set of time 1658511614000 ms
2022-07-22 18:40:26.053  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 12.052 s for time 1658511614000 ms (execution: 0.118 s)
2022-07-22 18:40:26.053  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1658511615000 ms.0 from job set of time 1658511615000 ms
2022-07-22 18:40:26.065  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-22 18:40:26.066  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-22 18:40:26.081  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 147 from persistence list
2022-07-22 18:40:26.083  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 146 from persistence list
2022-07-22 18:40:26.084  INFO   57 --- [-thread-pool-72] org.apache.spark.internal.Logging        : Removing RDD 147
2022-07-22 18:40:26.110  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[146] at receiverStream at Application.java:116 of time 1658511614000 ms
2022-07-22 18:40:26.111  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1658511612000 ms
2022-07-22 18:40:26.111  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1658511612000 ms
2022-07-22 18:40:26.111  INFO   57 --- [-thread-pool-76] org.apache.spark.internal.Logging        : Removing RDD 146
2022-07-22 18:40:26.177  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:136
2022-07-22 18:40:26.178  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 306 (count at Application.java:136) as input to shuffle 25
2022-07-22 18:40:26.179  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 29 (count at Application.java:136) with 1 output partitions
2022-07-22 18:40:26.179  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 55 (count at Application.java:136)
2022-07-22 18:40:26.179  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 54)
2022-07-22 18:40:26.179  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-22 18:40:26.180  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 55 (MapPartitionsRDD[309] at count at Application.java:136), which has no missing parents
2022-07-22 18:40:26.182  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_29 stored as values in memory (estimated size 11.0 KiB, free 897.1 MiB)
2022-07-22 18:40:26.184  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_29_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.1 MiB)
2022-07-22 18:40:26.185  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_29_piece0 in memory on host.docker.internal:63008 (size: 5.4 KiB, free: 897.5 MiB)
2022-07-22 18:40:26.186  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 29 from broadcast at DAGScheduler.scala:1478
2022-07-22 18:40:26.187  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 55 (MapPartitionsRDD[309] at count at Application.java:136) (first 15 tasks are for partitions Vector(0))
2022-07-22 18:40:26.187  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 55.0 with 1 tasks resource profile 0
2022-07-22 18:40:26.188  INFO   57 --- [er-event-loop-3] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 55.0 (TID 29) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-22 18:40:26.189  INFO   57 --- [e 55.0 (TID 29)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 55.0 (TID 29)
2022-07-22 18:40:26.193  INFO   57 --- [e 55.0 (TID 29)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-22 18:40:26.193  INFO   57 --- [e 55.0 (TID 29)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-22 18:40:26.194  INFO   57 --- [e 55.0 (TID 29)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 55.0 (TID 29). 2555 bytes result sent to driver
2022-07-22 18:40:26.195  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 55.0 (TID 29) in 7 ms on host.docker.internal (executor driver) (1/1)
2022-07-22 18:40:26.195  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Removed TaskSet 55.0, whose tasks have all completed, from pool 
2022-07-22 18:40:26.196  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 55 (count at Application.java:136) finished in 0.016 s
2022-07-22 18:40:26.196  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 29 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-22 18:40:26.197  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 55: Stage finished
2022-07-22 18:40:26.197  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 29 finished: count at Application.java:136, took 0.019719 s
2022-07-22 18:40:26.198  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1658511615000 ms.0 from job set of time 1658511615000 ms
2022-07-22 18:40:26.198  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 11.198 s for time 1658511615000 ms (execution: 0.145 s)
2022-07-22 18:40:26.198  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1658511616000 ms.0 from job set of time 1658511616000 ms
2022-07-22 18:40:26.199  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 149 from persistence list
2022-07-22 18:40:26.199  INFO   57 --- [-thread-pool-79] org.apache.spark.internal.Logging        : Removing RDD 149
2022-07-22 18:40:26.199  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 148 from persistence list
2022-07-22 18:40:26.200  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-22 18:40:26.200  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[148] at receiverStream at Application.java:116 of time 1658511615000 ms
2022-07-22 18:40:26.200  INFO   57 --- [-thread-pool-84] org.apache.spark.internal.Logging        : Removing RDD 148
2022-07-22 18:40:26.201  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1658511613000 ms
2022-07-22 18:40:26.200  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-22 18:40:26.201  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1658511613000 ms
2022-07-22 18:40:26.267  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:136
2022-07-22 18:40:26.268  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 315 (count at Application.java:136) as input to shuffle 26
2022-07-22 18:40:26.269  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 30 (count at Application.java:136) with 1 output partitions
2022-07-22 18:40:26.269  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 57 (count at Application.java:136)
2022-07-22 18:40:26.269  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 56)
2022-07-22 18:40:26.270  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-22 18:40:26.270  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 57 (MapPartitionsRDD[318] at count at Application.java:136), which has no missing parents
2022-07-22 18:40:26.274  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_30 stored as values in memory (estimated size 11.0 KiB, free 897.1 MiB)
2022-07-22 18:40:26.276  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_30_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.1 MiB)
2022-07-22 18:40:26.278  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_30_piece0 in memory on host.docker.internal:63008 (size: 5.4 KiB, free: 897.5 MiB)
2022-07-22 18:40:26.279  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 30 from broadcast at DAGScheduler.scala:1478
2022-07-22 18:40:26.280  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 57 (MapPartitionsRDD[318] at count at Application.java:136) (first 15 tasks are for partitions Vector(0))
2022-07-22 18:40:26.280  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 57.0 with 1 tasks resource profile 0
2022-07-22 18:40:26.282  INFO   57 --- [er-event-loop-2] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 57.0 (TID 30) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-22 18:40:26.283  INFO   57 --- [e 57.0 (TID 30)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 57.0 (TID 30)
2022-07-22 18:40:26.286  INFO   57 --- [e 57.0 (TID 30)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-22 18:40:26.286  INFO   57 --- [e 57.0 (TID 30)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-22 18:40:26.287  INFO   57 --- [e 57.0 (TID 30)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 57.0 (TID 30). 2555 bytes result sent to driver
2022-07-22 18:40:26.289  INFO   57 --- [result-getter-1] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 57.0 (TID 30) in 8 ms on host.docker.internal (executor driver) (1/1)
2022-07-22 18:40:26.289  INFO   57 --- [result-getter-1] org.apache.spark.internal.Logging        : Removed TaskSet 57.0, whose tasks have all completed, from pool 
2022-07-22 18:40:26.290  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 57 (count at Application.java:136) finished in 0.019 s
2022-07-22 18:40:26.290  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 30 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-22 18:40:26.291  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 57: Stage finished
2022-07-22 18:40:26.291  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 30 finished: count at Application.java:136, took 0.023145 s
2022-07-22 18:40:26.292  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1658511616000 ms.0 from job set of time 1658511616000 ms
2022-07-22 18:40:26.292  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 10.292 s for time 1658511616000 ms (execution: 0.094 s)
2022-07-22 18:40:26.293  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1658511617000 ms.0 from job set of time 1658511617000 ms
2022-07-22 18:40:26.294  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-22 18:40:26.294  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-22 18:40:26.296  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 151 from persistence list
2022-07-22 18:40:26.301  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 150 from persistence list
2022-07-22 18:40:26.302  INFO   57 --- [-thread-pool-85] org.apache.spark.internal.Logging        : Removing RDD 151
2022-07-22 18:40:26.304  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[150] at receiverStream at Application.java:116 of time 1658511616000 ms
2022-07-22 18:40:26.304  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1658511614000 ms
2022-07-22 18:40:26.304  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1658511614000 ms
2022-07-22 18:40:26.305  INFO   57 --- [-thread-pool-87] org.apache.spark.internal.Logging        : Removing RDD 150
2022-07-22 18:40:26.373  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:136
2022-07-22 18:40:26.374  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 324 (count at Application.java:136) as input to shuffle 27
2022-07-22 18:40:26.374  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 31 (count at Application.java:136) with 1 output partitions
2022-07-22 18:40:26.375  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 59 (count at Application.java:136)
2022-07-22 18:40:26.375  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 58)
2022-07-22 18:40:26.375  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-22 18:40:26.376  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 59 (MapPartitionsRDD[327] at count at Application.java:136), which has no missing parents
2022-07-22 18:40:26.379  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_31 stored as values in memory (estimated size 11.0 KiB, free 897.1 MiB)
2022-07-22 18:40:26.382  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_31_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.1 MiB)
2022-07-22 18:40:26.382  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_31_piece0 in memory on host.docker.internal:63008 (size: 5.4 KiB, free: 897.5 MiB)
2022-07-22 18:40:26.383  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 31 from broadcast at DAGScheduler.scala:1478
2022-07-22 18:40:26.384  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 59 (MapPartitionsRDD[327] at count at Application.java:136) (first 15 tasks are for partitions Vector(0))
2022-07-22 18:40:26.384  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 59.0 with 1 tasks resource profile 0
2022-07-22 18:40:26.385  INFO   57 --- [er-event-loop-1] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 59.0 (TID 31) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-22 18:40:26.386  INFO   57 --- [e 59.0 (TID 31)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 59.0 (TID 31)
2022-07-22 18:40:26.389  INFO   57 --- [e 59.0 (TID 31)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-22 18:40:26.390  INFO   57 --- [e 59.0 (TID 31)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-22 18:40:26.392  INFO   57 --- [e 59.0 (TID 31)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 59.0 (TID 31). 2555 bytes result sent to driver
2022-07-22 18:40:26.393  INFO   57 --- [result-getter-2] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 59.0 (TID 31) in 8 ms on host.docker.internal (executor driver) (1/1)
2022-07-22 18:40:26.393  INFO   57 --- [result-getter-2] org.apache.spark.internal.Logging        : Removed TaskSet 59.0, whose tasks have all completed, from pool 
2022-07-22 18:40:26.394  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 59 (count at Application.java:136) finished in 0.017 s
2022-07-22 18:40:26.394  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 31 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-22 18:40:26.394  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 59: Stage finished
2022-07-22 18:40:26.396  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 31 finished: count at Application.java:136, took 0.023218 s
2022-07-22 18:40:26.401  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-22 18:40:26.401  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-22 18:40:26.402  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1658511617000 ms.0 from job set of time 1658511617000 ms
2022-07-22 18:40:26.402  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 9.402 s for time 1658511617000 ms (execution: 0.109 s)
2022-07-22 18:40:26.402  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1658511618000 ms.0 from job set of time 1658511618000 ms
2022-07-22 18:40:26.405  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 154 from persistence list
2022-07-22 18:40:26.408  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 153 from persistence list
2022-07-22 18:40:26.408  INFO   57 --- [-thread-pool-90] org.apache.spark.internal.Logging        : Removing RDD 154
2022-07-22 18:40:26.409  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[153] at receiverStream at Application.java:116 of time 1658511617000 ms
2022-07-22 18:40:26.410  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1658511615000 ms
2022-07-22 18:40:26.410  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1658511615000 ms
2022-07-22 18:40:26.412  INFO   57 --- [-thread-pool-91] org.apache.spark.internal.Logging        : Removing RDD 153
2022-07-22 18:40:26.494  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:136
2022-07-22 18:40:26.495  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 333 (count at Application.java:136) as input to shuffle 28
2022-07-22 18:40:26.496  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 32 (count at Application.java:136) with 1 output partitions
2022-07-22 18:40:26.496  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 61 (count at Application.java:136)
2022-07-22 18:40:26.496  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 60)
2022-07-22 18:40:26.496  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-22 18:40:26.497  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 61 (MapPartitionsRDD[336] at count at Application.java:136), which has no missing parents
2022-07-22 18:40:26.499  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_32 stored as values in memory (estimated size 11.0 KiB, free 897.1 MiB)
2022-07-22 18:40:26.501  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_32_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.1 MiB)
2022-07-22 18:40:26.502  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_32_piece0 in memory on host.docker.internal:63008 (size: 5.4 KiB, free: 897.5 MiB)
2022-07-22 18:40:26.503  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 32 from broadcast at DAGScheduler.scala:1478
2022-07-22 18:40:26.503  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 61 (MapPartitionsRDD[336] at count at Application.java:136) (first 15 tasks are for partitions Vector(0))
2022-07-22 18:40:26.503  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 61.0 with 1 tasks resource profile 0
2022-07-22 18:40:26.505  INFO   57 --- [er-event-loop-0] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 61.0 (TID 32) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-22 18:40:26.506  INFO   57 --- [e 61.0 (TID 32)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 61.0 (TID 32)
2022-07-22 18:40:26.509  INFO   57 --- [e 61.0 (TID 32)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-22 18:40:26.509  INFO   57 --- [e 61.0 (TID 32)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-22 18:40:26.510  INFO   57 --- [e 61.0 (TID 32)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 61.0 (TID 32). 2555 bytes result sent to driver
2022-07-22 18:40:26.511  INFO   57 --- [result-getter-3] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 61.0 (TID 32) in 7 ms on host.docker.internal (executor driver) (1/1)
2022-07-22 18:40:26.512  INFO   57 --- [result-getter-3] org.apache.spark.internal.Logging        : Removed TaskSet 61.0, whose tasks have all completed, from pool 
2022-07-22 18:40:26.512  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 61 (count at Application.java:136) finished in 0.014 s
2022-07-22 18:40:26.513  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 32 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-22 18:40:26.513  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 61: Stage finished
2022-07-22 18:40:26.513  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 32 finished: count at Application.java:136, took 0.019036 s
2022-07-22 18:40:26.514  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1658511618000 ms.0 from job set of time 1658511618000 ms
2022-07-22 18:40:26.515  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 8.514 s for time 1658511618000 ms (execution: 0.112 s)
2022-07-22 18:40:26.515  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1658511619000 ms.0 from job set of time 1658511619000 ms
2022-07-22 18:40:26.516  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 156 from persistence list
2022-07-22 18:40:26.516  INFO   57 --- [-thread-pool-94] org.apache.spark.internal.Logging        : Removing RDD 156
2022-07-22 18:40:26.517  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-22 18:40:26.517  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 155 from persistence list
2022-07-22 18:40:26.517  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-22 18:40:26.518  INFO   57 --- [c-thread-pool-0] org.apache.spark.internal.Logging        : Removing RDD 155
2022-07-22 18:40:26.518  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[155] at receiverStream at Application.java:116 of time 1658511618000 ms
2022-07-22 18:40:26.519  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1658511616000 ms
2022-07-22 18:40:26.519  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1658511616000 ms
2022-07-22 18:40:26.561  INFO   57 --- [shutdown-hook-0] org.apache.spark.internal.Logging        : Invoking stop(stopGracefully=false) from shutdown hook
2022-07-22 18:40:26.590  INFO   57 --- [er-event-loop-3] org.apache.spark.internal.Logging        : Sent stop signal to all 1 receivers
2022-07-22 18:40:26.592  INFO   57 --- [er-event-loop-0] org.apache.spark.internal.Logging        : Received stop signal
2022-07-22 18:40:26.595  INFO   57 --- [er-event-loop-0] org.apache.spark.internal.Logging        : Stopping receiver with message: Stopped by driver: 
2022-07-22 18:40:26.596  INFO   57 --- [er-event-loop-0] org.apache.spark.internal.Logging        : Called receiver onStop
2022-07-22 18:40:26.597  INFO   57 --- [er-event-loop-0] org.apache.spark.internal.Logging        : Deregistering receiver 0
2022-07-22 18:40:26.607  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:136
2022-07-22 18:40:26.607  ERROR   73 --- [er-event-loop-1] org.apache.spark.internal.Logging        : Deregistered receiver for stream 0: Stopped by driver
2022-07-22 18:40:26.609  INFO   57 --- [er-event-loop-0] org.apache.spark.internal.Logging        : Stopped receiver 0
2022-07-22 18:40:26.610  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 342 (count at Application.java:136) as input to shuffle 29
2022-07-22 18:40:26.616  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 33 (count at Application.java:136) with 1 output partitions
2022-07-22 18:40:26.617  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 63 (count at Application.java:136)
2022-07-22 18:40:26.618  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 62)
2022-07-22 18:40:26.619  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-22 18:40:26.619  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 63 (MapPartitionsRDD[345] at count at Application.java:136), which has no missing parents
2022-07-22 18:40:26.623  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_33 stored as values in memory (estimated size 11.0 KiB, free 897.1 MiB)
2022-07-22 18:40:26.627  INFO   57 --- [er-event-loop-0] org.apache.spark.internal.Logging        : Stopping BlockGenerator
2022-07-22 18:40:26.637  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_33_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.1 MiB)
2022-07-22 18:40:26.640  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_33_piece0 in memory on host.docker.internal:63008 (size: 5.4 KiB, free: 897.4 MiB)
2022-07-22 18:40:26.641  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 33 from broadcast at DAGScheduler.scala:1478
2022-07-22 18:40:26.642  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 63 (MapPartitionsRDD[345] at count at Application.java:136) (first 15 tasks are for partitions Vector(0))
2022-07-22 18:40:26.642  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 63.0 with 1 tasks resource profile 0
2022-07-22 18:40:26.644  INFO   57 --- [er-event-loop-2] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 63.0 (TID 33) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-22 18:40:26.650  ERROR   94 --- [er-event-loop-2] org.apache.spark.internal.Logging        : Ignoring error
java.util.concurrent.RejectedExecutionException: Task org.apache.spark.executor.Executor$TaskRunner@7060f83e rejected from java.util.concurrent.ThreadPoolExecutor@375033d3[Shutting down, pool size = 1, active threads = 1, queued tasks = 0, completed tasks = 32]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2063)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:830)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1379)
	at org.apache.spark.executor.Executor.launchTask(Executor.scala:270)
	at org.apache.spark.scheduler.local.LocalEndpoint.$anonfun$reviveOffers$1(LocalSchedulerBackend.scala:93)
	at org.apache.spark.scheduler.local.LocalEndpoint.$anonfun$reviveOffers$1$adapted(LocalSchedulerBackend.scala:91)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at org.apache.spark.scheduler.local.LocalEndpoint.reviveOffers(LocalSchedulerBackend.scala:91)
	at org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$receive$1.applyOrElse(LocalSchedulerBackend.scala:68)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:115)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2022-07-22 18:40:27.000  INFO   57 --- [er-event-loop-0] org.apache.spark.internal.Logging        : Stopped timer for BlockGenerator after time 1658511627000
2022-07-22 18:40:27.001  INFO   57 --- [er-event-loop-0] org.apache.spark.internal.Logging        : Waiting for block pushing thread to terminate
2022-07-22 18:40:27.002  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1658511627000 ms
2022-07-22 18:40:27.007  INFO   57 --- [      Thread-14] org.apache.spark.internal.Logging        : Pushing out the last 0 blocks
2022-07-22 18:40:27.008  INFO   57 --- [      Thread-14] org.apache.spark.internal.Logging        : Stopped block pushing thread
2022-07-22 18:40:27.008  INFO   57 --- [er-event-loop-0] org.apache.spark.internal.Logging        : Stopped BlockGenerator
2022-07-22 18:40:27.010  INFO   57 --- [age 0.0 (TID 0)] org.apache.spark.internal.Logging        : Stopped receiver without error
2022-07-22 18:40:27.011  INFO   57 --- [age 0.0 (TID 0)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 0.0 (TID 0). 880 bytes result sent to driver
2022-07-22 18:40:27.012  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 0.0 (TID 0) in 32476 ms on host.docker.internal (executor driver) (1/1)
2022-07-22 18:40:27.012  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Removed TaskSet 0.0, whose tasks have all completed, from pool 
2022-07-22 18:40:27.013  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 0 (start at Application.java:143) finished in 36.861 s
2022-07-22 18:40:27.013  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-22 18:40:27.013  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 0: Stage finished
2022-07-22 18:40:27.015  INFO   57 --- [shutdown-hook-0] org.apache.spark.internal.Logging        : All of the receivers have deregistered successfully
2022-07-22 18:40:27.016  INFO   57 --- [shutdown-hook-0] org.apache.spark.internal.Logging        : ReceiverTracker stopped
2022-07-22 18:40:27.017  INFO   57 --- [shutdown-hook-0] org.apache.spark.internal.Logging        : Stopping JobGenerator immediately
2022-07-22 18:40:27.020  INFO   57 --- [shutdown-hook-0] org.apache.spark.internal.Logging        : Stopped timer for JobGenerator after time 1658511627000
2022-07-22 18:40:27.022  INFO   57 --- [shutdown-hook-0] org.apache.spark.internal.Logging        : Stopped JobGenerator
2022-07-22 18:40:29.049  INFO   57 --- [shutdown-hook-0] org.apache.spark.internal.Logging        : Stopped JobScheduler
2022-07-22 18:40:29.066  INFO 1153 --- [shutdown-hook-0] ject.jetty.server.handler.ContextHandler : Stopped o.s.j.s.ServletContextHandler@6fd77352{/streaming,null,STOPPED,@Spark}
2022-07-22 18:40:29.068  INFO 1153 --- [shutdown-hook-0] ject.jetty.server.handler.ContextHandler : Stopped o.s.j.s.ServletContextHandler@3f672204{/streaming/json,null,STOPPED,@Spark}
2022-07-22 18:40:29.071  INFO 1153 --- [shutdown-hook-0] ject.jetty.server.handler.ContextHandler : Stopped o.s.j.s.ServletContextHandler@6c65860d{/streaming/batch,null,STOPPED,@Spark}
2022-07-22 18:40:29.072  INFO 1153 --- [shutdown-hook-0] ject.jetty.server.handler.ContextHandler : Stopped o.s.j.s.ServletContextHandler@7cf283e1{/streaming/batch/json,null,STOPPED,@Spark}
2022-07-22 18:40:29.075  INFO 1153 --- [shutdown-hook-0] ject.jetty.server.handler.ContextHandler : Stopped o.s.j.s.ServletContextHandler@252f626c{/static/streaming,null,STOPPED,@Spark}
2022-07-22 18:40:29.077  INFO  154 --- [           main] com.elite.cdr.validator.Application      : ****************************************************
2022-07-22 18:40:29.077  INFO  155 --- [           main] com.elite.cdr.validator.Application      : Duration: 0.0 seconds
2022-07-22 18:40:29.077  INFO  156 --- [           main] com.elite.cdr.validator.Application      : Batch executed with success
2022-07-22 18:40:29.077  INFO  157 --- [           main] com.elite.cdr.validator.Application      : ****************************************************
2022-07-22 18:40:29.077  INFO   57 --- [shutdown-hook-0] org.apache.spark.internal.Logging        : StreamingContext stopped successfully
2022-07-22 18:40:29.078  INFO   57 --- [shutdown-hook-0] org.apache.spark.internal.Logging        : Invoking stop() from shutdown hook
2022-07-22 18:40:29.091  INFO  381 --- [shutdown-hook-0] rkproject.jetty.server.AbstractConnector : Stopped Spark@7caa550{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2022-07-22 18:40:29.092  INFO   57 --- [shutdown-hook-0] org.apache.spark.internal.Logging        : Stopped Spark web UI at http://host.docker.internal:4040
2022-07-22 18:40:29.097  INFO   57 --- [shutdown-hook-0] org.apache.spark.internal.Logging        : ResultStage 63 (count at Application.java:136) failed in 2.477 s due to Stage cancelled because SparkContext was shut down
2022-07-22 18:40:29.110  INFO   57 --- [er-event-loop-2] org.apache.spark.internal.Logging        : MapOutputTrackerMasterEndpoint stopped!
2022-07-22 18:40:29.207  INFO   57 --- [shutdown-hook-0] org.apache.spark.internal.Logging        : MemoryStore cleared
2022-07-22 18:40:29.208  INFO   57 --- [shutdown-hook-0] org.apache.spark.internal.Logging        : BlockManager stopped
2022-07-22 18:40:29.211  INFO   57 --- [shutdown-hook-0] org.apache.spark.internal.Logging        : BlockManagerMaster stopped
2022-07-22 18:40:29.220  INFO   57 --- [er-event-loop-2] org.apache.spark.internal.Logging        : OutputCommitCoordinator stopped!
2022-07-22 18:40:29.224  INFO   57 --- [shutdown-hook-0] org.apache.spark.internal.Logging        : Successfully stopped SparkContext
2022-07-22 18:40:29.225  INFO   57 --- [shutdown-hook-0] org.apache.spark.internal.Logging        : Shutdown hook called
2022-07-22 18:40:29.225  INFO   57 --- [shutdown-hook-0] org.apache.spark.internal.Logging        : Deleting directory C:\Users\Wael Hamdi\AppData\Local\Temp\spark-66cb08fb-8d1e-4216-a0ce-703ec02666f7
