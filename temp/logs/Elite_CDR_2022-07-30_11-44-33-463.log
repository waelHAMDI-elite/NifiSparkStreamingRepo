2022-07-30 11:44:33.512  INFO   48 --- [           main] com.elite.cdr.validator.Application      : Starting ASN1 Reader 
2022-07-30 11:44:33.665  INFO   50 --- [           main] com.elite.cdr.validator.Application      : ############### Run with the args [--env, local, --file, src/main/resources/data/simpleTypes.ber, --prop, src/main/resources/myapp.properties]
2022-07-30 11:44:33.756  INFO   56 --- [           main] com.elite.cdr.validator.Application      : ############### Run in local mode
2022-07-30 11:44:38.899  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Running Spark version 3.2.1
2022-07-30 11:44:40.202  INFO   57 --- [           main] org.apache.spark.internal.Logging        : ==============================================================
2022-07-30 11:44:40.208  INFO   57 --- [           main] org.apache.spark.internal.Logging        : No custom resources configured for spark.driver.
2022-07-30 11:44:40.209  INFO   57 --- [           main] org.apache.spark.internal.Logging        : ==============================================================
2022-07-30 11:44:40.210  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Submitted application: NiFi Spark Streaming example
2022-07-30 11:44:40.319  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2022-07-30 11:44:40.410  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Limiting resource is cpu
2022-07-30 11:44:40.441  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Added ResourceProfile id: 0
2022-07-30 11:44:41.131  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Changing view acls to: Wael Hamdi
2022-07-30 11:44:41.132  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Changing modify acls to: Wael Hamdi
2022-07-30 11:44:41.134  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Changing view acls groups to: 
2022-07-30 11:44:41.135  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Changing modify acls groups to: 
2022-07-30 11:44:41.136  INFO   57 --- [           main] org.apache.spark.internal.Logging        : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Wael Hamdi); groups with view permissions: Set(); users  with modify permissions: Set(Wael Hamdi); groups with modify permissions: Set()
2022-07-30 11:44:44.511  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Successfully started service 'sparkDriver' on port 58571.
2022-07-30 11:44:44.609  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Registering MapOutputTracker
2022-07-30 11:44:44.721  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Registering BlockManagerMaster
2022-07-30 11:44:44.777  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2022-07-30 11:44:44.778  INFO   57 --- [           main] org.apache.spark.internal.Logging        : BlockManagerMasterEndpoint up
2022-07-30 11:44:44.783  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Registering BlockManagerMasterHeartbeat
2022-07-30 11:44:44.864  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Created local directory at C:\Users\Wael Hamdi\AppData\Local\Temp\blockmgr-44f23b52-a775-49df-81eb-65ccea763228
2022-07-30 11:44:44.942  INFO   57 --- [           main] org.apache.spark.internal.Logging        : MemoryStore started with capacity 897.6 MiB
2022-07-30 11:44:45.013  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Registering OutputCommitCoordinator
2022-07-30 11:44:45.248  INFO  170 --- [           main] org.sparkproject.jetty.util.log.Log      : Logging initialized @13412ms to org.sparkproject.jetty.util.log.Slf4jLog
2022-07-30 11:44:45.514  INFO  375 --- [           main] org.sparkproject.jetty.server.Server     : jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_301-b09
2022-07-30 11:44:45.615  INFO  415 --- [           main] org.sparkproject.jetty.server.Server     : Started @13780ms
2022-07-30 11:44:45.750  INFO  331 --- [           main] rkproject.jetty.server.AbstractConnector : Started ServerConnector@2c715e84{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2022-07-30 11:44:45.751  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Successfully started service 'SparkUI' on port 4040.
2022-07-30 11:44:45.864  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2f4854d6{/jobs,null,AVAILABLE,@Spark}
2022-07-30 11:44:45.867  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@27e0f2f5{/jobs/json,null,AVAILABLE,@Spark}
2022-07-30 11:44:45.868  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6db66836{/jobs/job,null,AVAILABLE,@Spark}
2022-07-30 11:44:45.870  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3f093abe{/jobs/job/json,null,AVAILABLE,@Spark}
2022-07-30 11:44:45.874  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4eeea57d{/stages,null,AVAILABLE,@Spark}
2022-07-30 11:44:45.875  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@e24ddd0{/stages/json,null,AVAILABLE,@Spark}
2022-07-30 11:44:45.876  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@548e76f1{/stages/stage,null,AVAILABLE,@Spark}
2022-07-30 11:44:45.878  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3dd69f5a{/stages/stage/json,null,AVAILABLE,@Spark}
2022-07-30 11:44:45.879  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1ee4730{/stages/pool,null,AVAILABLE,@Spark}
2022-07-30 11:44:45.881  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5003041b{/stages/pool/json,null,AVAILABLE,@Spark}
2022-07-30 11:44:45.882  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@16fb356{/storage,null,AVAILABLE,@Spark}
2022-07-30 11:44:45.883  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@23a9ba52{/storage/json,null,AVAILABLE,@Spark}
2022-07-30 11:44:45.884  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@70ab80e3{/storage/rdd,null,AVAILABLE,@Spark}
2022-07-30 11:44:45.885  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@67427b69{/storage/rdd/json,null,AVAILABLE,@Spark}
2022-07-30 11:44:45.888  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@544630b7{/environment,null,AVAILABLE,@Spark}
2022-07-30 11:44:45.889  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1095f122{/environment/json,null,AVAILABLE,@Spark}
2022-07-30 11:44:45.890  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3d6300e8{/executors,null,AVAILABLE,@Spark}
2022-07-30 11:44:45.891  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@24a1c17f{/executors/json,null,AVAILABLE,@Spark}
2022-07-30 11:44:45.892  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@73511076{/executors/threadDump,null,AVAILABLE,@Spark}
2022-07-30 11:44:45.893  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@532721fd{/executors/threadDump/json,null,AVAILABLE,@Spark}
2022-07-30 11:44:45.979  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7fb9f71f{/static,null,AVAILABLE,@Spark}
2022-07-30 11:44:45.981  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@790174f2{/,null,AVAILABLE,@Spark}
2022-07-30 11:44:45.983  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7689ddef{/api,null,AVAILABLE,@Spark}
2022-07-30 11:44:45.984  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@70925b45{/jobs/job/kill,null,AVAILABLE,@Spark}
2022-07-30 11:44:45.986  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@aa22f1c{/stages/stage/kill,null,AVAILABLE,@Spark}
2022-07-30 11:44:45.991  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Bound SparkUI to 0.0.0.0, and started at http://host.docker.internal:4040
2022-07-30 11:44:46.605  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Starting executor ID driver on host host.docker.internal
2022-07-30 11:44:46.750  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 58598.
2022-07-30 11:44:46.750  INFO   82 --- [           main] .network.netty.NettyBlockTransferService : Server created on host.docker.internal:58598
2022-07-30 11:44:46.753  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2022-07-30 11:44:46.781  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Registering BlockManager BlockManagerId(driver, host.docker.internal, 58598, None)
2022-07-30 11:44:46.789  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Registering block manager host.docker.internal:58598 with 897.6 MiB RAM, BlockManagerId(driver, host.docker.internal, 58598, None)
2022-07-30 11:44:46.796  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Registered BlockManager BlockManagerId(driver, host.docker.internal, 58598, None)
2022-07-30 11:44:46.798  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Initialized BlockManager: BlockManagerId(driver, host.docker.internal, 58598, None)
2022-07-30 11:44:47.077  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1813f3e9{/metrics/json,null,AVAILABLE,@Spark}
2022-07-30 11:44:48.047  INFO   57 --- [streaming-start] org.apache.spark.internal.Logging        : Starting 1 receivers
2022-07-30 11:44:48.050  INFO   57 --- [streaming-start] org.apache.spark.internal.Logging        : ReceiverTracker started
2022-07-30 11:44:48.057  INFO   57 --- [streaming-start] org.apache.spark.internal.Logging        : Slide time = 1000 ms
2022-07-30 11:44:48.057  INFO   57 --- [streaming-start] org.apache.spark.internal.Logging        : Storage level = Serialized 1x Replicated
2022-07-30 11:44:48.058  INFO   57 --- [streaming-start] org.apache.spark.internal.Logging        : Checkpoint interval = null
2022-07-30 11:44:48.059  INFO   57 --- [streaming-start] org.apache.spark.internal.Logging        : Remember interval = 1000 ms
2022-07-30 11:44:48.060  INFO   57 --- [streaming-start] org.apache.spark.internal.Logging        : Initialized and validated org.apache.spark.streaming.dstream.PluggableInputDStream@6a76d7d9
2022-07-30 11:44:48.060  INFO   57 --- [streaming-start] org.apache.spark.internal.Logging        : Slide time = 1000 ms
2022-07-30 11:44:48.061  INFO   57 --- [streaming-start] org.apache.spark.internal.Logging        : Storage level = Serialized 1x Replicated
2022-07-30 11:44:48.061  INFO   57 --- [streaming-start] org.apache.spark.internal.Logging        : Checkpoint interval = null
2022-07-30 11:44:48.061  INFO   57 --- [streaming-start] org.apache.spark.internal.Logging        : Remember interval = 1000 ms
2022-07-30 11:44:48.061  INFO   57 --- [streaming-start] org.apache.spark.internal.Logging        : Initialized and validated org.apache.spark.streaming.dstream.MappedDStream@78e62de4
2022-07-30 11:44:48.062  INFO   57 --- [streaming-start] org.apache.spark.internal.Logging        : Slide time = 1000 ms
2022-07-30 11:44:48.062  INFO   57 --- [streaming-start] org.apache.spark.internal.Logging        : Storage level = Serialized 1x Replicated
2022-07-30 11:44:48.062  INFO   57 --- [streaming-start] org.apache.spark.internal.Logging        : Checkpoint interval = null
2022-07-30 11:44:48.063  INFO   57 --- [streaming-start] org.apache.spark.internal.Logging        : Remember interval = 1000 ms
2022-07-30 11:44:48.063  INFO   57 --- [streaming-start] org.apache.spark.internal.Logging        : Initialized and validated org.apache.spark.streaming.dstream.ForEachDStream@4939df8d
2022-07-30 11:44:48.286  INFO   57 --- [er-event-loop-3] org.apache.spark.internal.Logging        : Receiver 0 started
2022-07-30 11:44:48.296  INFO   57 --- [streaming-start] org.apache.spark.internal.Logging        : Started timer for JobGenerator at time 1659177889000
2022-07-30 11:44:48.296  INFO   57 --- [streaming-start] org.apache.spark.internal.Logging        : Started JobGenerator at 1659177889000 ms
2022-07-30 11:44:48.299  INFO   57 --- [streaming-start] org.apache.spark.internal.Logging        : Started JobScheduler
2022-07-30 11:44:48.302  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 0 (start at Application.java:156) with 1 output partitions
2022-07-30 11:44:48.306  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6972c30a{/streaming,null,AVAILABLE,@Spark}
2022-07-30 11:44:48.308  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1ab6718{/streaming/json,null,AVAILABLE,@Spark}
2022-07-30 11:44:48.310  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5109e8cf{/streaming/batch,null,AVAILABLE,@Spark}
2022-07-30 11:44:48.312  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@78b41097{/streaming/batch/json,null,AVAILABLE,@Spark}
2022-07-30 11:44:48.306  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 0 (start at Application.java:156)
2022-07-30 11:44:48.313  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List()
2022-07-30 11:44:48.314  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6c65860d{/static/streaming,null,AVAILABLE,@Spark}
2022-07-30 11:44:48.315  INFO   57 --- [           main] org.apache.spark.internal.Logging        : StreamingContext started
2022-07-30 11:44:48.316  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:44:48.326  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 0 (Receiver 0 ParallelCollectionRDD[0] at makeRDD at ReceiverTracker.scala:609), which has no missing parents
2022-07-30 11:44:48.678  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_0 stored as values in memory (estimated size 97.5 KiB, free 897.5 MiB)
2022-07-30 11:44:48.850  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_0_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 897.5 MiB)
2022-07-30 11:44:48.859  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_0_piece0 in memory on host.docker.internal:58598 (size: 34.2 KiB, free: 897.6 MiB)
2022-07-30 11:44:48.867  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 0 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:44:48.902  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 0 (Receiver 0 ParallelCollectionRDD[0] at makeRDD at ReceiverTracker.scala:609) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:44:48.911  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 0.0 with 1 tasks resource profile 0
2022-07-30 11:44:49.159  INFO   57 --- [er-event-loop-0] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 0.0 (TID 0) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 5950 bytes) taskResourceAssignments Map()
2022-07-30 11:44:49.163  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177889000 ms
2022-07-30 11:44:49.167  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177889000 ms.0 from job set of time 1659177889000 ms
2022-07-30 11:44:49.217  INFO   57 --- [age 0.0 (TID 0)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 0.0 (TID 0)
2022-07-30 11:44:49.630  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkContext; some configuration may not take effect.
2022-07-30 11:44:49.845  INFO   57 --- [age 0.0 (TID 0)] org.apache.spark.internal.Logging        : Started timer for BlockGenerator at time 1659177890000
2022-07-30 11:44:49.847  INFO   57 --- [age 0.0 (TID 0)] org.apache.spark.internal.Logging        : Started BlockGenerator
2022-07-30 11:44:49.867  INFO   57 --- [      Thread-14] org.apache.spark.internal.Logging        : Started block pushing thread
2022-07-30 11:44:49.905  INFO   57 --- [er-event-loop-0] org.apache.spark.internal.Logging        : Registered receiver for stream 0 from host.docker.internal:58571
2022-07-30 11:44:49.906  INFO   57 --- [age 0.0 (TID 0)] org.apache.spark.internal.Logging        : Starting receiver 0
2022-07-30 11:44:49.908  INFO   57 --- [age 0.0 (TID 0)] org.apache.spark.internal.Logging        : Called receiver 0 onStart
2022-07-30 11:44:49.909  INFO   57 --- [age 0.0 (TID 0)] org.apache.spark.internal.Logging        : Waiting for receiver to be stopped
2022-07-30 11:44:50.009  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177890000 ms
2022-07-30 11:44:51.018  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177891000 ms
2022-07-30 11:44:51.813  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2022-07-30 11:44:52.003  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177892000 ms
2022-07-30 11:44:52.832  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Warehouse path is 'file:/C:/IntelliJProjects/NifiSparkStreaming/spark-warehouse'.
2022-07-30 11:44:52.930  INFO  915 --- [-job-executor-0] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@11bc883f{/SQL,null,AVAILABLE,@Spark}
2022-07-30 11:44:52.932  INFO  915 --- [-job-executor-0] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@16c2c5e8{/SQL/json,null,AVAILABLE,@Spark}
2022-07-30 11:44:52.934  INFO  915 --- [-job-executor-0] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@58bb04da{/SQL/execution,null,AVAILABLE,@Spark}
2022-07-30 11:44:52.936  INFO  915 --- [-job-executor-0] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7a5144d1{/SQL/execution/json,null,AVAILABLE,@Spark}
2022-07-30 11:44:52.952  INFO  915 --- [-job-executor-0] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@52b7a029{/static/sql,null,AVAILABLE,@Spark}
2022-07-30 11:44:53.009  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177893000 ms
2022-07-30 11:44:53.707  INFO  571 --- [  NiFi Receiver] g.apache.nifi.remote.client.PeerSelector : Successfully refreshed peer status cache; remote group consists of 1 peers
2022-07-30 11:44:53.707  INFO  571 --- [ool Maintenance] g.apache.nifi.remote.client.PeerSelector : Successfully refreshed peer status cache; remote group consists of 1 peers
2022-07-30 11:44:54.003  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177894000 ms
2022-07-30 11:44:55.005  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177895000 ms
2022-07-30 11:44:55.034  INFO   57 --- [  NiFi Receiver] org.apache.spark.internal.Logging        : Block input-0-1659177889817 stored as values in memory (estimated size 55.9 MiB, free 841.6 MiB)
2022-07-30 11:44:55.035  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added input-0-1659177889817 in memory on host.docker.internal:58598 (size: 55.9 MiB, free: 841.7 MiB)
2022-07-30 11:44:56.029  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177896000 ms
2022-07-30 11:44:57.045  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177897000 ms
2022-07-30 11:44:57.409  WARN   69 --- [ver-heartbeater] org.apache.spark.internal.Logging        : Exception when trying to compute pagesize, as a result reporting of ProcessTree metrics is stopped
2022-07-30 11:44:58.002  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177898000 ms
2022-07-30 11:44:59.002  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177899000 ms
2022-07-30 11:45:00.003  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177900000 ms
2022-07-30 11:45:01.018  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177901000 ms
2022-07-30 11:45:02.053  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177902000 ms
2022-07-30 11:45:03.099  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177903000 ms
2022-07-30 11:45:04.017  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177904000 ms
2022-07-30 11:45:05.006  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177905000 ms
2022-07-30 11:45:06.163  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177906000 ms
2022-07-30 11:45:07.003  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177907000 ms
2022-07-30 11:45:07.946  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Code generated in 372.8538 ms
2022-07-30 11:45:08.004  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177908000 ms
2022-07-30 11:45:08.657  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Code generated in 30.5029 ms
2022-07-30 11:45:08.718  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Code generated in 16.4171 ms
2022-07-30 11:45:08.833  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:45:08.838  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 46 (count at Application.java:147) as input to shuffle 0
2022-07-30 11:45:08.843  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 1 (count at Application.java:147) with 1 output partitions
2022-07-30 11:45:08.843  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 2 (count at Application.java:147)
2022-07-30 11:45:08.843  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 1)
2022-07-30 11:45:08.845  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:45:08.847  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 2 (MapPartitionsRDD[49] at count at Application.java:147), which has no missing parents
2022-07-30 11:45:08.855  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_1 stored as values in memory (estimated size 11.0 KiB, free 841.6 MiB)
2022-07-30 11:45:08.859  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 841.6 MiB)
2022-07-30 11:45:08.861  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_1_piece0 in memory on host.docker.internal:58598 (size: 5.4 KiB, free: 841.7 MiB)
2022-07-30 11:45:08.862  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 1 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:45:08.863  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[49] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:45:08.863  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 2.0 with 1 tasks resource profile 0
2022-07-30 11:45:08.865  INFO   57 --- [er-event-loop-2] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 2.0 (TID 1) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:45:08.867  INFO   57 --- [age 2.0 (TID 1)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 2.0 (TID 1)
2022-07-30 11:45:09.006  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177909000 ms
2022-07-30 11:45:09.165  INFO   57 --- [age 2.0 (TID 1)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:45:09.170  INFO   57 --- [age 2.0 (TID 1)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 14 ms
2022-07-30 11:45:09.242  INFO   57 --- [age 2.0 (TID 1)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 2.0 (TID 1). 2727 bytes result sent to driver
2022-07-30 11:45:09.256  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 2.0 (TID 1) in 387 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:45:09.259  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Removed TaskSet 2.0, whose tasks have all completed, from pool 
2022-07-30 11:45:09.270  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 2 (count at Application.java:147) finished in 0.416 s
2022-07-30 11:45:09.276  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:45:09.277  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 2: Stage finished
2022-07-30 11:45:09.286  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 1 finished: count at Application.java:147, took 0.451818 s
2022-07-30 11:45:09.301  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177889000 ms.0 from job set of time 1659177889000 ms
2022-07-30 11:45:09.302  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 20.298 s for time 1659177889000 ms (execution: 20.132 s)
2022-07-30 11:45:09.303  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177890000 ms.0 from job set of time 1659177890000 ms
2022-07-30 11:45:09.313  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:45:09.314  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:45:09.316  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 
2022-07-30 11:45:09.320  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 
2022-07-30 11:45:09.471  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:45:09.473  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 57 (count at Application.java:147) as input to shuffle 1
2022-07-30 11:45:09.474  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 2 (count at Application.java:147) with 1 output partitions
2022-07-30 11:45:09.474  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 4 (count at Application.java:147)
2022-07-30 11:45:09.474  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 3)
2022-07-30 11:45:09.474  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:45:09.476  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 4 (MapPartitionsRDD[60] at count at Application.java:147), which has no missing parents
2022-07-30 11:45:09.479  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_2 stored as values in memory (estimated size 11.0 KiB, free 841.6 MiB)
2022-07-30 11:45:09.484  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 841.5 MiB)
2022-07-30 11:45:09.489  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_2_piece0 in memory on host.docker.internal:58598 (size: 5.4 KiB, free: 841.7 MiB)
2022-07-30 11:45:09.490  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 2 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:45:09.491  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[60] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:45:09.491  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 4.0 with 1 tasks resource profile 0
2022-07-30 11:45:09.493  INFO   57 --- [er-event-loop-1] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 4.0 (TID 2) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:45:09.494  INFO   57 --- [age 4.0 (TID 2)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 4.0 (TID 2)
2022-07-30 11:45:09.506  INFO   57 --- [age 4.0 (TID 2)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:45:09.506  INFO   57 --- [age 4.0 (TID 2)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 1 ms
2022-07-30 11:45:09.509  INFO   57 --- [age 4.0 (TID 2)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 4.0 (TID 2). 2598 bytes result sent to driver
2022-07-30 11:45:09.512  INFO   57 --- [result-getter-1] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 4.0 (TID 2) in 20 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:45:09.513  INFO   57 --- [result-getter-1] org.apache.spark.internal.Logging        : Removed TaskSet 4.0, whose tasks have all completed, from pool 
2022-07-30 11:45:09.514  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 4 (count at Application.java:147) finished in 0.037 s
2022-07-30 11:45:09.515  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:45:09.515  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 4: Stage finished
2022-07-30 11:45:09.515  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 2 finished: count at Application.java:147, took 0.043501 s
2022-07-30 11:45:09.518  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177890000 ms.0 from job set of time 1659177890000 ms
2022-07-30 11:45:09.522  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 19.518 s for time 1659177890000 ms (execution: 0.215 s)
2022-07-30 11:45:09.522  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177891000 ms.0 from job set of time 1659177891000 ms
2022-07-30 11:45:09.524  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:45:09.524  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:45:09.525  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 2 from persistence list
2022-07-30 11:45:09.565  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 1 from persistence list
2022-07-30 11:45:09.567  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[1] at receiverStream at Application.java:122 of time 1659177890000 ms
2022-07-30 11:45:09.572  INFO   57 --- [c-thread-pool-0] org.apache.spark.internal.Logging        : Removing RDD 2
2022-07-30 11:45:09.569  INFO   57 --- [c-thread-pool-1] org.apache.spark.internal.Logging        : Removing RDD 1
2022-07-30 11:45:09.572  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 
2022-07-30 11:45:09.578  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 
2022-07-30 11:45:09.712  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:45:09.717  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 66 (count at Application.java:147) as input to shuffle 2
2022-07-30 11:45:09.718  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 3 (count at Application.java:147) with 1 output partitions
2022-07-30 11:45:09.719  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 6 (count at Application.java:147)
2022-07-30 11:45:09.722  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 5)
2022-07-30 11:45:09.723  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:45:09.724  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 6 (MapPartitionsRDD[69] at count at Application.java:147), which has no missing parents
2022-07-30 11:45:09.739  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_3 stored as values in memory (estimated size 11.0 KiB, free 841.5 MiB)
2022-07-30 11:45:09.774  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_3_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 841.5 MiB)
2022-07-30 11:45:09.775  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_3_piece0 in memory on host.docker.internal:58598 (size: 5.4 KiB, free: 841.7 MiB)
2022-07-30 11:45:09.776  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 3 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:45:09.777  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[69] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:45:09.780  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 6.0 with 1 tasks resource profile 0
2022-07-30 11:45:09.785  INFO   57 --- [er-event-loop-0] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 6.0 (TID 3) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:45:09.789  INFO   57 --- [age 6.0 (TID 3)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 6.0 (TID 3)
2022-07-30 11:45:09.802  INFO   57 --- [age 6.0 (TID 3)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:45:09.806  INFO   57 --- [age 6.0 (TID 3)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 4 ms
2022-07-30 11:45:09.810  INFO   57 --- [age 6.0 (TID 3)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 6.0 (TID 3). 2555 bytes result sent to driver
2022-07-30 11:45:09.812  INFO   57 --- [result-getter-2] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 6.0 (TID 3) in 28 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:45:09.812  INFO   57 --- [result-getter-2] org.apache.spark.internal.Logging        : Removed TaskSet 6.0, whose tasks have all completed, from pool 
2022-07-30 11:45:09.814  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 6 (count at Application.java:147) finished in 0.083 s
2022-07-30 11:45:09.814  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:45:09.814  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 6: Stage finished
2022-07-30 11:45:09.815  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 3 finished: count at Application.java:147, took 0.102598 s
2022-07-30 11:45:09.823  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:45:09.823  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:45:09.826  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177891000 ms.0 from job set of time 1659177891000 ms
2022-07-30 11:45:09.828  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 18.826 s for time 1659177891000 ms (execution: 0.304 s)
2022-07-30 11:45:09.829  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 5 from persistence list
2022-07-30 11:45:09.829  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177892000 ms.0 from job set of time 1659177892000 ms
2022-07-30 11:45:09.831  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 4 from persistence list
2022-07-30 11:45:09.833  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[4] at receiverStream at Application.java:122 of time 1659177891000 ms
2022-07-30 11:45:09.833  INFO   57 --- [c-thread-pool-6] org.apache.spark.internal.Logging        : Removing RDD 5
2022-07-30 11:45:09.834  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177889000 ms
2022-07-30 11:45:09.835  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177889000 ms
2022-07-30 11:45:09.834  INFO   57 --- [c-thread-pool-7] org.apache.spark.internal.Logging        : Removing RDD 4
2022-07-30 11:45:10.001  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:45:10.007  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177910000 ms
2022-07-30 11:45:10.007  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 75 (count at Application.java:147) as input to shuffle 3
2022-07-30 11:45:10.008  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 4 (count at Application.java:147) with 1 output partitions
2022-07-30 11:45:10.008  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 8 (count at Application.java:147)
2022-07-30 11:45:10.009  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 7)
2022-07-30 11:45:10.009  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:45:10.010  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 8 (MapPartitionsRDD[78] at count at Application.java:147), which has no missing parents
2022-07-30 11:45:10.022  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_4 stored as values in memory (estimated size 11.0 KiB, free 841.5 MiB)
2022-07-30 11:45:10.025  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_4_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 841.5 MiB)
2022-07-30 11:45:10.026  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_2_piece0 on host.docker.internal:58598 in memory (size: 5.4 KiB, free: 841.7 MiB)
2022-07-30 11:45:10.029  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_4_piece0 in memory on host.docker.internal:58598 (size: 5.4 KiB, free: 841.7 MiB)
2022-07-30 11:45:10.030  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 4 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:45:10.031  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[78] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:45:10.031  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 8.0 with 1 tasks resource profile 0
2022-07-30 11:45:10.033  INFO   57 --- [er-event-loop-3] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 8.0 (TID 4) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:45:10.034  INFO   57 --- [age 8.0 (TID 4)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 8.0 (TID 4)
2022-07-30 11:45:10.040  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_3_piece0 on host.docker.internal:58598 in memory (size: 5.4 KiB, free: 841.7 MiB)
2022-07-30 11:45:10.045  INFO   57 --- [age 8.0 (TID 4)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:45:10.045  INFO   57 --- [age 8.0 (TID 4)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 1 ms
2022-07-30 11:45:10.047  INFO   57 --- [age 8.0 (TID 4)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 8.0 (TID 4). 2598 bytes result sent to driver
2022-07-30 11:45:10.050  INFO   57 --- [result-getter-3] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 8.0 (TID 4) in 17 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:45:10.051  INFO   57 --- [result-getter-3] org.apache.spark.internal.Logging        : Removed TaskSet 8.0, whose tasks have all completed, from pool 
2022-07-30 11:45:10.052  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_1_piece0 on host.docker.internal:58598 in memory (size: 5.4 KiB, free: 841.7 MiB)
2022-07-30 11:45:10.053  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 8 (count at Application.java:147) finished in 0.039 s
2022-07-30 11:45:10.055  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:45:10.055  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 8: Stage finished
2022-07-30 11:45:10.055  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 4 finished: count at Application.java:147, took 0.053077 s
2022-07-30 11:45:10.057  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177892000 ms.0 from job set of time 1659177892000 ms
2022-07-30 11:45:10.058  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 18.057 s for time 1659177892000 ms (execution: 0.229 s)
2022-07-30 11:45:10.058  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177893000 ms.0 from job set of time 1659177893000 ms
2022-07-30 11:45:10.060  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 7 from persistence list
2022-07-30 11:45:10.062  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 6 from persistence list
2022-07-30 11:45:10.063  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:45:10.064  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:45:10.068  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[6] at receiverStream at Application.java:122 of time 1659177892000 ms
2022-07-30 11:45:10.068  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177890000 ms
2022-07-30 11:45:10.069  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177890000 ms
2022-07-30 11:45:10.107  INFO   57 --- [-thread-pool-30] org.apache.spark.internal.Logging        : Removing RDD 7
2022-07-30 11:45:10.108  INFO   57 --- [-thread-pool-31] org.apache.spark.internal.Logging        : Removing RDD 6
2022-07-30 11:45:10.200  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:45:10.202  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 86 (count at Application.java:147) as input to shuffle 4
2022-07-30 11:45:10.202  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 5 (count at Application.java:147) with 1 output partitions
2022-07-30 11:45:10.203  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 10 (count at Application.java:147)
2022-07-30 11:45:10.203  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 9)
2022-07-30 11:45:10.203  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:45:10.205  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 10 (MapPartitionsRDD[89] at count at Application.java:147), which has no missing parents
2022-07-30 11:45:10.208  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_5 stored as values in memory (estimated size 11.0 KiB, free 841.6 MiB)
2022-07-30 11:45:10.212  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_5_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 841.5 MiB)
2022-07-30 11:45:10.214  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_5_piece0 in memory on host.docker.internal:58598 (size: 5.4 KiB, free: 841.7 MiB)
2022-07-30 11:45:10.215  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 5 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:45:10.216  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[89] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:45:10.216  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 10.0 with 1 tasks resource profile 0
2022-07-30 11:45:10.230  INFO   57 --- [er-event-loop-2] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 10.0 (TID 5) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:45:10.231  INFO   57 --- [ge 10.0 (TID 5)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 10.0 (TID 5)
2022-07-30 11:45:10.240  INFO   57 --- [ge 10.0 (TID 5)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:45:10.240  INFO   57 --- [ge 10.0 (TID 5)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-30 11:45:10.242  INFO   57 --- [ge 10.0 (TID 5)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 10.0 (TID 5). 2598 bytes result sent to driver
2022-07-30 11:45:10.244  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 10.0 (TID 5) in 15 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:45:10.244  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Removed TaskSet 10.0, whose tasks have all completed, from pool 
2022-07-30 11:45:10.245  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 10 (count at Application.java:147) finished in 0.039 s
2022-07-30 11:45:10.246  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:45:10.246  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 10: Stage finished
2022-07-30 11:45:10.247  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 5 finished: count at Application.java:147, took 0.046446 s
2022-07-30 11:45:10.256  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177893000 ms.0 from job set of time 1659177893000 ms
2022-07-30 11:45:10.257  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 17.248 s for time 1659177893000 ms (execution: 0.190 s)
2022-07-30 11:45:10.258  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177894000 ms.0 from job set of time 1659177894000 ms
2022-07-30 11:45:10.259  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:45:10.259  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:45:10.262  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 10 from persistence list
2022-07-30 11:45:10.276  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 9 from persistence list
2022-07-30 11:45:10.280  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[9] at receiverStream at Application.java:122 of time 1659177893000 ms
2022-07-30 11:45:10.290  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177891000 ms
2022-07-30 11:45:10.291  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177891000 ms
2022-07-30 11:45:10.324  INFO   57 --- [-thread-pool-36] org.apache.spark.internal.Logging        : Removing RDD 10
2022-07-30 11:45:10.325  INFO   57 --- [-thread-pool-37] org.apache.spark.internal.Logging        : Removing RDD 9
2022-07-30 11:45:10.478  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:45:10.479  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 95 (count at Application.java:147) as input to shuffle 5
2022-07-30 11:45:10.480  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 6 (count at Application.java:147) with 1 output partitions
2022-07-30 11:45:10.480  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 12 (count at Application.java:147)
2022-07-30 11:45:10.480  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 11)
2022-07-30 11:45:10.480  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:45:10.482  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 12 (MapPartitionsRDD[98] at count at Application.java:147), which has no missing parents
2022-07-30 11:45:10.493  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_6 stored as values in memory (estimated size 11.0 KiB, free 841.5 MiB)
2022-07-30 11:45:10.496  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_6_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 841.5 MiB)
2022-07-30 11:45:10.497  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_6_piece0 in memory on host.docker.internal:58598 (size: 5.4 KiB, free: 841.7 MiB)
2022-07-30 11:45:10.498  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 6 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:45:10.500  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[98] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:45:10.501  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 12.0 with 1 tasks resource profile 0
2022-07-30 11:45:10.505  INFO   57 --- [er-event-loop-1] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 12.0 (TID 6) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:45:10.507  INFO   57 --- [ge 12.0 (TID 6)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 12.0 (TID 6)
2022-07-30 11:45:10.512  INFO   57 --- [ge 12.0 (TID 6)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:45:10.512  INFO   57 --- [ge 12.0 (TID 6)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-30 11:45:10.517  INFO   57 --- [ge 12.0 (TID 6)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 12.0 (TID 6). 2598 bytes result sent to driver
2022-07-30 11:45:10.523  INFO   57 --- [result-getter-1] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 12.0 (TID 6) in 20 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:45:10.523  INFO   57 --- [result-getter-1] org.apache.spark.internal.Logging        : Removed TaskSet 12.0, whose tasks have all completed, from pool 
2022-07-30 11:45:10.524  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 12 (count at Application.java:147) finished in 0.035 s
2022-07-30 11:45:10.524  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:45:10.525  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 12: Stage finished
2022-07-30 11:45:10.525  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 6 finished: count at Application.java:147, took 0.047195 s
2022-07-30 11:45:10.538  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177894000 ms.0 from job set of time 1659177894000 ms
2022-07-30 11:45:10.539  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 16.538 s for time 1659177894000 ms (execution: 0.281 s)
2022-07-30 11:45:10.540  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:45:10.540  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:45:10.539  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177895000 ms.0 from job set of time 1659177895000 ms
2022-07-30 11:45:10.544  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 12 from persistence list
2022-07-30 11:45:10.546  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 11 from persistence list
2022-07-30 11:45:10.562  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[11] at receiverStream at Application.java:122 of time 1659177894000 ms
2022-07-30 11:45:10.563  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177892000 ms
2022-07-30 11:45:10.564  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177892000 ms
2022-07-30 11:45:10.566  INFO   57 --- [-thread-pool-42] org.apache.spark.internal.Logging        : Removing RDD 12
2022-07-30 11:45:10.566  INFO   57 --- [-thread-pool-43] org.apache.spark.internal.Logging        : Removing RDD 11
2022-07-30 11:45:10.675  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:45:10.677  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 104 (count at Application.java:147) as input to shuffle 6
2022-07-30 11:45:10.678  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 7 (count at Application.java:147) with 1 output partitions
2022-07-30 11:45:10.678  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 14 (count at Application.java:147)
2022-07-30 11:45:10.679  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 13)
2022-07-30 11:45:10.679  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:45:10.681  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 14 (MapPartitionsRDD[107] at count at Application.java:147), which has no missing parents
2022-07-30 11:45:10.689  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_7 stored as values in memory (estimated size 11.0 KiB, free 841.5 MiB)
2022-07-30 11:45:10.731  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_7_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 841.5 MiB)
2022-07-30 11:45:10.734  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_7_piece0 in memory on host.docker.internal:58598 (size: 5.4 KiB, free: 841.7 MiB)
2022-07-30 11:45:10.739  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 7 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:45:10.740  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[107] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:45:10.740  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 14.0 with 1 tasks resource profile 0
2022-07-30 11:45:10.741  INFO   57 --- [er-event-loop-0] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 14.0 (TID 7) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:45:10.742  INFO   57 --- [ge 14.0 (TID 7)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 14.0 (TID 7)
2022-07-30 11:45:10.759  INFO   57 --- [ge 14.0 (TID 7)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:45:10.760  INFO   57 --- [ge 14.0 (TID 7)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 1 ms
2022-07-30 11:45:10.776  INFO   57 --- [ge 14.0 (TID 7)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 14.0 (TID 7). 2555 bytes result sent to driver
2022-07-30 11:45:10.785  INFO   57 --- [result-getter-2] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 14.0 (TID 7) in 43 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:45:10.791  INFO   57 --- [result-getter-2] org.apache.spark.internal.Logging        : Removed TaskSet 14.0, whose tasks have all completed, from pool 
2022-07-30 11:45:10.801  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 14 (count at Application.java:147) finished in 0.117 s
2022-07-30 11:45:10.802  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:45:10.802  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 14: Stage finished
2022-07-30 11:45:10.805  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 7 finished: count at Application.java:147, took 0.129563 s
2022-07-30 11:45:10.810  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:45:10.810  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:45:10.813  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177895000 ms.0 from job set of time 1659177895000 ms
2022-07-30 11:45:10.814  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 15.813 s for time 1659177895000 ms (execution: 0.274 s)
2022-07-30 11:45:10.814  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177896000 ms.0 from job set of time 1659177896000 ms
2022-07-30 11:45:10.865  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 14 from persistence list
2022-07-30 11:45:10.868  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 13 from persistence list
2022-07-30 11:45:10.872  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[13] at receiverStream at Application.java:122 of time 1659177895000 ms
2022-07-30 11:45:10.873  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177893000 ms
2022-07-30 11:45:10.873  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177893000 ms
2022-07-30 11:45:10.943  INFO   57 --- [-thread-pool-48] org.apache.spark.internal.Logging        : Removing RDD 14
2022-07-30 11:45:10.945  INFO   57 --- [-thread-pool-49] org.apache.spark.internal.Logging        : Removing RDD 13
2022-07-30 11:45:10.960  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: show at Application.java:146
2022-07-30 11:45:10.962  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 8 (show at Application.java:146) with 1 output partitions
2022-07-30 11:45:10.962  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 15 (show at Application.java:146)
2022-07-30 11:45:10.963  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List()
2022-07-30 11:45:10.963  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:45:10.976  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 15 (MapPartitionsRDD[111] at show at Application.java:146), which has no missing parents
2022-07-30 11:45:11.012  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177911000 ms
2022-07-30 11:45:11.017  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_8 stored as values in memory (estimated size 12.9 KiB, free 841.5 MiB)
2022-07-30 11:45:11.022  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_8_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 841.5 MiB)
2022-07-30 11:45:11.023  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_8_piece0 in memory on host.docker.internal:58598 (size: 5.8 KiB, free: 841.7 MiB)
2022-07-30 11:45:11.024  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 8 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:45:11.025  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[111] at show at Application.java:146) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:45:11.025  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 15.0 with 1 tasks resource profile 0
2022-07-30 11:45:11.028  INFO   57 --- [er-event-loop-3] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 15.0 (TID 8) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
2022-07-30 11:45:11.029  INFO   57 --- [ge 15.0 (TID 8)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 15.0 (TID 8)
2022-07-30 11:45:11.063  INFO   57 --- [ge 15.0 (TID 8)] org.apache.spark.internal.Logging        : Found block input-0-1659177889817 locally
2022-07-30 11:45:11.239  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_4_piece0 on host.docker.internal:58598 in memory (size: 5.4 KiB, free: 841.7 MiB)
2022-07-30 11:45:11.306  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_6_piece0 on host.docker.internal:58598 in memory (size: 5.4 KiB, free: 841.7 MiB)
2022-07-30 11:45:11.314  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_7_piece0 on host.docker.internal:58598 in memory (size: 5.4 KiB, free: 841.7 MiB)
2022-07-30 11:45:11.321  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_5_piece0 on host.docker.internal:58598 in memory (size: 5.4 KiB, free: 841.7 MiB)
2022-07-30 11:45:12.003  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177912000 ms
2022-07-30 11:45:12.271  INFO   57 --- [ge 15.0 (TID 8)] org.apache.spark.internal.Logging        : 1 block locks were not released by task 0.0 in stage 15.0 (TID 8)
[input-0-1659177889817]
2022-07-30 11:45:12.274  INFO   57 --- [ge 15.0 (TID 8)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 15.0 (TID 8). 2167 bytes result sent to driver
2022-07-30 11:45:12.275  INFO   57 --- [result-getter-3] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 15.0 (TID 8) in 1248 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:45:12.276  INFO   57 --- [result-getter-3] org.apache.spark.internal.Logging        : Removed TaskSet 15.0, whose tasks have all completed, from pool 
2022-07-30 11:45:12.277  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 15 (show at Application.java:146) finished in 1.282 s
2022-07-30 11:45:12.278  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:45:12.278  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 15: Stage finished
2022-07-30 11:45:12.279  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 8 finished: show at Application.java:146, took 1.317628 s
2022-07-30 11:45:12.402  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Code generated in 78.5851 ms
2022-07-30 11:45:12.479  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 117 (count at Application.java:147) as input to shuffle 7
2022-07-30 11:45:12.480  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got map stage job 9 (count at Application.java:147) with 1 output partitions
2022-07-30 11:45:12.481  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ShuffleMapStage 16 (count at Application.java:147)
2022-07-30 11:45:12.481  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List()
2022-07-30 11:45:12.482  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:45:12.485  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ShuffleMapStage 16 (MapPartitionsRDD[117] at count at Application.java:147), which has no missing parents
2022-07-30 11:45:12.517  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_9 stored as values in memory (estimated size 13.6 KiB, free 841.6 MiB)
2022-07-30 11:45:12.521  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_9_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 841.5 MiB)
2022-07-30 11:45:12.524  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_9_piece0 in memory on host.docker.internal:58598 (size: 6.7 KiB, free: 841.7 MiB)
2022-07-30 11:45:12.525  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 9 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:45:12.527  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ShuffleMapStage 16 (MapPartitionsRDD[117] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:45:12.527  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 16.0 with 1 tasks resource profile 0
2022-07-30 11:45:12.530  INFO   57 --- [er-event-loop-2] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 16.0 (TID 9) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4383 bytes) taskResourceAssignments Map()
2022-07-30 11:45:12.531  INFO   57 --- [ge 16.0 (TID 9)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 16.0 (TID 9)
2022-07-30 11:45:12.569  INFO   57 --- [ge 16.0 (TID 9)] org.apache.spark.internal.Logging        : Found block input-0-1659177889817 locally
2022-07-30 11:45:12.876  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_8_piece0 on host.docker.internal:58598 in memory (size: 5.8 KiB, free: 841.7 MiB)
2022-07-30 11:45:13.003  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177913000 ms
2022-07-30 11:45:14.005  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177914000 ms
2022-07-30 11:45:14.049  INFO   57 --- [ge 16.0 (TID 9)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 16.0 (TID 9). 1924 bytes result sent to driver
2022-07-30 11:45:14.051  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 16.0 (TID 9) in 1523 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:45:14.051  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Removed TaskSet 16.0, whose tasks have all completed, from pool 
2022-07-30 11:45:14.059  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ShuffleMapStage 16 (count at Application.java:147) finished in 1.561 s
2022-07-30 11:45:14.060  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : looking for newly runnable stages
2022-07-30 11:45:14.060  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : running: Set(ResultStage 0)
2022-07-30 11:45:14.061  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : waiting: Set()
2022-07-30 11:45:14.061  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : failed: Set()
2022-07-30 11:45:14.084  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:45:14.085  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 10 (count at Application.java:147) with 1 output partitions
2022-07-30 11:45:14.085  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 18 (count at Application.java:147)
2022-07-30 11:45:14.085  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 17)
2022-07-30 11:45:14.086  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:45:14.087  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 18 (MapPartitionsRDD[124] at count at Application.java:147), which has no missing parents
2022-07-30 11:45:14.094  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_10 stored as values in memory (estimated size 11.0 KiB, free 841.6 MiB)
2022-07-30 11:45:14.097  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_10_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 841.5 MiB)
2022-07-30 11:45:14.098  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_10_piece0 in memory on host.docker.internal:58598 (size: 5.5 KiB, free: 841.7 MiB)
2022-07-30 11:45:14.099  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 10 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:45:14.099  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[124] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:45:14.100  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 18.0 with 1 tasks resource profile 0
2022-07-30 11:45:14.102  INFO   57 --- [er-event-loop-1] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 18.0 (TID 10) (host.docker.internal, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:45:14.103  INFO   57 --- [e 18.0 (TID 10)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 18.0 (TID 10)
2022-07-30 11:45:14.114  INFO   57 --- [e 18.0 (TID 10)] org.apache.spark.internal.Logging        : Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:45:14.114  INFO   57 --- [e 18.0 (TID 10)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 4 ms
2022-07-30 11:45:14.134  INFO   57 --- [e 18.0 (TID 10)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 18.0 (TID 10). 2648 bytes result sent to driver
2022-07-30 11:45:14.136  INFO   57 --- [result-getter-1] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 18.0 (TID 10) in 34 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:45:14.136  INFO   57 --- [result-getter-1] org.apache.spark.internal.Logging        : Removed TaskSet 18.0, whose tasks have all completed, from pool 
2022-07-30 11:45:14.137  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 18 (count at Application.java:147) finished in 0.045 s
2022-07-30 11:45:14.138  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 10 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:45:14.138  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 18: Stage finished
2022-07-30 11:45:14.139  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 10 finished: count at Application.java:147, took 0.054717 s
2022-07-30 11:45:15.004  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177915000 ms
2022-07-30 11:45:16.002  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177916000 ms
2022-07-30 11:45:17.004  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177917000 ms
2022-07-30 11:45:18.001  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177918000 ms
2022-07-30 11:45:18.533  INFO  142 --- [-job-executor-0] mapreduce.lib.output.FileOutputCommitter : File Output Committer Algorithm version is 1
2022-07-30 11:45:18.533  INFO  157 --- [-job-executor-0] mapreduce.lib.output.FileOutputCommitter : FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2022-07-30 11:45:18.535  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2022-07-30 11:45:18.692  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: csv at Application.java:148
2022-07-30 11:45:18.694  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 11 (csv at Application.java:148) with 1 output partitions
2022-07-30 11:45:18.694  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 19 (csv at Application.java:148)
2022-07-30 11:45:18.694  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List()
2022-07-30 11:45:18.694  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:45:18.695  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 19 (MapPartitionsRDD[133] at csv at Application.java:148), which has no missing parents
2022-07-30 11:45:18.731  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_11 stored as values in memory (estimated size 206.8 KiB, free 841.3 MiB)
2022-07-30 11:45:18.735  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_11_piece0 stored as bytes in memory (estimated size 74.0 KiB, free 841.3 MiB)
2022-07-30 11:45:18.737  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_11_piece0 in memory on host.docker.internal:58598 (size: 74.0 KiB, free: 841.6 MiB)
2022-07-30 11:45:18.738  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 11 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:45:18.739  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[133] at csv at Application.java:148) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:45:18.739  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 19.0 with 1 tasks resource profile 0
2022-07-30 11:45:18.740  INFO   57 --- [er-event-loop-2] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 19.0 (TID 11) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
2022-07-30 11:45:18.741  INFO   57 --- [e 19.0 (TID 11)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 19.0 (TID 11)
2022-07-30 11:45:18.794  INFO   57 --- [e 19.0 (TID 11)] org.apache.spark.internal.Logging        : Found block input-0-1659177889817 locally
2022-07-30 11:45:18.797  INFO  142 --- [e 19.0 (TID 11)] mapreduce.lib.output.FileOutputCommitter : File Output Committer Algorithm version is 1
2022-07-30 11:45:18.799  INFO  157 --- [e 19.0 (TID 11)] mapreduce.lib.output.FileOutputCommitter : FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2022-07-30 11:45:18.800  INFO   57 --- [e 19.0 (TID 11)] org.apache.spark.internal.Logging        : Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2022-07-30 11:45:19.002  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177919000 ms
2022-07-30 11:45:19.391  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_10_piece0 on host.docker.internal:58598 in memory (size: 5.5 KiB, free: 841.6 MiB)
2022-07-30 11:45:20.003  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177920000 ms
2022-07-30 11:45:20.368  INFO  604 --- [e 19.0 (TID 11)] mapreduce.lib.output.FileOutputCommitter : Saved output of task 'attempt_202207301145186181453367712769092_0019_m_000000_11' to hdfs://localhost:9000/user/dataFromSpark/file1/_temporary/0/task_202207301145186181453367712769092_0019_m_000000
2022-07-30 11:45:20.368  INFO   57 --- [e 19.0 (TID 11)] org.apache.spark.internal.Logging        : attempt_202207301145186181453367712769092_0019_m_000000_11: Committed
2022-07-30 11:45:20.392  INFO   57 --- [e 19.0 (TID 11)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 19.0 (TID 11). 2515 bytes result sent to driver
2022-07-30 11:45:20.396  INFO   57 --- [result-getter-2] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 19.0 (TID 11) in 1656 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:45:20.396  INFO   57 --- [result-getter-2] org.apache.spark.internal.Logging        : Removed TaskSet 19.0, whose tasks have all completed, from pool 
2022-07-30 11:45:20.398  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 19 (csv at Application.java:148) finished in 1.702 s
2022-07-30 11:45:20.399  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 11 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:45:20.399  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 19: Stage finished
2022-07-30 11:45:20.400  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 11 finished: csv at Application.java:148, took 1.707345 s
2022-07-30 11:45:20.402  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Start to commit write Job 9ddb40b4-f847-40fa-809d-557b65cf2515.
2022-07-30 11:45:20.585  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Write Job 9ddb40b4-f847-40fa-809d-557b65cf2515 committed. Elapsed time: 179 ms.
2022-07-30 11:45:20.603  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Finished processing stats for write job 9ddb40b4-f847-40fa-809d-557b65cf2515.
2022-07-30 11:45:20.613  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177896000 ms.0 from job set of time 1659177896000 ms
2022-07-30 11:45:20.614  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 24.613 s for time 1659177896000 ms (execution: 9.799 s)
2022-07-30 11:45:20.615  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 16 from persistence list
2022-07-30 11:45:20.615  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177897000 ms.0 from job set of time 1659177897000 ms
2022-07-30 11:45:20.616  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 15 from persistence list
2022-07-30 11:45:20.617  INFO   57 --- [-thread-pool-84] org.apache.spark.internal.Logging        : Removing RDD 16
2022-07-30 11:45:20.619  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[15] at receiverStream at Application.java:122 of time 1659177896000 ms
2022-07-30 11:45:20.621  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177894000 ms
2022-07-30 11:45:20.622  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177894000 ms
2022-07-30 11:45:20.623  INFO   57 --- [-thread-pool-87] org.apache.spark.internal.Logging        : Removing RDD 15
2022-07-30 11:45:20.625  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:45:20.625  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:45:20.776  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:45:20.778  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 143 (count at Application.java:147) as input to shuffle 8
2022-07-30 11:45:20.779  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 12 (count at Application.java:147) with 1 output partitions
2022-07-30 11:45:20.779  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 21 (count at Application.java:147)
2022-07-30 11:45:20.779  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 20)
2022-07-30 11:45:20.780  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:45:20.780  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 21 (MapPartitionsRDD[146] at count at Application.java:147), which has no missing parents
2022-07-30 11:45:20.783  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_12 stored as values in memory (estimated size 11.0 KiB, free 841.3 MiB)
2022-07-30 11:45:20.791  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_12_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 841.3 MiB)
2022-07-30 11:45:20.793  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_12_piece0 in memory on host.docker.internal:58598 (size: 5.4 KiB, free: 841.6 MiB)
2022-07-30 11:45:20.795  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 12 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:45:20.796  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 21 (MapPartitionsRDD[146] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:45:20.796  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 21.0 with 1 tasks resource profile 0
2022-07-30 11:45:20.800  INFO   57 --- [er-event-loop-2] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 21.0 (TID 12) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:45:20.801  INFO   57 --- [e 21.0 (TID 12)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 21.0 (TID 12)
2022-07-30 11:45:20.808  INFO   57 --- [e 21.0 (TID 12)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:45:20.808  INFO   57 --- [e 21.0 (TID 12)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-30 11:45:20.811  INFO   57 --- [e 21.0 (TID 12)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 21.0 (TID 12). 2555 bytes result sent to driver
2022-07-30 11:45:20.814  INFO   57 --- [result-getter-3] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 21.0 (TID 12) in 15 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:45:20.814  INFO   57 --- [result-getter-3] org.apache.spark.internal.Logging        : Removed TaskSet 21.0, whose tasks have all completed, from pool 
2022-07-30 11:45:20.818  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 21 (count at Application.java:147) finished in 0.036 s
2022-07-30 11:45:20.818  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 12 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:45:20.819  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 21: Stage finished
2022-07-30 11:45:20.819  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 12 finished: count at Application.java:147, took 0.041825 s
2022-07-30 11:45:20.823  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177897000 ms.0 from job set of time 1659177897000 ms
2022-07-30 11:45:20.823  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 23.823 s for time 1659177897000 ms (execution: 0.208 s)
2022-07-30 11:45:20.824  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177898000 ms.0 from job set of time 1659177898000 ms
2022-07-30 11:45:20.829  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 18 from persistence list
2022-07-30 11:45:20.831  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:45:20.831  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:45:20.836  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 17 from persistence list
2022-07-30 11:45:20.840  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[17] at receiverStream at Application.java:122 of time 1659177897000 ms
2022-07-30 11:45:20.850  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177895000 ms
2022-07-30 11:45:20.850  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177895000 ms
2022-07-30 11:45:20.894  INFO   57 --- [-thread-pool-90] org.apache.spark.internal.Logging        : Removing RDD 18
2022-07-30 11:45:20.895  INFO   57 --- [-thread-pool-91] org.apache.spark.internal.Logging        : Removing RDD 17
2022-07-30 11:45:20.899  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed input-0-1659177889817 on host.docker.internal:58598 in memory (size: 55.9 MiB, free: 897.5 MiB)
2022-07-30 11:45:20.995  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:45:20.996  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 152 (count at Application.java:147) as input to shuffle 9
2022-07-30 11:45:20.997  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 13 (count at Application.java:147) with 1 output partitions
2022-07-30 11:45:20.997  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 23 (count at Application.java:147)
2022-07-30 11:45:20.997  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 22)
2022-07-30 11:45:20.997  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:45:20.998  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 23 (MapPartitionsRDD[155] at count at Application.java:147), which has no missing parents
2022-07-30 11:45:21.004  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_13 stored as values in memory (estimated size 11.0 KiB, free 897.2 MiB)
2022-07-30 11:45:21.007  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177921000 ms
2022-07-30 11:45:21.010  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_13_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.1 MiB)
2022-07-30 11:45:21.011  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_13_piece0 in memory on host.docker.internal:58598 (size: 5.4 KiB, free: 897.5 MiB)
2022-07-30 11:45:21.012  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 13 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:45:21.012  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 23 (MapPartitionsRDD[155] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:45:21.012  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 23.0 with 1 tasks resource profile 0
2022-07-30 11:45:21.014  INFO   57 --- [er-event-loop-1] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 23.0 (TID 13) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:45:21.014  INFO   57 --- [e 23.0 (TID 13)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 23.0 (TID 13)
2022-07-30 11:45:21.018  INFO   57 --- [e 23.0 (TID 13)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:45:21.018  INFO   57 --- [e 23.0 (TID 13)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-30 11:45:21.021  INFO   57 --- [e 23.0 (TID 13)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 23.0 (TID 13). 2555 bytes result sent to driver
2022-07-30 11:45:21.022  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 23.0 (TID 13) in 9 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:45:21.022  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Removed TaskSet 23.0, whose tasks have all completed, from pool 
2022-07-30 11:45:21.023  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 23 (count at Application.java:147) finished in 0.023 s
2022-07-30 11:45:21.024  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 13 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:45:21.024  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 23: Stage finished
2022-07-30 11:45:21.026  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 13 finished: count at Application.java:147, took 0.030871 s
2022-07-30 11:45:21.035  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177898000 ms.0 from job set of time 1659177898000 ms
2022-07-30 11:45:21.039  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 23.035 s for time 1659177898000 ms (execution: 0.211 s)
2022-07-30 11:45:21.039  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:45:21.040  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:45:21.051  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 20 from persistence list
2022-07-30 11:45:21.039  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177899000 ms.0 from job set of time 1659177899000 ms
2022-07-30 11:45:21.056  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 19 from persistence list
2022-07-30 11:45:21.058  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[19] at receiverStream at Application.java:122 of time 1659177898000 ms
2022-07-30 11:45:21.059  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177896000 ms
2022-07-30 11:45:21.059  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177896000 ms
2022-07-30 11:45:21.060  INFO   57 --- [c-thread-pool-0] org.apache.spark.internal.Logging        : Removing RDD 19
2022-07-30 11:45:21.083  INFO   57 --- [-thread-pool-99] org.apache.spark.internal.Logging        : Removing RDD 20
2022-07-30 11:45:21.352  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:45:21.408  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 163 (count at Application.java:147) as input to shuffle 10
2022-07-30 11:45:21.410  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 14 (count at Application.java:147) with 1 output partitions
2022-07-30 11:45:21.410  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 25 (count at Application.java:147)
2022-07-30 11:45:21.410  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 24)
2022-07-30 11:45:21.410  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:45:21.411  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 25 (MapPartitionsRDD[166] at count at Application.java:147), which has no missing parents
2022-07-30 11:45:21.454  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_14 stored as values in memory (estimated size 11.0 KiB, free 897.1 MiB)
2022-07-30 11:45:21.464  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_13_piece0 on host.docker.internal:58598 in memory (size: 5.4 KiB, free: 897.5 MiB)
2022-07-30 11:45:21.643  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_14_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.1 MiB)
2022-07-30 11:45:21.644  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_14_piece0 in memory on host.docker.internal:58598 (size: 5.4 KiB, free: 897.5 MiB)
2022-07-30 11:45:21.645  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 14 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:45:21.646  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 25 (MapPartitionsRDD[166] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:45:21.646  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 25.0 with 1 tasks resource profile 0
2022-07-30 11:45:21.648  INFO   57 --- [er-event-loop-0] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 25.0 (TID 14) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:45:21.656  INFO   57 --- [e 25.0 (TID 14)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 25.0 (TID 14)
2022-07-30 11:45:21.699  INFO   57 --- [e 25.0 (TID 14)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:45:21.699  INFO   57 --- [e 25.0 (TID 14)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 2 ms
2022-07-30 11:45:21.839  INFO   57 --- [e 25.0 (TID 14)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 25.0 (TID 14). 2555 bytes result sent to driver
2022-07-30 11:45:21.846  INFO   57 --- [result-getter-1] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 25.0 (TID 14) in 197 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:45:21.847  INFO   57 --- [result-getter-1] org.apache.spark.internal.Logging        : Removed TaskSet 25.0, whose tasks have all completed, from pool 
2022-07-30 11:45:21.856  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 25 (count at Application.java:147) finished in 0.440 s
2022-07-30 11:45:21.859  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 14 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:45:21.860  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 25: Stage finished
2022-07-30 11:45:21.869  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 14 finished: count at Application.java:147, took 0.505279 s
2022-07-30 11:45:21.881  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_12_piece0 on host.docker.internal:58598 in memory (size: 5.4 KiB, free: 897.5 MiB)
2022-07-30 11:45:22.007  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177922000 ms
2022-07-30 11:45:22.089  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177899000 ms.0 from job set of time 1659177899000 ms
2022-07-30 11:45:22.090  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 23.089 s for time 1659177899000 ms (execution: 1.050 s)
2022-07-30 11:45:22.093  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 22 from persistence list
2022-07-30 11:45:22.093  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177900000 ms.0 from job set of time 1659177900000 ms
2022-07-30 11:45:22.094  INFO   57 --- [-thread-pool-17] org.apache.spark.internal.Logging        : Removing RDD 22
2022-07-30 11:45:22.096  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 21 from persistence list
2022-07-30 11:45:22.100  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:45:22.100  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:45:22.106  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[21] at receiverStream at Application.java:122 of time 1659177899000 ms
2022-07-30 11:45:22.106  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177897000 ms
2022-07-30 11:45:22.107  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177897000 ms
2022-07-30 11:45:22.107  INFO   57 --- [-thread-pool-20] org.apache.spark.internal.Logging        : Removing RDD 21
2022-07-30 11:45:22.428  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:45:22.429  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 174 (count at Application.java:147) as input to shuffle 11
2022-07-30 11:45:22.430  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 15 (count at Application.java:147) with 1 output partitions
2022-07-30 11:45:22.430  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 27 (count at Application.java:147)
2022-07-30 11:45:22.430  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 26)
2022-07-30 11:45:22.430  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:45:22.431  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 27 (MapPartitionsRDD[177] at count at Application.java:147), which has no missing parents
2022-07-30 11:45:22.434  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_15 stored as values in memory (estimated size 11.0 KiB, free 897.2 MiB)
2022-07-30 11:45:22.439  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_15_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.1 MiB)
2022-07-30 11:45:22.441  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_15_piece0 in memory on host.docker.internal:58598 (size: 5.4 KiB, free: 897.5 MiB)
2022-07-30 11:45:22.442  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 15 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:45:22.443  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 27 (MapPartitionsRDD[177] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:45:22.444  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 27.0 with 1 tasks resource profile 0
2022-07-30 11:45:22.446  INFO   57 --- [er-event-loop-3] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 27.0 (TID 15) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:45:22.447  INFO   57 --- [e 27.0 (TID 15)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 27.0 (TID 15)
2022-07-30 11:45:22.452  INFO   57 --- [e 27.0 (TID 15)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:45:22.452  INFO   57 --- [e 27.0 (TID 15)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-30 11:45:22.455  INFO   57 --- [e 27.0 (TID 15)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 27.0 (TID 15). 2598 bytes result sent to driver
2022-07-30 11:45:22.456  INFO   57 --- [result-getter-2] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 27.0 (TID 15) in 11 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:45:22.456  INFO   57 --- [result-getter-2] org.apache.spark.internal.Logging        : Removed TaskSet 27.0, whose tasks have all completed, from pool 
2022-07-30 11:45:22.457  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 27 (count at Application.java:147) finished in 0.025 s
2022-07-30 11:45:22.458  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 15 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:45:22.458  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 27: Stage finished
2022-07-30 11:45:22.459  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 15 finished: count at Application.java:147, took 0.030657 s
2022-07-30 11:45:22.460  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177900000 ms.0 from job set of time 1659177900000 ms
2022-07-30 11:45:22.461  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 22.460 s for time 1659177900000 ms (execution: 0.367 s)
2022-07-30 11:45:22.461  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177901000 ms.0 from job set of time 1659177901000 ms
2022-07-30 11:45:22.464  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:45:22.464  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:45:22.465  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 24 from persistence list
2022-07-30 11:45:22.469  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 23 from persistence list
2022-07-30 11:45:22.470  INFO   57 --- [-thread-pool-23] org.apache.spark.internal.Logging        : Removing RDD 24
2022-07-30 11:45:22.476  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[23] at receiverStream at Application.java:122 of time 1659177900000 ms
2022-07-30 11:45:22.477  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177898000 ms
2022-07-30 11:45:22.478  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177898000 ms
2022-07-30 11:45:22.478  INFO   57 --- [-thread-pool-25] org.apache.spark.internal.Logging        : Removing RDD 23
2022-07-30 11:45:22.589  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:45:22.591  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 183 (count at Application.java:147) as input to shuffle 12
2022-07-30 11:45:22.591  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 16 (count at Application.java:147) with 1 output partitions
2022-07-30 11:45:22.591  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 29 (count at Application.java:147)
2022-07-30 11:45:22.591  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 28)
2022-07-30 11:45:22.592  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:45:22.592  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 29 (MapPartitionsRDD[186] at count at Application.java:147), which has no missing parents
2022-07-30 11:45:22.595  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_16 stored as values in memory (estimated size 11.0 KiB, free 897.1 MiB)
2022-07-30 11:45:22.599  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_16_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.1 MiB)
2022-07-30 11:45:22.599  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_16_piece0 in memory on host.docker.internal:58598 (size: 5.4 KiB, free: 897.5 MiB)
2022-07-30 11:45:22.600  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 16 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:45:22.601  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 29 (MapPartitionsRDD[186] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:45:22.601  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 29.0 with 1 tasks resource profile 0
2022-07-30 11:45:22.603  INFO   57 --- [er-event-loop-2] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 29.0 (TID 16) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:45:22.604  INFO   57 --- [e 29.0 (TID 16)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 29.0 (TID 16)
2022-07-30 11:45:22.609  INFO   57 --- [e 29.0 (TID 16)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:45:22.610  INFO   57 --- [e 29.0 (TID 16)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 1 ms
2022-07-30 11:45:22.611  INFO   57 --- [e 29.0 (TID 16)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 29.0 (TID 16). 2598 bytes result sent to driver
2022-07-30 11:45:22.634  INFO   57 --- [result-getter-3] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 29.0 (TID 16) in 32 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:45:22.635  INFO   57 --- [result-getter-3] org.apache.spark.internal.Logging        : Removed TaskSet 29.0, whose tasks have all completed, from pool 
2022-07-30 11:45:22.637  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 29 (count at Application.java:147) finished in 0.042 s
2022-07-30 11:45:22.637  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 16 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:45:22.637  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 29: Stage finished
2022-07-30 11:45:22.639  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 16 finished: count at Application.java:147, took 0.048813 s
2022-07-30 11:45:22.641  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177901000 ms.0 from job set of time 1659177901000 ms
2022-07-30 11:45:22.642  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 21.641 s for time 1659177901000 ms (execution: 0.180 s)
2022-07-30 11:45:22.642  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177902000 ms.0 from job set of time 1659177902000 ms
2022-07-30 11:45:22.643  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 26 from persistence list
2022-07-30 11:45:22.645  INFO   57 --- [-thread-pool-29] org.apache.spark.internal.Logging        : Removing RDD 26
2022-07-30 11:45:22.646  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 25 from persistence list
2022-07-30 11:45:22.649  INFO   57 --- [-thread-pool-30] org.apache.spark.internal.Logging        : Removing RDD 25
2022-07-30 11:45:22.649  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[25] at receiverStream at Application.java:122 of time 1659177901000 ms
2022-07-30 11:45:22.649  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:45:22.650  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177899000 ms
2022-07-30 11:45:22.650  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:45:22.650  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177899000 ms
2022-07-30 11:45:22.796  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:45:22.797  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 192 (count at Application.java:147) as input to shuffle 13
2022-07-30 11:45:22.798  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 17 (count at Application.java:147) with 1 output partitions
2022-07-30 11:45:22.798  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 31 (count at Application.java:147)
2022-07-30 11:45:22.799  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 30)
2022-07-30 11:45:22.799  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:45:22.800  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 31 (MapPartitionsRDD[195] at count at Application.java:147), which has no missing parents
2022-07-30 11:45:22.802  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_17 stored as values in memory (estimated size 11.0 KiB, free 897.1 MiB)
2022-07-30 11:45:22.805  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_17_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.1 MiB)
2022-07-30 11:45:22.806  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_17_piece0 in memory on host.docker.internal:58598 (size: 5.4 KiB, free: 897.5 MiB)
2022-07-30 11:45:22.808  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 17 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:45:22.808  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 31 (MapPartitionsRDD[195] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:45:22.808  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 31.0 with 1 tasks resource profile 0
2022-07-30 11:45:22.810  INFO   57 --- [er-event-loop-1] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 31.0 (TID 17) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:45:22.811  INFO   57 --- [e 31.0 (TID 17)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 31.0 (TID 17)
2022-07-30 11:45:22.815  INFO   57 --- [e 31.0 (TID 17)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:45:22.816  INFO   57 --- [e 31.0 (TID 17)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-30 11:45:22.817  INFO   57 --- [e 31.0 (TID 17)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 31.0 (TID 17). 2555 bytes result sent to driver
2022-07-30 11:45:22.818  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 31.0 (TID 17) in 8 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:45:22.819  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Removed TaskSet 31.0, whose tasks have all completed, from pool 
2022-07-30 11:45:22.820  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 31 (count at Application.java:147) finished in 0.019 s
2022-07-30 11:45:22.821  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 17 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:45:22.821  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 31: Stage finished
2022-07-30 11:45:22.823  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 17 finished: count at Application.java:147, took 0.026078 s
2022-07-30 11:45:22.825  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177902000 ms.0 from job set of time 1659177902000 ms
2022-07-30 11:45:22.825  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 20.825 s for time 1659177902000 ms (execution: 0.183 s)
2022-07-30 11:45:22.825  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177903000 ms.0 from job set of time 1659177903000 ms
2022-07-30 11:45:22.827  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 28 from persistence list
2022-07-30 11:45:22.827  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 27 from persistence list
2022-07-30 11:45:22.828  INFO   57 --- [-thread-pool-35] org.apache.spark.internal.Logging        : Removing RDD 28
2022-07-30 11:45:22.829  INFO   57 --- [-thread-pool-39] org.apache.spark.internal.Logging        : Removing RDD 27
2022-07-30 11:45:22.829  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[27] at receiverStream at Application.java:122 of time 1659177902000 ms
2022-07-30 11:45:22.829  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177900000 ms
2022-07-30 11:45:22.829  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177900000 ms
2022-07-30 11:45:22.832  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:45:22.832  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:45:22.978  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:45:22.979  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 201 (count at Application.java:147) as input to shuffle 14
2022-07-30 11:45:22.979  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 18 (count at Application.java:147) with 1 output partitions
2022-07-30 11:45:22.980  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 33 (count at Application.java:147)
2022-07-30 11:45:22.980  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 32)
2022-07-30 11:45:22.980  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:45:22.980  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 33 (MapPartitionsRDD[204] at count at Application.java:147), which has no missing parents
2022-07-30 11:45:22.983  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_18 stored as values in memory (estimated size 11.0 KiB, free 897.1 MiB)
2022-07-30 11:45:22.986  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_18_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.1 MiB)
2022-07-30 11:45:22.987  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_18_piece0 in memory on host.docker.internal:58598 (size: 5.4 KiB, free: 897.5 MiB)
2022-07-30 11:45:22.988  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 18 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:45:22.988  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 33 (MapPartitionsRDD[204] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:45:22.988  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 33.0 with 1 tasks resource profile 0
2022-07-30 11:45:22.990  INFO   57 --- [er-event-loop-0] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 33.0 (TID 18) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:45:22.990  INFO   57 --- [e 33.0 (TID 18)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 33.0 (TID 18)
2022-07-30 11:45:22.995  INFO   57 --- [e 33.0 (TID 18)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:45:22.995  INFO   57 --- [e 33.0 (TID 18)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 1 ms
2022-07-30 11:45:22.997  INFO   57 --- [e 33.0 (TID 18)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 33.0 (TID 18). 2555 bytes result sent to driver
2022-07-30 11:45:22.998  INFO   57 --- [result-getter-1] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 33.0 (TID 18) in 9 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:45:22.998  INFO   57 --- [result-getter-1] org.apache.spark.internal.Logging        : Removed TaskSet 33.0, whose tasks have all completed, from pool 
2022-07-30 11:45:22.999  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 33 (count at Application.java:147) finished in 0.017 s
2022-07-30 11:45:22.999  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 18 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:45:23.000  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 33: Stage finished
2022-07-30 11:45:23.000  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 18 finished: count at Application.java:147, took 0.021492 s
2022-07-30 11:45:23.001  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177903000 ms.0 from job set of time 1659177903000 ms
2022-07-30 11:45:23.002  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 20.001 s for time 1659177903000 ms (execution: 0.176 s)
2022-07-30 11:45:23.002  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177904000 ms.0 from job set of time 1659177904000 ms
2022-07-30 11:45:23.002  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177923000 ms
2022-07-30 11:45:23.004  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 30 from persistence list
2022-07-30 11:45:23.005  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 29 from persistence list
2022-07-30 11:45:23.005  INFO   57 --- [-thread-pool-41] org.apache.spark.internal.Logging        : Removing RDD 30
2022-07-30 11:45:23.006  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:45:23.006  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:45:23.006  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[29] at receiverStream at Application.java:122 of time 1659177903000 ms
2022-07-30 11:45:23.007  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177901000 ms
2022-07-30 11:45:23.007  INFO   57 --- [-thread-pool-42] org.apache.spark.internal.Logging        : Removing RDD 29
2022-07-30 11:45:23.007  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177901000 ms
2022-07-30 11:45:23.093  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:45:23.094  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 212 (count at Application.java:147) as input to shuffle 15
2022-07-30 11:45:23.095  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 19 (count at Application.java:147) with 1 output partitions
2022-07-30 11:45:23.095  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 35 (count at Application.java:147)
2022-07-30 11:45:23.095  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 34)
2022-07-30 11:45:23.095  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:45:23.095  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 35 (MapPartitionsRDD[215] at count at Application.java:147), which has no missing parents
2022-07-30 11:45:23.097  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_19 stored as values in memory (estimated size 11.0 KiB, free 897.1 MiB)
2022-07-30 11:45:23.099  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_19_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.1 MiB)
2022-07-30 11:45:23.101  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_19_piece0 in memory on host.docker.internal:58598 (size: 5.4 KiB, free: 897.5 MiB)
2022-07-30 11:45:23.101  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 19 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:45:23.105  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 35 (MapPartitionsRDD[215] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:45:23.106  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 35.0 with 1 tasks resource profile 0
2022-07-30 11:45:23.107  INFO   57 --- [er-event-loop-3] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 35.0 (TID 19) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:45:23.108  INFO   57 --- [e 35.0 (TID 19)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 35.0 (TID 19)
2022-07-30 11:45:23.115  INFO   57 --- [e 35.0 (TID 19)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:45:23.117  INFO   57 --- [e 35.0 (TID 19)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 2 ms
2022-07-30 11:45:23.118  INFO   57 --- [e 35.0 (TID 19)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 35.0 (TID 19). 2555 bytes result sent to driver
2022-07-30 11:45:23.121  INFO   57 --- [result-getter-2] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 35.0 (TID 19) in 14 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:45:23.121  INFO   57 --- [result-getter-2] org.apache.spark.internal.Logging        : Removed TaskSet 35.0, whose tasks have all completed, from pool 
2022-07-30 11:45:23.123  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 35 (count at Application.java:147) finished in 0.027 s
2022-07-30 11:45:23.123  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 19 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:45:23.124  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 35: Stage finished
2022-07-30 11:45:23.124  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 19 finished: count at Application.java:147, took 0.030535 s
2022-07-30 11:45:23.128  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:45:23.129  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:45:23.129  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177904000 ms.0 from job set of time 1659177904000 ms
2022-07-30 11:45:23.130  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 19.129 s for time 1659177904000 ms (execution: 0.127 s)
2022-07-30 11:45:23.130  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177905000 ms.0 from job set of time 1659177905000 ms
2022-07-30 11:45:23.135  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 32 from persistence list
2022-07-30 11:45:23.136  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 31 from persistence list
2022-07-30 11:45:23.137  INFO   57 --- [-thread-pool-47] org.apache.spark.internal.Logging        : Removing RDD 32
2022-07-30 11:45:23.141  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[31] at receiverStream at Application.java:122 of time 1659177904000 ms
2022-07-30 11:45:23.141  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177902000 ms
2022-07-30 11:45:23.141  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177902000 ms
2022-07-30 11:45:23.141  INFO   57 --- [-thread-pool-49] org.apache.spark.internal.Logging        : Removing RDD 31
2022-07-30 11:45:23.245  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:45:23.246  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 221 (count at Application.java:147) as input to shuffle 16
2022-07-30 11:45:23.246  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 20 (count at Application.java:147) with 1 output partitions
2022-07-30 11:45:23.246  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 37 (count at Application.java:147)
2022-07-30 11:45:23.246  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 36)
2022-07-30 11:45:23.247  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:45:23.247  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 37 (MapPartitionsRDD[224] at count at Application.java:147), which has no missing parents
2022-07-30 11:45:23.250  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_20 stored as values in memory (estimated size 11.0 KiB, free 897.1 MiB)
2022-07-30 11:45:23.252  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_20_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.1 MiB)
2022-07-30 11:45:23.253  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_20_piece0 in memory on host.docker.internal:58598 (size: 5.4 KiB, free: 897.5 MiB)
2022-07-30 11:45:23.254  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 20 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:45:23.254  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 37 (MapPartitionsRDD[224] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:45:23.254  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 37.0 with 1 tasks resource profile 0
2022-07-30 11:45:23.255  INFO   57 --- [er-event-loop-2] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 37.0 (TID 20) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:45:23.256  INFO   57 --- [e 37.0 (TID 20)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 37.0 (TID 20)
2022-07-30 11:45:23.260  INFO   57 --- [e 37.0 (TID 20)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:45:23.260  INFO   57 --- [e 37.0 (TID 20)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-30 11:45:23.262  INFO   57 --- [e 37.0 (TID 20)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 37.0 (TID 20). 2555 bytes result sent to driver
2022-07-30 11:45:23.265  INFO   57 --- [result-getter-3] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 37.0 (TID 20) in 10 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:45:23.265  INFO   57 --- [result-getter-3] org.apache.spark.internal.Logging        : Removed TaskSet 37.0, whose tasks have all completed, from pool 
2022-07-30 11:45:23.266  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 37 (count at Application.java:147) finished in 0.018 s
2022-07-30 11:45:23.266  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 20 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:45:23.267  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 37: Stage finished
2022-07-30 11:45:23.267  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 20 finished: count at Application.java:147, took 0.022169 s
2022-07-30 11:45:23.269  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177905000 ms.0 from job set of time 1659177905000 ms
2022-07-30 11:45:23.269  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 18.269 s for time 1659177905000 ms (execution: 0.139 s)
2022-07-30 11:45:23.270  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177906000 ms.0 from job set of time 1659177906000 ms
2022-07-30 11:45:23.275  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:45:23.275  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:45:23.276  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 34 from persistence list
2022-07-30 11:45:23.281  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 33 from persistence list
2022-07-30 11:45:23.282  INFO   57 --- [-thread-pool-51] org.apache.spark.internal.Logging        : Removing RDD 34
2022-07-30 11:45:23.284  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[33] at receiverStream at Application.java:122 of time 1659177905000 ms
2022-07-30 11:45:23.285  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177903000 ms
2022-07-30 11:45:23.287  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177903000 ms
2022-07-30 11:45:23.288  INFO   57 --- [-thread-pool-55] org.apache.spark.internal.Logging        : Removing RDD 33
2022-07-30 11:45:23.473  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:45:23.474  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 230 (count at Application.java:147) as input to shuffle 17
2022-07-30 11:45:23.475  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 21 (count at Application.java:147) with 1 output partitions
2022-07-30 11:45:23.475  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 39 (count at Application.java:147)
2022-07-30 11:45:23.476  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 38)
2022-07-30 11:45:23.476  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:45:23.477  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 39 (MapPartitionsRDD[233] at count at Application.java:147), which has no missing parents
2022-07-30 11:45:23.480  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_21 stored as values in memory (estimated size 11.0 KiB, free 897.1 MiB)
2022-07-30 11:45:23.483  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_21_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.0 MiB)
2022-07-30 11:45:23.484  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_21_piece0 in memory on host.docker.internal:58598 (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:45:23.485  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 21 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:45:23.485  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 39 (MapPartitionsRDD[233] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:45:23.485  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 39.0 with 1 tasks resource profile 0
2022-07-30 11:45:23.487  INFO   57 --- [er-event-loop-1] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 39.0 (TID 21) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:45:23.488  INFO   57 --- [e 39.0 (TID 21)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 39.0 (TID 21)
2022-07-30 11:45:23.492  INFO   57 --- [e 39.0 (TID 21)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:45:23.492  INFO   57 --- [e 39.0 (TID 21)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-30 11:45:23.494  INFO   57 --- [e 39.0 (TID 21)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 39.0 (TID 21). 2555 bytes result sent to driver
2022-07-30 11:45:23.495  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 39.0 (TID 21) in 8 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:45:23.495  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Removed TaskSet 39.0, whose tasks have all completed, from pool 
2022-07-30 11:45:23.497  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 39 (count at Application.java:147) finished in 0.018 s
2022-07-30 11:45:23.497  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 21 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:45:23.498  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 39: Stage finished
2022-07-30 11:45:23.499  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 21 finished: count at Application.java:147, took 0.025361 s
2022-07-30 11:45:23.501  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177906000 ms.0 from job set of time 1659177906000 ms
2022-07-30 11:45:23.504  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:45:23.505  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:45:23.508  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 17.501 s for time 1659177906000 ms (execution: 0.232 s)
2022-07-30 11:45:23.508  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177907000 ms.0 from job set of time 1659177907000 ms
2022-07-30 11:45:23.510  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 36 from persistence list
2022-07-30 11:45:23.514  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 35 from persistence list
2022-07-30 11:45:23.517  INFO   57 --- [-thread-pool-59] org.apache.spark.internal.Logging        : Removing RDD 36
2022-07-30 11:45:23.527  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[35] at receiverStream at Application.java:122 of time 1659177906000 ms
2022-07-30 11:45:23.528  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177904000 ms
2022-07-30 11:45:23.529  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177904000 ms
2022-07-30 11:45:23.529  INFO   57 --- [-thread-pool-57] org.apache.spark.internal.Logging        : Removing RDD 35
2022-07-30 11:45:23.597  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:45:23.599  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 239 (count at Application.java:147) as input to shuffle 18
2022-07-30 11:45:23.611  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 22 (count at Application.java:147) with 1 output partitions
2022-07-30 11:45:23.611  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 41 (count at Application.java:147)
2022-07-30 11:45:23.612  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 40)
2022-07-30 11:45:23.612  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:45:23.613  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 41 (MapPartitionsRDD[242] at count at Application.java:147), which has no missing parents
2022-07-30 11:45:23.615  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_22 stored as values in memory (estimated size 11.0 KiB, free 897.0 MiB)
2022-07-30 11:45:23.630  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_22_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.0 MiB)
2022-07-30 11:45:23.631  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_22_piece0 in memory on host.docker.internal:58598 (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:45:23.635  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 22 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:45:23.639  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 41 (MapPartitionsRDD[242] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:45:23.639  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 41.0 with 1 tasks resource profile 0
2022-07-30 11:45:23.642  INFO   57 --- [er-event-loop-0] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 41.0 (TID 22) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:45:23.644  INFO   57 --- [e 41.0 (TID 22)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 41.0 (TID 22)
2022-07-30 11:45:23.652  INFO   57 --- [e 41.0 (TID 22)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:45:23.657  INFO   57 --- [e 41.0 (TID 22)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 7 ms
2022-07-30 11:45:23.663  INFO   57 --- [e 41.0 (TID 22)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 41.0 (TID 22). 2555 bytes result sent to driver
2022-07-30 11:45:23.664  INFO   57 --- [result-getter-1] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 41.0 (TID 22) in 22 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:45:23.665  INFO   57 --- [result-getter-1] org.apache.spark.internal.Logging        : Removed TaskSet 41.0, whose tasks have all completed, from pool 
2022-07-30 11:45:23.666  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 41 (count at Application.java:147) finished in 0.051 s
2022-07-30 11:45:23.667  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 22 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:45:23.668  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 41: Stage finished
2022-07-30 11:45:23.668  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 22 finished: count at Application.java:147, took 0.070577 s
2022-07-30 11:45:23.673  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177907000 ms.0 from job set of time 1659177907000 ms
2022-07-30 11:45:23.674  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 16.673 s for time 1659177907000 ms (execution: 0.165 s)
2022-07-30 11:45:23.675  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177908000 ms.0 from job set of time 1659177908000 ms
2022-07-30 11:45:23.675  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:45:23.675  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:45:23.699  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 38 from persistence list
2022-07-30 11:45:23.705  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 37 from persistence list
2022-07-30 11:45:23.710  INFO   57 --- [-thread-pool-65] org.apache.spark.internal.Logging        : Removing RDD 38
2022-07-30 11:45:23.718  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[37] at receiverStream at Application.java:122 of time 1659177907000 ms
2022-07-30 11:45:23.718  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177905000 ms
2022-07-30 11:45:23.718  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177905000 ms
2022-07-30 11:45:23.718  INFO   57 --- [-thread-pool-66] org.apache.spark.internal.Logging        : Removing RDD 37
2022-07-30 11:45:23.865  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:45:23.868  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 248 (count at Application.java:147) as input to shuffle 19
2022-07-30 11:45:23.869  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 23 (count at Application.java:147) with 1 output partitions
2022-07-30 11:45:23.871  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 43 (count at Application.java:147)
2022-07-30 11:45:23.871  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 42)
2022-07-30 11:45:23.873  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:45:23.874  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 43 (MapPartitionsRDD[251] at count at Application.java:147), which has no missing parents
2022-07-30 11:45:23.876  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_23 stored as values in memory (estimated size 11.0 KiB, free 897.0 MiB)
2022-07-30 11:45:23.880  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_23_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.0 MiB)
2022-07-30 11:45:23.882  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_23_piece0 in memory on host.docker.internal:58598 (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:45:23.883  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 23 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:45:23.884  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 43 (MapPartitionsRDD[251] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:45:23.885  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 43.0 with 1 tasks resource profile 0
2022-07-30 11:45:23.889  INFO   57 --- [er-event-loop-3] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 43.0 (TID 23) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:45:23.890  INFO   57 --- [e 43.0 (TID 23)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 43.0 (TID 23)
2022-07-30 11:45:23.896  INFO   57 --- [e 43.0 (TID 23)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:45:23.896  INFO   57 --- [e 43.0 (TID 23)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 1 ms
2022-07-30 11:45:23.898  INFO   57 --- [e 43.0 (TID 23)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 43.0 (TID 23). 2555 bytes result sent to driver
2022-07-30 11:45:23.899  INFO   57 --- [result-getter-2] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 43.0 (TID 23) in 10 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:45:23.899  INFO   57 --- [result-getter-2] org.apache.spark.internal.Logging        : Removed TaskSet 43.0, whose tasks have all completed, from pool 
2022-07-30 11:45:23.900  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 43 (count at Application.java:147) finished in 0.025 s
2022-07-30 11:45:23.901  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 23 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:45:23.901  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 43: Stage finished
2022-07-30 11:45:23.906  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 23 finished: count at Application.java:147, took 0.040760 s
2022-07-30 11:45:23.907  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177908000 ms.0 from job set of time 1659177908000 ms
2022-07-30 11:45:23.908  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 15.907 s for time 1659177908000 ms (execution: 0.232 s)
2022-07-30 11:45:23.909  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177909000 ms.0 from job set of time 1659177909000 ms
2022-07-30 11:45:23.912  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:45:23.912  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 40 from persistence list
2022-07-30 11:45:23.912  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:45:23.918  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 39 from persistence list
2022-07-30 11:45:23.919  INFO   57 --- [-thread-pool-69] org.apache.spark.internal.Logging        : Removing RDD 40
2022-07-30 11:45:23.924  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[39] at receiverStream at Application.java:122 of time 1659177908000 ms
2022-07-30 11:45:23.925  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177906000 ms
2022-07-30 11:45:23.926  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177906000 ms
2022-07-30 11:45:23.926  INFO   57 --- [-thread-pool-74] org.apache.spark.internal.Logging        : Removing RDD 39
2022-07-30 11:45:24.002  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177924000 ms
2022-07-30 11:45:24.032  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:45:24.034  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 259 (count at Application.java:147) as input to shuffle 20
2022-07-30 11:45:24.035  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 24 (count at Application.java:147) with 1 output partitions
2022-07-30 11:45:24.035  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 45 (count at Application.java:147)
2022-07-30 11:45:24.035  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 44)
2022-07-30 11:45:24.036  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:45:24.037  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 45 (MapPartitionsRDD[262] at count at Application.java:147), which has no missing parents
2022-07-30 11:45:24.040  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_24 stored as values in memory (estimated size 11.0 KiB, free 897.0 MiB)
2022-07-30 11:45:24.044  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_24_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.0 MiB)
2022-07-30 11:45:24.045  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_24_piece0 in memory on host.docker.internal:58598 (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:45:24.046  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 24 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:45:24.046  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 45 (MapPartitionsRDD[262] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:45:24.047  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 45.0 with 1 tasks resource profile 0
2022-07-30 11:45:24.050  INFO   57 --- [er-event-loop-2] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 45.0 (TID 24) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:45:24.052  INFO   57 --- [e 45.0 (TID 24)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 45.0 (TID 24)
2022-07-30 11:45:24.061  INFO   57 --- [e 45.0 (TID 24)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:45:24.061  INFO   57 --- [e 45.0 (TID 24)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 1 ms
2022-07-30 11:45:24.063  INFO   57 --- [e 45.0 (TID 24)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 45.0 (TID 24). 2555 bytes result sent to driver
2022-07-30 11:45:24.065  INFO   57 --- [result-getter-3] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 45.0 (TID 24) in 16 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:45:24.066  INFO   57 --- [result-getter-3] org.apache.spark.internal.Logging        : Removed TaskSet 45.0, whose tasks have all completed, from pool 
2022-07-30 11:45:24.067  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 45 (count at Application.java:147) finished in 0.027 s
2022-07-30 11:45:24.067  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 24 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:45:24.067  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 45: Stage finished
2022-07-30 11:45:24.074  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 24 finished: count at Application.java:147, took 0.041663 s
2022-07-30 11:45:24.078  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177909000 ms.0 from job set of time 1659177909000 ms
2022-07-30 11:45:24.079  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 15.078 s for time 1659177909000 ms (execution: 0.169 s)
2022-07-30 11:45:24.079  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177910000 ms.0 from job set of time 1659177910000 ms
2022-07-30 11:45:24.081  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:45:24.081  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:45:24.085  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 44 from persistence list
2022-07-30 11:45:24.089  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 43 from persistence list
2022-07-30 11:45:24.089  INFO   57 --- [-thread-pool-77] org.apache.spark.internal.Logging        : Removing RDD 44
2022-07-30 11:45:24.090  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[43] at receiverStream at Application.java:122 of time 1659177909000 ms
2022-07-30 11:45:24.090  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177907000 ms
2022-07-30 11:45:24.091  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177907000 ms
2022-07-30 11:45:24.092  INFO   57 --- [-thread-pool-80] org.apache.spark.internal.Logging        : Removing RDD 43
2022-07-30 11:45:24.241  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:45:24.242  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 268 (count at Application.java:147) as input to shuffle 21
2022-07-30 11:45:24.245  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 25 (count at Application.java:147) with 1 output partitions
2022-07-30 11:45:24.245  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 47 (count at Application.java:147)
2022-07-30 11:45:24.245  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 46)
2022-07-30 11:45:24.246  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:45:24.246  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 47 (MapPartitionsRDD[271] at count at Application.java:147), which has no missing parents
2022-07-30 11:45:24.248  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_25 stored as values in memory (estimated size 11.0 KiB, free 897.0 MiB)
2022-07-30 11:45:24.254  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_25_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.0 MiB)
2022-07-30 11:45:24.254  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_25_piece0 in memory on host.docker.internal:58598 (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:45:24.255  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 25 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:45:24.256  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 47 (MapPartitionsRDD[271] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:45:24.256  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 47.0 with 1 tasks resource profile 0
2022-07-30 11:45:24.258  INFO   57 --- [er-event-loop-1] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 47.0 (TID 25) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:45:24.260  INFO   57 --- [e 47.0 (TID 25)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 47.0 (TID 25)
2022-07-30 11:45:24.264  INFO   57 --- [e 47.0 (TID 25)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:45:24.264  INFO   57 --- [e 47.0 (TID 25)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-30 11:45:24.266  INFO   57 --- [e 47.0 (TID 25)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 47.0 (TID 25). 2598 bytes result sent to driver
2022-07-30 11:45:24.267  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 47.0 (TID 25) in 10 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:45:24.268  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Removed TaskSet 47.0, whose tasks have all completed, from pool 
2022-07-30 11:45:24.268  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 47 (count at Application.java:147) finished in 0.021 s
2022-07-30 11:45:24.269  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 25 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:45:24.271  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 47: Stage finished
2022-07-30 11:45:24.273  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 25 finished: count at Application.java:147, took 0.030654 s
2022-07-30 11:45:24.277  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:45:24.277  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:45:24.277  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177910000 ms.0 from job set of time 1659177910000 ms
2022-07-30 11:45:24.283  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 14.277 s for time 1659177910000 ms (execution: 0.198 s)
2022-07-30 11:45:24.283  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177911000 ms.0 from job set of time 1659177911000 ms
2022-07-30 11:45:24.284  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 51 from persistence list
2022-07-30 11:45:24.285  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 50 from persistence list
2022-07-30 11:45:24.285  INFO   57 --- [-thread-pool-83] org.apache.spark.internal.Logging        : Removing RDD 51
2022-07-30 11:45:24.289  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[50] at receiverStream at Application.java:122 of time 1659177910000 ms
2022-07-30 11:45:24.289  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177908000 ms
2022-07-30 11:45:24.289  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177908000 ms
2022-07-30 11:45:24.290  INFO   57 --- [-thread-pool-85] org.apache.spark.internal.Logging        : Removing RDD 50
2022-07-30 11:45:24.409  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:45:24.411  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 277 (count at Application.java:147) as input to shuffle 22
2022-07-30 11:45:24.411  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 26 (count at Application.java:147) with 1 output partitions
2022-07-30 11:45:24.412  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 49 (count at Application.java:147)
2022-07-30 11:45:24.412  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 48)
2022-07-30 11:45:24.412  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:45:24.435  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 49 (MapPartitionsRDD[280] at count at Application.java:147), which has no missing parents
2022-07-30 11:45:24.440  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_26 stored as values in memory (estimated size 11.0 KiB, free 897.0 MiB)
2022-07-30 11:45:24.443  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_26_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.0 MiB)
2022-07-30 11:45:24.444  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_26_piece0 in memory on host.docker.internal:58598 (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:45:24.445  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 26 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:45:24.445  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 49 (MapPartitionsRDD[280] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:45:24.445  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 49.0 with 1 tasks resource profile 0
2022-07-30 11:45:24.447  INFO   57 --- [er-event-loop-0] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 49.0 (TID 26) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:45:24.448  INFO   57 --- [e 49.0 (TID 26)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 49.0 (TID 26)
2022-07-30 11:45:24.452  INFO   57 --- [e 49.0 (TID 26)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:45:24.452  INFO   57 --- [e 49.0 (TID 26)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-30 11:45:24.455  INFO   57 --- [e 49.0 (TID 26)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 49.0 (TID 26). 2598 bytes result sent to driver
2022-07-30 11:45:24.456  INFO   57 --- [result-getter-1] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 49.0 (TID 26) in 10 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:45:24.456  INFO   57 --- [result-getter-1] org.apache.spark.internal.Logging        : Removed TaskSet 49.0, whose tasks have all completed, from pool 
2022-07-30 11:45:24.457  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 49 (count at Application.java:147) finished in 0.017 s
2022-07-30 11:45:24.457  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 26 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:45:24.457  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 49: Stage finished
2022-07-30 11:45:24.458  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 26 finished: count at Application.java:147, took 0.048099 s
2022-07-30 11:45:24.460  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177911000 ms.0 from job set of time 1659177911000 ms
2022-07-30 11:45:24.461  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 13.460 s for time 1659177911000 ms (execution: 0.177 s)
2022-07-30 11:45:24.461  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177912000 ms.0 from job set of time 1659177912000 ms
2022-07-30 11:45:24.462  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:45:24.462  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:45:24.469  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 80 from persistence list
2022-07-30 11:45:24.472  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 79 from persistence list
2022-07-30 11:45:24.473  INFO   57 --- [-thread-pool-89] org.apache.spark.internal.Logging        : Removing RDD 80
2022-07-30 11:45:24.474  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[79] at receiverStream at Application.java:122 of time 1659177911000 ms
2022-07-30 11:45:24.475  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177909000 ms
2022-07-30 11:45:24.475  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177909000 ms
2022-07-30 11:45:24.475  INFO   57 --- [-thread-pool-94] org.apache.spark.internal.Logging        : Removing RDD 79
2022-07-30 11:45:24.546  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:45:24.546  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 286 (count at Application.java:147) as input to shuffle 23
2022-07-30 11:45:24.547  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 27 (count at Application.java:147) with 1 output partitions
2022-07-30 11:45:24.547  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 51 (count at Application.java:147)
2022-07-30 11:45:24.548  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 50)
2022-07-30 11:45:24.548  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:45:24.548  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 51 (MapPartitionsRDD[289] at count at Application.java:147), which has no missing parents
2022-07-30 11:45:24.550  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_27 stored as values in memory (estimated size 11.0 KiB, free 897.0 MiB)
2022-07-30 11:45:24.556  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_27_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.0 MiB)
2022-07-30 11:45:24.557  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_27_piece0 in memory on host.docker.internal:58598 (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:45:24.558  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 27 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:45:24.558  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 51 (MapPartitionsRDD[289] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:45:24.558  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 51.0 with 1 tasks resource profile 0
2022-07-30 11:45:24.559  INFO   57 --- [er-event-loop-3] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 51.0 (TID 27) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:45:24.560  INFO   57 --- [e 51.0 (TID 27)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 51.0 (TID 27)
2022-07-30 11:45:24.564  INFO   57 --- [e 51.0 (TID 27)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:45:24.565  INFO   57 --- [e 51.0 (TID 27)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-30 11:45:24.566  INFO   57 --- [e 51.0 (TID 27)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 51.0 (TID 27). 2598 bytes result sent to driver
2022-07-30 11:45:24.566  INFO   57 --- [result-getter-2] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 51.0 (TID 27) in 7 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:45:24.566  INFO   57 --- [result-getter-2] org.apache.spark.internal.Logging        : Removed TaskSet 51.0, whose tasks have all completed, from pool 
2022-07-30 11:45:24.567  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 51 (count at Application.java:147) finished in 0.018 s
2022-07-30 11:45:24.567  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 27 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:45:24.567  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 51: Stage finished
2022-07-30 11:45:24.568  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 27 finished: count at Application.java:147, took 0.021623 s
2022-07-30 11:45:24.568  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177912000 ms.0 from job set of time 1659177912000 ms
2022-07-30 11:45:24.569  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 12.568 s for time 1659177912000 ms (execution: 0.107 s)
2022-07-30 11:45:24.572  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177913000 ms.0 from job set of time 1659177913000 ms
2022-07-30 11:45:24.573  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 113 from persistence list
2022-07-30 11:45:24.575  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:45:24.575  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:45:24.576  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 112 from persistence list
2022-07-30 11:45:24.577  INFO   57 --- [-thread-pool-91] org.apache.spark.internal.Logging        : Removing RDD 113
2022-07-30 11:45:24.578  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[112] at receiverStream at Application.java:122 of time 1659177912000 ms
2022-07-30 11:45:24.578  INFO   57 --- [-thread-pool-97] org.apache.spark.internal.Logging        : Removing RDD 112
2022-07-30 11:45:24.579  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177910000 ms
2022-07-30 11:45:24.579  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177910000 ms
2022-07-30 11:45:24.650  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:45:24.651  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 295 (count at Application.java:147) as input to shuffle 24
2022-07-30 11:45:24.652  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 28 (count at Application.java:147) with 1 output partitions
2022-07-30 11:45:24.652  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 53 (count at Application.java:147)
2022-07-30 11:45:24.652  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 52)
2022-07-30 11:45:24.652  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:45:24.653  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 53 (MapPartitionsRDD[298] at count at Application.java:147), which has no missing parents
2022-07-30 11:45:24.655  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_28 stored as values in memory (estimated size 11.0 KiB, free 896.9 MiB)
2022-07-30 11:45:24.657  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_28_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 896.9 MiB)
2022-07-30 11:45:24.659  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_28_piece0 in memory on host.docker.internal:58598 (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:45:24.660  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 28 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:45:24.660  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 53 (MapPartitionsRDD[298] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:45:24.661  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 53.0 with 1 tasks resource profile 0
2022-07-30 11:45:24.662  INFO   57 --- [er-event-loop-2] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 53.0 (TID 28) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:45:24.662  INFO   57 --- [e 53.0 (TID 28)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 53.0 (TID 28)
2022-07-30 11:45:24.666  INFO   57 --- [e 53.0 (TID 28)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:45:24.666  INFO   57 --- [e 53.0 (TID 28)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-30 11:45:24.668  INFO   57 --- [e 53.0 (TID 28)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 53.0 (TID 28). 2555 bytes result sent to driver
2022-07-30 11:45:24.669  INFO   57 --- [result-getter-3] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 53.0 (TID 28) in 8 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:45:24.669  INFO   57 --- [result-getter-3] org.apache.spark.internal.Logging        : Removed TaskSet 53.0, whose tasks have all completed, from pool 
2022-07-30 11:45:24.670  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 53 (count at Application.java:147) finished in 0.016 s
2022-07-30 11:45:24.670  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 28 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:45:24.670  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 53: Stage finished
2022-07-30 11:45:24.672  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 28 finished: count at Application.java:147, took 0.021148 s
2022-07-30 11:45:24.673  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177913000 ms.0 from job set of time 1659177913000 ms
2022-07-30 11:45:24.674  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 11.673 s for time 1659177913000 ms (execution: 0.101 s)
2022-07-30 11:45:24.674  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177914000 ms.0 from job set of time 1659177914000 ms
2022-07-30 11:45:24.676  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:45:24.676  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:45:24.692  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 115 from persistence list
2022-07-30 11:45:24.699  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 114 from persistence list
2022-07-30 11:45:24.700  INFO   57 --- [c-thread-pool-2] org.apache.spark.internal.Logging        : Removing RDD 115
2022-07-30 11:45:24.701  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[114] at receiverStream at Application.java:122 of time 1659177913000 ms
2022-07-30 11:45:24.702  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177911000 ms
2022-07-30 11:45:24.702  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177911000 ms
2022-07-30 11:45:24.702  INFO   57 --- [c-thread-pool-4] org.apache.spark.internal.Logging        : Removing RDD 114
2022-07-30 11:45:24.778  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:45:24.779  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 304 (count at Application.java:147) as input to shuffle 25
2022-07-30 11:45:24.780  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 29 (count at Application.java:147) with 1 output partitions
2022-07-30 11:45:24.780  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 55 (count at Application.java:147)
2022-07-30 11:45:24.780  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 54)
2022-07-30 11:45:24.781  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:45:24.781  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 55 (MapPartitionsRDD[307] at count at Application.java:147), which has no missing parents
2022-07-30 11:45:24.783  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_29 stored as values in memory (estimated size 11.0 KiB, free 896.9 MiB)
2022-07-30 11:45:24.785  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_29_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 896.9 MiB)
2022-07-30 11:45:24.787  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_29_piece0 in memory on host.docker.internal:58598 (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:45:24.789  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 29 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:45:24.789  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 55 (MapPartitionsRDD[307] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:45:24.789  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 55.0 with 1 tasks resource profile 0
2022-07-30 11:45:24.791  INFO   57 --- [er-event-loop-1] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 55.0 (TID 29) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:45:24.792  INFO   57 --- [e 55.0 (TID 29)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 55.0 (TID 29)
2022-07-30 11:45:24.796  INFO   57 --- [e 55.0 (TID 29)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:45:24.796  INFO   57 --- [e 55.0 (TID 29)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 1 ms
2022-07-30 11:45:24.798  INFO   57 --- [e 55.0 (TID 29)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 55.0 (TID 29). 2598 bytes result sent to driver
2022-07-30 11:45:24.799  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 55.0 (TID 29) in 9 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:45:24.800  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Removed TaskSet 55.0, whose tasks have all completed, from pool 
2022-07-30 11:45:24.800  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 55 (count at Application.java:147) finished in 0.018 s
2022-07-30 11:45:24.801  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 29 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:45:24.801  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 55: Stage finished
2022-07-30 11:45:24.801  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 29 finished: count at Application.java:147, took 0.023287 s
2022-07-30 11:45:24.805  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177914000 ms.0 from job set of time 1659177914000 ms
2022-07-30 11:45:24.808  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:45:24.809  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:45:24.814  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 10.805 s for time 1659177914000 ms (execution: 0.131 s)
2022-07-30 11:45:24.815  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177915000 ms.0 from job set of time 1659177915000 ms
2022-07-30 11:45:24.819  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 119 from persistence list
2022-07-30 11:45:24.825  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 118 from persistence list
2022-07-30 11:45:24.828  INFO   57 --- [c-thread-pool-5] org.apache.spark.internal.Logging        : Removing RDD 119
2022-07-30 11:45:24.830  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[118] at receiverStream at Application.java:122 of time 1659177914000 ms
2022-07-30 11:45:24.830  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177912000 ms
2022-07-30 11:45:24.830  INFO   57 --- [c-thread-pool-8] org.apache.spark.internal.Logging        : Removing RDD 118
2022-07-30 11:45:24.830  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177912000 ms
2022-07-30 11:45:24.890  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:45:24.891  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 313 (count at Application.java:147) as input to shuffle 26
2022-07-30 11:45:24.892  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 30 (count at Application.java:147) with 1 output partitions
2022-07-30 11:45:24.892  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 57 (count at Application.java:147)
2022-07-30 11:45:24.892  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 56)
2022-07-30 11:45:24.893  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:45:24.893  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 57 (MapPartitionsRDD[316] at count at Application.java:147), which has no missing parents
2022-07-30 11:45:24.897  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_30 stored as values in memory (estimated size 11.0 KiB, free 896.9 MiB)
2022-07-30 11:45:24.899  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_30_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 896.9 MiB)
2022-07-30 11:45:24.900  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_30_piece0 in memory on host.docker.internal:58598 (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:45:24.901  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 30 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:45:24.902  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 57 (MapPartitionsRDD[316] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:45:24.903  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 57.0 with 1 tasks resource profile 0
2022-07-30 11:45:24.905  INFO   57 --- [er-event-loop-0] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 57.0 (TID 30) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:45:24.906  INFO   57 --- [e 57.0 (TID 30)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 57.0 (TID 30)
2022-07-30 11:45:24.909  INFO   57 --- [e 57.0 (TID 30)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:45:24.910  INFO   57 --- [e 57.0 (TID 30)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 1 ms
2022-07-30 11:45:24.911  INFO   57 --- [e 57.0 (TID 30)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 57.0 (TID 30). 2555 bytes result sent to driver
2022-07-30 11:45:24.912  INFO   57 --- [result-getter-1] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 57.0 (TID 30) in 8 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:45:24.913  INFO   57 --- [result-getter-1] org.apache.spark.internal.Logging        : Removed TaskSet 57.0, whose tasks have all completed, from pool 
2022-07-30 11:45:24.914  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 57 (count at Application.java:147) finished in 0.020 s
2022-07-30 11:45:24.914  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 30 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:45:24.914  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 57: Stage finished
2022-07-30 11:45:24.915  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 30 finished: count at Application.java:147, took 0.024195 s
2022-07-30 11:45:24.923  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:45:24.924  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:45:24.932  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177915000 ms.0 from job set of time 1659177915000 ms
2022-07-30 11:45:24.932  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 9.932 s for time 1659177915000 ms (execution: 0.118 s)
2022-07-30 11:45:24.932  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177916000 ms.0 from job set of time 1659177916000 ms
2022-07-30 11:45:24.936  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 121 from persistence list
2022-07-30 11:45:24.937  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 120 from persistence list
2022-07-30 11:45:24.938  INFO   57 --- [-thread-pool-13] org.apache.spark.internal.Logging        : Removing RDD 121
2022-07-30 11:45:24.940  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[120] at receiverStream at Application.java:122 of time 1659177915000 ms
2022-07-30 11:45:24.940  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177913000 ms
2022-07-30 11:45:24.940  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177913000 ms
2022-07-30 11:45:24.941  INFO   57 --- [-thread-pool-16] org.apache.spark.internal.Logging        : Removing RDD 120
2022-07-30 11:45:25.010  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:45:25.011  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 322 (count at Application.java:147) as input to shuffle 27
2022-07-30 11:45:25.016  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 31 (count at Application.java:147) with 1 output partitions
2022-07-30 11:45:25.016  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 59 (count at Application.java:147)
2022-07-30 11:45:25.017  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 58)
2022-07-30 11:45:25.017  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:45:25.021  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 59 (MapPartitionsRDD[325] at count at Application.java:147), which has no missing parents
2022-07-30 11:45:25.025  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_31 stored as values in memory (estimated size 11.0 KiB, free 896.9 MiB)
2022-07-30 11:45:25.026  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177925000 ms
2022-07-30 11:45:25.041  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_31_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 896.9 MiB)
2022-07-30 11:45:25.042  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_31_piece0 in memory on host.docker.internal:58598 (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:45:25.042  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 31 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:45:25.043  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 59 (MapPartitionsRDD[325] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:45:25.044  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 59.0 with 1 tasks resource profile 0
2022-07-30 11:45:25.046  INFO   57 --- [er-event-loop-3] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 59.0 (TID 31) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:45:25.047  INFO   57 --- [e 59.0 (TID 31)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 59.0 (TID 31)
2022-07-30 11:45:25.054  INFO   57 --- [e 59.0 (TID 31)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:45:25.055  INFO   57 --- [e 59.0 (TID 31)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 2 ms
2022-07-30 11:45:25.056  INFO   57 --- [e 59.0 (TID 31)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 59.0 (TID 31). 2555 bytes result sent to driver
2022-07-30 11:45:25.057  INFO   57 --- [result-getter-2] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 59.0 (TID 31) in 11 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:45:25.057  INFO   57 --- [result-getter-2] org.apache.spark.internal.Logging        : Removed TaskSet 59.0, whose tasks have all completed, from pool 
2022-07-30 11:45:25.058  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 59 (count at Application.java:147) finished in 0.034 s
2022-07-30 11:45:25.059  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 31 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:45:25.059  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 59: Stage finished
2022-07-30 11:45:25.060  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 31 finished: count at Application.java:147, took 0.048914 s
2022-07-30 11:45:25.062  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177916000 ms.0 from job set of time 1659177916000 ms
2022-07-30 11:45:25.062  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 9.062 s for time 1659177916000 ms (execution: 0.130 s)
2022-07-30 11:45:25.062  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177917000 ms.0 from job set of time 1659177917000 ms
2022-07-30 11:45:25.065  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 126 from persistence list
2022-07-30 11:45:25.067  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:45:25.067  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:45:25.068  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 125 from persistence list
2022-07-30 11:45:25.068  INFO   57 --- [-thread-pool-19] org.apache.spark.internal.Logging        : Removing RDD 126
2022-07-30 11:45:25.072  INFO   57 --- [-thread-pool-21] org.apache.spark.internal.Logging        : Removing RDD 125
2022-07-30 11:45:25.072  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[125] at receiverStream at Application.java:122 of time 1659177916000 ms
2022-07-30 11:45:25.077  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177914000 ms
2022-07-30 11:45:25.078  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177914000 ms
2022-07-30 11:45:25.140  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:45:25.141  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 333 (count at Application.java:147) as input to shuffle 28
2022-07-30 11:45:25.141  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 32 (count at Application.java:147) with 1 output partitions
2022-07-30 11:45:25.141  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 61 (count at Application.java:147)
2022-07-30 11:45:25.141  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 60)
2022-07-30 11:45:25.141  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:45:25.142  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 61 (MapPartitionsRDD[336] at count at Application.java:147), which has no missing parents
2022-07-30 11:45:25.143  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_32 stored as values in memory (estimated size 11.0 KiB, free 896.9 MiB)
2022-07-30 11:45:25.145  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_32_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 896.9 MiB)
2022-07-30 11:45:25.145  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_32_piece0 in memory on host.docker.internal:58598 (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:45:25.146  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 32 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:45:25.146  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 61 (MapPartitionsRDD[336] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:45:25.146  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 61.0 with 1 tasks resource profile 0
2022-07-30 11:45:25.147  INFO   57 --- [er-event-loop-2] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 61.0 (TID 32) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:45:25.148  INFO   57 --- [e 61.0 (TID 32)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 61.0 (TID 32)
2022-07-30 11:45:25.150  INFO   57 --- [e 61.0 (TID 32)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:45:25.150  INFO   57 --- [e 61.0 (TID 32)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-30 11:45:25.151  INFO   57 --- [e 61.0 (TID 32)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 61.0 (TID 32). 2555 bytes result sent to driver
2022-07-30 11:45:25.152  INFO   57 --- [result-getter-3] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 61.0 (TID 32) in 5 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:45:25.153  INFO   57 --- [result-getter-3] org.apache.spark.internal.Logging        : Removed TaskSet 61.0, whose tasks have all completed, from pool 
2022-07-30 11:45:25.154  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 61 (count at Application.java:147) finished in 0.011 s
2022-07-30 11:45:25.155  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 32 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:45:25.155  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 61: Stage finished
2022-07-30 11:45:25.155  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 32 finished: count at Application.java:147, took 0.015100 s
2022-07-30 11:45:25.156  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177917000 ms.0 from job set of time 1659177917000 ms
2022-07-30 11:45:25.156  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 8.156 s for time 1659177917000 ms (execution: 0.094 s)
2022-07-30 11:45:25.157  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177918000 ms.0 from job set of time 1659177918000 ms
2022-07-30 11:45:25.158  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 128 from persistence list
2022-07-30 11:45:25.158  INFO   57 --- [-thread-pool-26] org.apache.spark.internal.Logging        : Removing RDD 128
2022-07-30 11:45:25.158  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:45:25.158  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 127 from persistence list
2022-07-30 11:45:25.159  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:45:25.159  INFO   57 --- [-thread-pool-28] org.apache.spark.internal.Logging        : Removing RDD 127
2022-07-30 11:45:25.159  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[127] at receiverStream at Application.java:122 of time 1659177917000 ms
2022-07-30 11:45:25.160  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177915000 ms
2022-07-30 11:45:25.160  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177915000 ms
2022-07-30 11:45:25.215  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:45:25.216  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 342 (count at Application.java:147) as input to shuffle 29
2022-07-30 11:45:25.217  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 33 (count at Application.java:147) with 1 output partitions
2022-07-30 11:45:25.217  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 63 (count at Application.java:147)
2022-07-30 11:45:25.217  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 62)
2022-07-30 11:45:25.218  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:45:25.218  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 63 (MapPartitionsRDD[345] at count at Application.java:147), which has no missing parents
2022-07-30 11:45:25.221  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_33 stored as values in memory (estimated size 11.0 KiB, free 896.9 MiB)
2022-07-30 11:45:25.223  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_33_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 896.9 MiB)
2022-07-30 11:45:25.225  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_33_piece0 in memory on host.docker.internal:58598 (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:45:25.225  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 33 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:45:25.226  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 63 (MapPartitionsRDD[345] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:45:25.226  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 63.0 with 1 tasks resource profile 0
2022-07-30 11:45:25.227  INFO   57 --- [er-event-loop-1] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 63.0 (TID 33) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:45:25.228  INFO   57 --- [e 63.0 (TID 33)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 63.0 (TID 33)
2022-07-30 11:45:25.231  INFO   57 --- [e 63.0 (TID 33)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:45:25.231  INFO   57 --- [e 63.0 (TID 33)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-30 11:45:25.232  INFO   57 --- [e 63.0 (TID 33)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 63.0 (TID 33). 2598 bytes result sent to driver
2022-07-30 11:45:25.233  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 63.0 (TID 33) in 6 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:45:25.233  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Removed TaskSet 63.0, whose tasks have all completed, from pool 
2022-07-30 11:45:25.234  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 63 (count at Application.java:147) finished in 0.015 s
2022-07-30 11:45:25.234  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 33 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:45:25.234  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 63: Stage finished
2022-07-30 11:45:25.235  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 33 finished: count at Application.java:147, took 0.018909 s
2022-07-30 11:45:25.235  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177918000 ms.0 from job set of time 1659177918000 ms
2022-07-30 11:45:25.236  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 7.235 s for time 1659177918000 ms (execution: 0.078 s)
2022-07-30 11:45:25.236  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177919000 ms.0 from job set of time 1659177919000 ms
2022-07-30 11:45:25.236  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 130 from persistence list
2022-07-30 11:45:25.238  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 129 from persistence list
2022-07-30 11:45:25.239  INFO   57 --- [-thread-pool-32] org.apache.spark.internal.Logging        : Removing RDD 130
2022-07-30 11:45:25.239  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:45:25.239  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:45:25.239  INFO   57 --- [-thread-pool-30] org.apache.spark.internal.Logging        : Removing RDD 129
2022-07-30 11:45:25.240  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[129] at receiverStream at Application.java:122 of time 1659177918000 ms
2022-07-30 11:45:25.240  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177916000 ms
2022-07-30 11:45:25.240  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177916000 ms
2022-07-30 11:45:25.307  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:45:25.307  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 351 (count at Application.java:147) as input to shuffle 30
2022-07-30 11:45:25.308  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 34 (count at Application.java:147) with 1 output partitions
2022-07-30 11:45:25.308  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 65 (count at Application.java:147)
2022-07-30 11:45:25.308  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 64)
2022-07-30 11:45:25.309  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:45:25.309  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 65 (MapPartitionsRDD[354] at count at Application.java:147), which has no missing parents
2022-07-30 11:45:25.312  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_34 stored as values in memory (estimated size 11.0 KiB, free 896.8 MiB)
2022-07-30 11:45:25.314  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_34_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 896.8 MiB)
2022-07-30 11:45:25.315  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_34_piece0 in memory on host.docker.internal:58598 (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:45:25.318  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 34 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:45:25.318  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 65 (MapPartitionsRDD[354] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:45:25.319  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 65.0 with 1 tasks resource profile 0
2022-07-30 11:45:25.322  INFO   57 --- [er-event-loop-0] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 65.0 (TID 34) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:45:25.323  INFO   57 --- [e 65.0 (TID 34)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 65.0 (TID 34)
2022-07-30 11:45:25.326  INFO   57 --- [e 65.0 (TID 34)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:45:25.329  INFO   57 --- [e 65.0 (TID 34)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 2 ms
2022-07-30 11:45:25.330  INFO   57 --- [e 65.0 (TID 34)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 65.0 (TID 34). 2598 bytes result sent to driver
2022-07-30 11:45:25.332  INFO   57 --- [result-getter-1] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 65.0 (TID 34) in 11 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:45:25.332  INFO   57 --- [result-getter-1] org.apache.spark.internal.Logging        : Removed TaskSet 65.0, whose tasks have all completed, from pool 
2022-07-30 11:45:25.333  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 65 (count at Application.java:147) finished in 0.023 s
2022-07-30 11:45:25.334  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 34 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:45:25.334  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 65: Stage finished
2022-07-30 11:45:25.335  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 34 finished: count at Application.java:147, took 0.027852 s
2022-07-30 11:45:25.341  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177919000 ms.0 from job set of time 1659177919000 ms
2022-07-30 11:45:25.341  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:45:25.342  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:45:25.342  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 6.341 s for time 1659177919000 ms (execution: 0.105 s)
2022-07-30 11:45:25.343  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177920000 ms.0 from job set of time 1659177920000 ms
2022-07-30 11:45:25.342  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 132 from persistence list
2022-07-30 11:45:25.345  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 131 from persistence list
2022-07-30 11:45:25.345  INFO   57 --- [-thread-pool-38] org.apache.spark.internal.Logging        : Removing RDD 132
2022-07-30 11:45:25.346  INFO   57 --- [-thread-pool-37] org.apache.spark.internal.Logging        : Removing RDD 131
2022-07-30 11:45:25.347  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[131] at receiverStream at Application.java:122 of time 1659177919000 ms
2022-07-30 11:45:25.348  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177917000 ms
2022-07-30 11:45:25.348  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177917000 ms
2022-07-30 11:45:25.416  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:45:25.417  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 360 (count at Application.java:147) as input to shuffle 31
2022-07-30 11:45:25.418  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 35 (count at Application.java:147) with 1 output partitions
2022-07-30 11:45:25.418  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 67 (count at Application.java:147)
2022-07-30 11:45:25.418  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 66)
2022-07-30 11:45:25.418  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:45:25.418  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 67 (MapPartitionsRDD[363] at count at Application.java:147), which has no missing parents
2022-07-30 11:45:25.422  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_35 stored as values in memory (estimated size 11.0 KiB, free 896.8 MiB)
2022-07-30 11:45:25.426  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_35_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 896.8 MiB)
2022-07-30 11:45:25.426  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_35_piece0 in memory on host.docker.internal:58598 (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:45:25.427  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 35 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:45:25.427  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 67 (MapPartitionsRDD[363] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:45:25.428  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 67.0 with 1 tasks resource profile 0
2022-07-30 11:45:25.428  INFO   57 --- [er-event-loop-3] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 67.0 (TID 35) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:45:25.429  INFO   57 --- [e 67.0 (TID 35)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 67.0 (TID 35)
2022-07-30 11:45:25.433  INFO   57 --- [e 67.0 (TID 35)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:45:25.433  INFO   57 --- [e 67.0 (TID 35)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-30 11:45:25.434  INFO   57 --- [e 67.0 (TID 35)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 67.0 (TID 35). 2555 bytes result sent to driver
2022-07-30 11:45:25.436  INFO   57 --- [result-getter-2] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 67.0 (TID 35) in 7 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:45:25.436  INFO   57 --- [result-getter-2] org.apache.spark.internal.Logging        : Removed TaskSet 67.0, whose tasks have all completed, from pool 
2022-07-30 11:45:25.437  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 67 (count at Application.java:147) finished in 0.018 s
2022-07-30 11:45:25.437  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 35 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:45:25.437  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 67: Stage finished
2022-07-30 11:45:25.438  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 35 finished: count at Application.java:147, took 0.021177 s
2022-07-30 11:45:25.439  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177920000 ms.0 from job set of time 1659177920000 ms
2022-07-30 11:45:25.439  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 5.439 s for time 1659177920000 ms (execution: 0.096 s)
2022-07-30 11:45:25.439  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177921000 ms.0 from job set of time 1659177921000 ms
2022-07-30 11:45:25.440  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 135 from persistence list
2022-07-30 11:45:25.440  INFO   57 --- [-thread-pool-44] org.apache.spark.internal.Logging        : Removing RDD 135
2022-07-30 11:45:25.441  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 134 from persistence list
2022-07-30 11:45:25.441  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:45:25.441  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[134] at receiverStream at Application.java:122 of time 1659177920000 ms
2022-07-30 11:45:25.441  INFO   57 --- [-thread-pool-42] org.apache.spark.internal.Logging        : Removing RDD 134
2022-07-30 11:45:25.441  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:45:25.442  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177918000 ms
2022-07-30 11:45:25.442  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177918000 ms
2022-07-30 11:45:25.506  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:45:25.507  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 369 (count at Application.java:147) as input to shuffle 32
2022-07-30 11:45:25.508  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 36 (count at Application.java:147) with 1 output partitions
2022-07-30 11:45:25.509  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 69 (count at Application.java:147)
2022-07-30 11:45:25.509  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 68)
2022-07-30 11:45:25.509  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:45:25.510  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 69 (MapPartitionsRDD[372] at count at Application.java:147), which has no missing parents
2022-07-30 11:45:25.512  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_36 stored as values in memory (estimated size 11.0 KiB, free 896.8 MiB)
2022-07-30 11:45:25.515  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_36_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 896.8 MiB)
2022-07-30 11:45:25.517  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_36_piece0 in memory on host.docker.internal:58598 (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:45:25.517  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 36 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:45:25.518  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 69 (MapPartitionsRDD[372] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:45:25.518  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 69.0 with 1 tasks resource profile 0
2022-07-30 11:45:25.524  INFO   57 --- [er-event-loop-2] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 69.0 (TID 36) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:45:25.527  INFO   57 --- [e 69.0 (TID 36)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 69.0 (TID 36)
2022-07-30 11:45:25.532  INFO   57 --- [e 69.0 (TID 36)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:45:25.533  INFO   57 --- [e 69.0 (TID 36)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-30 11:45:25.534  INFO   57 --- [e 69.0 (TID 36)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 69.0 (TID 36). 2598 bytes result sent to driver
2022-07-30 11:45:25.535  INFO   57 --- [result-getter-3] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 69.0 (TID 36) in 11 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:45:25.535  INFO   57 --- [result-getter-3] org.apache.spark.internal.Logging        : Removed TaskSet 69.0, whose tasks have all completed, from pool 
2022-07-30 11:45:25.590  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 69 (count at Application.java:147) finished in 0.026 s
2022-07-30 11:45:25.594  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 36 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:45:25.594  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 69: Stage finished
2022-07-30 11:45:25.595  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 36 finished: count at Application.java:147, took 0.087742 s
2022-07-30 11:45:25.596  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177921000 ms.0 from job set of time 1659177921000 ms
2022-07-30 11:45:25.597  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 4.596 s for time 1659177921000 ms (execution: 0.157 s)
2022-07-30 11:45:25.597  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177922000 ms.0 from job set of time 1659177922000 ms
2022-07-30 11:45:25.598  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 137 from persistence list
2022-07-30 11:45:25.599  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_33_piece0 on host.docker.internal:58598 in memory (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:45:25.600  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 136 from persistence list
2022-07-30 11:45:25.600  INFO   57 --- [-thread-pool-55] org.apache.spark.internal.Logging        : Removing RDD 137
2022-07-30 11:45:25.602  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[136] at receiverStream at Application.java:122 of time 1659177921000 ms
2022-07-30 11:45:25.604  INFO   57 --- [-thread-pool-62] org.apache.spark.internal.Logging        : Removing RDD 136
2022-07-30 11:45:25.604  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177919000 ms
2022-07-30 11:45:25.605  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177919000 ms
2022-07-30 11:45:25.604  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:45:25.605  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:45:25.608  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_21_piece0 on host.docker.internal:58598 in memory (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:45:25.612  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_28_piece0 on host.docker.internal:58598 in memory (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:45:25.617  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_16_piece0 on host.docker.internal:58598 in memory (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:45:25.631  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_20_piece0 on host.docker.internal:58598 in memory (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:45:25.665  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_24_piece0 on host.docker.internal:58598 in memory (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:45:25.716  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_26_piece0 on host.docker.internal:58598 in memory (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:45:25.746  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_15_piece0 on host.docker.internal:58598 in memory (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:45:25.749  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_14_piece0 on host.docker.internal:58598 in memory (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:45:25.752  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_19_piece0 on host.docker.internal:58598 in memory (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:45:25.757  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_30_piece0 on host.docker.internal:58598 in memory (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:45:25.762  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:45:25.763  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 378 (count at Application.java:147) as input to shuffle 33
2022-07-30 11:45:25.763  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_25_piece0 on host.docker.internal:58598 in memory (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:45:25.763  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 37 (count at Application.java:147) with 1 output partitions
2022-07-30 11:45:25.764  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 71 (count at Application.java:147)
2022-07-30 11:45:25.764  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 70)
2022-07-30 11:45:25.764  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:45:25.765  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 71 (MapPartitionsRDD[381] at count at Application.java:147), which has no missing parents
2022-07-30 11:45:25.769  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_37 stored as values in memory (estimated size 11.0 KiB, free 897.0 MiB)
2022-07-30 11:45:25.772  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_35_piece0 on host.docker.internal:58598 in memory (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:45:25.775  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_37_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.0 MiB)
2022-07-30 11:45:25.776  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_37_piece0 in memory on host.docker.internal:58598 (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:45:25.777  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 37 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:45:25.778  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 71 (MapPartitionsRDD[381] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:45:25.778  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 71.0 with 1 tasks resource profile 0
2022-07-30 11:45:25.779  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_22_piece0 on host.docker.internal:58598 in memory (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:45:25.780  INFO   57 --- [er-event-loop-1] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 71.0 (TID 37) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:45:25.782  INFO   57 --- [e 71.0 (TID 37)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 71.0 (TID 37)
2022-07-30 11:45:25.788  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_27_piece0 on host.docker.internal:58598 in memory (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:45:25.788  INFO   57 --- [e 71.0 (TID 37)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:45:25.789  INFO   57 --- [e 71.0 (TID 37)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 2 ms
2022-07-30 11:45:25.790  INFO   57 --- [e 71.0 (TID 37)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 71.0 (TID 37). 2555 bytes result sent to driver
2022-07-30 11:45:25.792  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 71.0 (TID 37) in 12 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:45:25.792  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Removed TaskSet 71.0, whose tasks have all completed, from pool 
2022-07-30 11:45:25.793  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 71 (count at Application.java:147) finished in 0.026 s
2022-07-30 11:45:25.794  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 37 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:45:25.794  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 71: Stage finished
2022-07-30 11:45:25.795  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 37 finished: count at Application.java:147, took 0.033010 s
2022-07-30 11:45:25.797  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177922000 ms.0 from job set of time 1659177922000 ms
2022-07-30 11:45:25.797  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 3.797 s for time 1659177922000 ms (execution: 0.200 s)
2022-07-30 11:45:25.798  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177923000 ms.0 from job set of time 1659177923000 ms
2022-07-30 11:45:25.799  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:45:25.799  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:45:25.802  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 157 from persistence list
2022-07-30 11:45:25.804  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 156 from persistence list
2022-07-30 11:45:25.804  INFO   57 --- [-thread-pool-39] org.apache.spark.internal.Logging        : Removing RDD 157
2022-07-30 11:45:25.805  INFO   57 --- [-thread-pool-40] org.apache.spark.internal.Logging        : Removing RDD 156
2022-07-30 11:45:25.806  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[156] at receiverStream at Application.java:122 of time 1659177922000 ms
2022-07-30 11:45:25.806  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177920000 ms
2022-07-30 11:45:25.807  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177920000 ms
2022-07-30 11:45:25.809  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_23_piece0 on host.docker.internal:58598 in memory (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:45:25.812  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_17_piece0 on host.docker.internal:58598 in memory (size: 5.4 KiB, free: 897.5 MiB)
2022-07-30 11:45:25.821  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_32_piece0 on host.docker.internal:58598 in memory (size: 5.4 KiB, free: 897.5 MiB)
2022-07-30 11:45:25.824  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_31_piece0 on host.docker.internal:58598 in memory (size: 5.4 KiB, free: 897.5 MiB)
2022-07-30 11:45:25.827  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_29_piece0 on host.docker.internal:58598 in memory (size: 5.4 KiB, free: 897.5 MiB)
2022-07-30 11:45:25.832  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_18_piece0 on host.docker.internal:58598 in memory (size: 5.4 KiB, free: 897.5 MiB)
2022-07-30 11:45:25.834  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_34_piece0 on host.docker.internal:58598 in memory (size: 5.4 KiB, free: 897.5 MiB)
2022-07-30 11:45:25.885  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:45:25.888  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 387 (count at Application.java:147) as input to shuffle 34
2022-07-30 11:45:25.889  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 38 (count at Application.java:147) with 1 output partitions
2022-07-30 11:45:25.889  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 73 (count at Application.java:147)
2022-07-30 11:45:25.889  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 72)
2022-07-30 11:45:25.889  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:45:25.889  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 73 (MapPartitionsRDD[390] at count at Application.java:147), which has no missing parents
2022-07-30 11:45:25.898  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_38 stored as values in memory (estimated size 11.0 KiB, free 897.1 MiB)
2022-07-30 11:45:25.901  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_38_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.1 MiB)
2022-07-30 11:45:25.915  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_38_piece0 in memory on host.docker.internal:58598 (size: 5.4 KiB, free: 897.5 MiB)
2022-07-30 11:45:25.917  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 38 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:45:25.918  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 73 (MapPartitionsRDD[390] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:45:25.918  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 73.0 with 1 tasks resource profile 0
2022-07-30 11:45:25.941  INFO   57 --- [er-event-loop-0] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 73.0 (TID 38) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:45:25.942  INFO   57 --- [e 73.0 (TID 38)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 73.0 (TID 38)
2022-07-30 11:45:25.947  INFO   57 --- [e 73.0 (TID 38)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:45:25.947  INFO   57 --- [e 73.0 (TID 38)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-30 11:45:25.950  INFO   57 --- [e 73.0 (TID 38)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 73.0 (TID 38). 2555 bytes result sent to driver
2022-07-30 11:45:25.950  INFO   57 --- [result-getter-1] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 73.0 (TID 38) in 31 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:45:25.951  INFO   57 --- [result-getter-1] org.apache.spark.internal.Logging        : Removed TaskSet 73.0, whose tasks have all completed, from pool 
2022-07-30 11:45:25.951  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 73 (count at Application.java:147) finished in 0.060 s
2022-07-30 11:45:25.952  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 38 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:45:25.956  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 73: Stage finished
2022-07-30 11:45:25.958  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 38 finished: count at Application.java:147, took 0.071290 s
2022-07-30 11:45:25.959  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177923000 ms.0 from job set of time 1659177923000 ms
2022-07-30 11:45:25.960  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 2.959 s for time 1659177923000 ms (execution: 0.161 s)
2022-07-30 11:45:25.960  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177924000 ms.0 from job set of time 1659177924000 ms
2022-07-30 11:45:25.962  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:45:25.963  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:45:25.964  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 168 from persistence list
2022-07-30 11:45:25.965  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 167 from persistence list
2022-07-30 11:45:25.966  INFO   57 --- [-thread-pool-90] org.apache.spark.internal.Logging        : Removing RDD 168
2022-07-30 11:45:25.975  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[167] at receiverStream at Application.java:122 of time 1659177923000 ms
2022-07-30 11:45:25.990  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177921000 ms
2022-07-30 11:45:25.990  INFO   57 --- [-thread-pool-93] org.apache.spark.internal.Logging        : Removing RDD 167
2022-07-30 11:45:25.990  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177921000 ms
2022-07-30 11:45:26.004  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177926000 ms
2022-07-30 11:45:26.055  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:45:26.056  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 398 (count at Application.java:147) as input to shuffle 35
2022-07-30 11:45:26.057  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 39 (count at Application.java:147) with 1 output partitions
2022-07-30 11:45:26.057  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 75 (count at Application.java:147)
2022-07-30 11:45:26.057  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 74)
2022-07-30 11:45:26.057  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:45:26.058  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 75 (MapPartitionsRDD[401] at count at Application.java:147), which has no missing parents
2022-07-30 11:45:26.060  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_39 stored as values in memory (estimated size 11.0 KiB, free 897.1 MiB)
2022-07-30 11:45:26.062  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_39_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.1 MiB)
2022-07-30 11:45:26.062  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_39_piece0 in memory on host.docker.internal:58598 (size: 5.4 KiB, free: 897.5 MiB)
2022-07-30 11:45:26.063  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 39 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:45:26.067  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 75 (MapPartitionsRDD[401] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:45:26.067  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 75.0 with 1 tasks resource profile 0
2022-07-30 11:45:26.068  INFO   57 --- [er-event-loop-3] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 75.0 (TID 39) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:45:26.068  INFO   57 --- [e 75.0 (TID 39)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 75.0 (TID 39)
2022-07-30 11:45:26.073  INFO   57 --- [e 75.0 (TID 39)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:45:26.073  INFO   57 --- [e 75.0 (TID 39)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-30 11:45:26.074  INFO   57 --- [e 75.0 (TID 39)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 75.0 (TID 39). 2555 bytes result sent to driver
2022-07-30 11:45:26.075  INFO   57 --- [result-getter-2] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 75.0 (TID 39) in 8 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:45:26.075  INFO   57 --- [result-getter-2] org.apache.spark.internal.Logging        : Removed TaskSet 75.0, whose tasks have all completed, from pool 
2022-07-30 11:45:26.075  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 75 (count at Application.java:147) finished in 0.016 s
2022-07-30 11:45:26.076  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 39 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:45:26.076  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 75: Stage finished
2022-07-30 11:45:26.076  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 39 finished: count at Application.java:147, took 0.020545 s
2022-07-30 11:45:26.077  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177924000 ms.0 from job set of time 1659177924000 ms
2022-07-30 11:45:26.077  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 2.077 s for time 1659177924000 ms (execution: 0.117 s)
2022-07-30 11:45:26.077  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177925000 ms.0 from job set of time 1659177925000 ms
2022-07-30 11:45:26.078  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 206 from persistence list
2022-07-30 11:45:26.080  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:45:26.080  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:45:26.081  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 205 from persistence list
2022-07-30 11:45:26.081  INFO   57 --- [-thread-pool-95] org.apache.spark.internal.Logging        : Removing RDD 206
2022-07-30 11:45:26.083  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[205] at receiverStream at Application.java:122 of time 1659177924000 ms
2022-07-30 11:45:26.083  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177922000 ms
2022-07-30 11:45:26.083  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177922000 ms
2022-07-30 11:45:26.084  INFO   57 --- [c-thread-pool-0] org.apache.spark.internal.Logging        : Removing RDD 205
2022-07-30 11:45:26.190  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:45:26.193  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 407 (count at Application.java:147) as input to shuffle 36
2022-07-30 11:45:26.194  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 40 (count at Application.java:147) with 1 output partitions
2022-07-30 11:45:26.194  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 77 (count at Application.java:147)
2022-07-30 11:45:26.194  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 76)
2022-07-30 11:45:26.194  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:45:26.195  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 77 (MapPartitionsRDD[410] at count at Application.java:147), which has no missing parents
2022-07-30 11:45:26.198  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_40 stored as values in memory (estimated size 11.0 KiB, free 897.1 MiB)
2022-07-30 11:45:26.208  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_40_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.1 MiB)
2022-07-30 11:45:26.209  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_40_piece0 in memory on host.docker.internal:58598 (size: 5.4 KiB, free: 897.5 MiB)
2022-07-30 11:45:26.211  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 40 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:45:26.212  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 77 (MapPartitionsRDD[410] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:45:26.212  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 77.0 with 1 tasks resource profile 0
2022-07-30 11:45:26.213  INFO   57 --- [er-event-loop-2] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 77.0 (TID 40) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:45:26.214  INFO   57 --- [e 77.0 (TID 40)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 77.0 (TID 40)
2022-07-30 11:45:26.218  INFO   57 --- [e 77.0 (TID 40)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:45:26.218  INFO   57 --- [e 77.0 (TID 40)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-30 11:45:26.223  INFO   57 --- [e 77.0 (TID 40)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 77.0 (TID 40). 2555 bytes result sent to driver
2022-07-30 11:45:26.225  INFO   57 --- [result-getter-3] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 77.0 (TID 40) in 12 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:45:26.225  INFO   57 --- [result-getter-3] org.apache.spark.internal.Logging        : Removed TaskSet 77.0, whose tasks have all completed, from pool 
2022-07-30 11:45:26.225  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 77 (count at Application.java:147) finished in 0.028 s
2022-07-30 11:45:26.226  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 40 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:45:26.226  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 77: Stage finished
2022-07-30 11:45:26.227  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 40 finished: count at Application.java:147, took 0.035992 s
2022-07-30 11:45:26.227  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177925000 ms.0 from job set of time 1659177925000 ms
2022-07-30 11:45:26.228  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 1.227 s for time 1659177925000 ms (execution: 0.150 s)
2022-07-30 11:45:26.228  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177926000 ms.0 from job set of time 1659177926000 ms
2022-07-30 11:45:26.229  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 257 from persistence list
2022-07-30 11:45:26.230  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:45:26.230  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:45:26.230  INFO   57 --- [c-thread-pool-3] org.apache.spark.internal.Logging        : Removing RDD 257
2022-07-30 11:45:26.230  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 256 from persistence list
2022-07-30 11:45:26.232  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[256] at receiverStream at Application.java:122 of time 1659177925000 ms
2022-07-30 11:45:26.233  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177923000 ms
2022-07-30 11:45:26.233  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177923000 ms
2022-07-30 11:45:26.233  INFO   57 --- [c-thread-pool-6] org.apache.spark.internal.Logging        : Removing RDD 256
2022-07-30 11:45:26.283  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:45:26.283  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 416 (count at Application.java:147) as input to shuffle 37
2022-07-30 11:45:26.283  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 41 (count at Application.java:147) with 1 output partitions
2022-07-30 11:45:26.284  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 79 (count at Application.java:147)
2022-07-30 11:45:26.284  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 78)
2022-07-30 11:45:26.284  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:45:26.284  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 79 (MapPartitionsRDD[419] at count at Application.java:147), which has no missing parents
2022-07-30 11:45:26.285  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_41 stored as values in memory (estimated size 11.0 KiB, free 897.1 MiB)
2022-07-30 11:45:26.287  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_41_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.1 MiB)
2022-07-30 11:45:26.288  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_41_piece0 in memory on host.docker.internal:58598 (size: 5.4 KiB, free: 897.5 MiB)
2022-07-30 11:45:26.288  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 41 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:45:26.289  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 79 (MapPartitionsRDD[419] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:45:26.289  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 79.0 with 1 tasks resource profile 0
2022-07-30 11:45:26.290  INFO   57 --- [er-event-loop-1] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 79.0 (TID 41) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:45:26.290  INFO   57 --- [e 79.0 (TID 41)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 79.0 (TID 41)
2022-07-30 11:45:26.293  INFO   57 --- [e 79.0 (TID 41)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:45:26.294  INFO   57 --- [e 79.0 (TID 41)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-30 11:45:26.294  INFO   57 --- [e 79.0 (TID 41)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 79.0 (TID 41). 2555 bytes result sent to driver
2022-07-30 11:45:26.295  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 79.0 (TID 41) in 6 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:45:26.295  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Removed TaskSet 79.0, whose tasks have all completed, from pool 
2022-07-30 11:45:26.296  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 79 (count at Application.java:147) finished in 0.011 s
2022-07-30 11:45:26.297  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 41 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:45:26.297  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 79: Stage finished
2022-07-30 11:45:26.297  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 41 finished: count at Application.java:147, took 0.014296 s
2022-07-30 11:45:26.298  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177926000 ms.0 from job set of time 1659177926000 ms
2022-07-30 11:45:26.298  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 0.298 s for time 1659177926000 ms (execution: 0.070 s)
2022-07-30 11:45:26.298  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 327 from persistence list
2022-07-30 11:45:26.299  INFO   57 --- [c-thread-pool-9] org.apache.spark.internal.Logging        : Removing RDD 327
2022-07-30 11:45:26.299  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 326 from persistence list
2022-07-30 11:45:26.299  INFO   57 --- [-thread-pool-10] org.apache.spark.internal.Logging        : Removing RDD 326
2022-07-30 11:45:26.300  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[326] at receiverStream at Application.java:122 of time 1659177926000 ms
2022-07-30 11:45:26.300  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177924000 ms
2022-07-30 11:45:26.300  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177924000 ms
2022-07-30 11:45:27.007  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177927000 ms
2022-07-30 11:45:27.007  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177927000 ms.0 from job set of time 1659177927000 ms
2022-07-30 11:45:27.010  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:45:27.010  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:45:27.183  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:45:27.184  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 427 (count at Application.java:147) as input to shuffle 38
2022-07-30 11:45:27.184  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 42 (count at Application.java:147) with 1 output partitions
2022-07-30 11:45:27.184  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 81 (count at Application.java:147)
2022-07-30 11:45:27.184  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 80)
2022-07-30 11:45:27.185  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:45:27.185  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 81 (MapPartitionsRDD[430] at count at Application.java:147), which has no missing parents
2022-07-30 11:45:27.187  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_42 stored as values in memory (estimated size 11.0 KiB, free 897.1 MiB)
2022-07-30 11:45:27.290  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_42_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.1 MiB)
2022-07-30 11:45:27.294  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_42_piece0 in memory on host.docker.internal:58598 (size: 5.4 KiB, free: 897.5 MiB)
2022-07-30 11:45:27.295  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 42 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:45:27.295  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 81 (MapPartitionsRDD[430] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:45:27.295  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 81.0 with 1 tasks resource profile 0
2022-07-30 11:45:27.296  INFO   57 --- [er-event-loop-0] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 81.0 (TID 42) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:45:27.297  INFO   57 --- [e 81.0 (TID 42)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 81.0 (TID 42)
2022-07-30 11:45:27.300  INFO   57 --- [e 81.0 (TID 42)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:45:27.301  INFO   57 --- [e 81.0 (TID 42)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-30 11:45:27.301  INFO   57 --- [e 81.0 (TID 42)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 81.0 (TID 42). 2555 bytes result sent to driver
2022-07-30 11:45:27.302  INFO   57 --- [result-getter-1] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 81.0 (TID 42) in 6 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:45:27.302  INFO   57 --- [result-getter-1] org.apache.spark.internal.Logging        : Removed TaskSet 81.0, whose tasks have all completed, from pool 
2022-07-30 11:45:27.306  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 81 (count at Application.java:147) finished in 0.118 s
2022-07-30 11:45:27.307  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 42 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:45:27.308  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 81: Stage finished
2022-07-30 11:45:27.309  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 42 finished: count at Application.java:147, took 0.125185 s
2022-07-30 11:45:27.311  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177927000 ms.0 from job set of time 1659177927000 ms
2022-07-30 11:45:27.311  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 0.311 s for time 1659177927000 ms (execution: 0.304 s)
2022-07-30 11:45:27.311  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 394 from persistence list
2022-07-30 11:45:27.313  INFO   57 --- [-thread-pool-14] org.apache.spark.internal.Logging        : Removing RDD 394
2022-07-30 11:45:27.313  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 393 from persistence list
2022-07-30 11:45:27.314  INFO   57 --- [-thread-pool-17] org.apache.spark.internal.Logging        : Removing RDD 393
2022-07-30 11:45:27.314  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[393] at receiverStream at Application.java:122 of time 1659177927000 ms
2022-07-30 11:45:27.314  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177925000 ms
2022-07-30 11:45:27.314  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177925000 ms
2022-07-30 11:45:28.001  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177928000 ms
2022-07-30 11:45:28.001  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177928000 ms.0 from job set of time 1659177928000 ms
2022-07-30 11:45:28.003  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:45:28.004  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:45:28.064  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:45:28.065  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 438 (count at Application.java:147) as input to shuffle 39
2022-07-30 11:45:28.066  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 43 (count at Application.java:147) with 1 output partitions
2022-07-30 11:45:28.066  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 83 (count at Application.java:147)
2022-07-30 11:45:28.066  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 82)
2022-07-30 11:45:28.066  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:45:28.066  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 83 (MapPartitionsRDD[441] at count at Application.java:147), which has no missing parents
2022-07-30 11:45:28.069  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_43 stored as values in memory (estimated size 11.0 KiB, free 897.1 MiB)
2022-07-30 11:45:28.071  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_43_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.0 MiB)
2022-07-30 11:45:28.071  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_43_piece0 in memory on host.docker.internal:58598 (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:45:28.072  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 43 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:45:28.072  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 83 (MapPartitionsRDD[441] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:45:28.072  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 83.0 with 1 tasks resource profile 0
2022-07-30 11:45:28.073  INFO   57 --- [er-event-loop-1] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 83.0 (TID 43) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:45:28.074  INFO   57 --- [e 83.0 (TID 43)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 83.0 (TID 43)
2022-07-30 11:45:28.076  INFO   57 --- [e 83.0 (TID 43)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:45:28.076  INFO   57 --- [e 83.0 (TID 43)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-30 11:45:28.077  INFO   57 --- [e 83.0 (TID 43)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 83.0 (TID 43). 2598 bytes result sent to driver
2022-07-30 11:45:28.078  INFO   57 --- [result-getter-2] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 83.0 (TID 43) in 5 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:45:28.078  INFO   57 --- [result-getter-2] org.apache.spark.internal.Logging        : Removed TaskSet 83.0, whose tasks have all completed, from pool 
2022-07-30 11:45:28.078  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 83 (count at Application.java:147) finished in 0.011 s
2022-07-30 11:45:28.079  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 43 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:45:28.079  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 83: Stage finished
2022-07-30 11:45:28.079  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 43 finished: count at Application.java:147, took 0.014552 s
2022-07-30 11:45:28.080  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177928000 ms.0 from job set of time 1659177928000 ms
2022-07-30 11:45:28.080  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 0.080 s for time 1659177928000 ms (execution: 0.079 s)
2022-07-30 11:45:28.080  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 421 from persistence list
2022-07-30 11:45:28.081  INFO   57 --- [-thread-pool-21] org.apache.spark.internal.Logging        : Removing RDD 421
2022-07-30 11:45:28.081  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 420 from persistence list
2022-07-30 11:45:28.081  INFO   57 --- [-thread-pool-23] org.apache.spark.internal.Logging        : Removing RDD 420
2022-07-30 11:45:28.082  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[420] at receiverStream at Application.java:122 of time 1659177928000 ms
2022-07-30 11:45:28.082  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177926000 ms
2022-07-30 11:45:28.082  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177926000 ms
2022-07-30 11:45:29.005  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177929000 ms
2022-07-30 11:45:29.005  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177929000 ms.0 from job set of time 1659177929000 ms
2022-07-30 11:45:29.011  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:45:29.011  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:45:29.063  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:45:29.064  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 449 (count at Application.java:147) as input to shuffle 40
2022-07-30 11:45:29.064  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 44 (count at Application.java:147) with 1 output partitions
2022-07-30 11:45:29.064  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 85 (count at Application.java:147)
2022-07-30 11:45:29.064  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 84)
2022-07-30 11:45:29.065  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:45:29.065  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 85 (MapPartitionsRDD[452] at count at Application.java:147), which has no missing parents
2022-07-30 11:45:29.066  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_44 stored as values in memory (estimated size 11.0 KiB, free 897.0 MiB)
2022-07-30 11:45:29.068  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_44_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.0 MiB)
2022-07-30 11:45:29.068  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_44_piece0 in memory on host.docker.internal:58598 (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:45:29.069  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 44 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:45:29.069  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 85 (MapPartitionsRDD[452] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:45:29.070  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 85.0 with 1 tasks resource profile 0
2022-07-30 11:45:29.071  INFO   57 --- [er-event-loop-0] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 85.0 (TID 44) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:45:29.071  INFO   57 --- [e 85.0 (TID 44)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 85.0 (TID 44)
2022-07-30 11:45:29.074  INFO   57 --- [e 85.0 (TID 44)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:45:29.074  INFO   57 --- [e 85.0 (TID 44)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-30 11:45:29.075  INFO   57 --- [e 85.0 (TID 44)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 85.0 (TID 44). 2555 bytes result sent to driver
2022-07-30 11:45:29.075  INFO   57 --- [result-getter-3] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 85.0 (TID 44) in 4 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:45:29.076  INFO   57 --- [result-getter-3] org.apache.spark.internal.Logging        : Removed TaskSet 85.0, whose tasks have all completed, from pool 
2022-07-30 11:45:29.076  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 85 (count at Application.java:147) finished in 0.011 s
2022-07-30 11:45:29.076  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 44 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:45:29.076  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 85: Stage finished
2022-07-30 11:45:29.077  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 44 finished: count at Application.java:147, took 0.012924 s
2022-07-30 11:45:29.077  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177929000 ms.0 from job set of time 1659177929000 ms
2022-07-30 11:45:29.077  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 0.077 s for time 1659177929000 ms (execution: 0.072 s)
2022-07-30 11:45:29.078  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 432 from persistence list
2022-07-30 11:45:29.078  INFO   57 --- [-thread-pool-25] org.apache.spark.internal.Logging        : Removing RDD 432
2022-07-30 11:45:29.079  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 431 from persistence list
2022-07-30 11:45:29.079  INFO   57 --- [-thread-pool-29] org.apache.spark.internal.Logging        : Removing RDD 431
2022-07-30 11:45:29.079  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[431] at receiverStream at Application.java:122 of time 1659177929000 ms
2022-07-30 11:45:29.080  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177927000 ms
2022-07-30 11:45:29.080  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177927000 ms
2022-07-30 11:45:30.003  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177930000 ms
2022-07-30 11:45:30.003  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177930000 ms.0 from job set of time 1659177930000 ms
2022-07-30 11:45:30.006  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:45:30.006  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:45:30.061  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:45:30.061  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 460 (count at Application.java:147) as input to shuffle 41
2022-07-30 11:45:30.062  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 45 (count at Application.java:147) with 1 output partitions
2022-07-30 11:45:30.062  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 87 (count at Application.java:147)
2022-07-30 11:45:30.062  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 86)
2022-07-30 11:45:30.062  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:45:30.063  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 87 (MapPartitionsRDD[463] at count at Application.java:147), which has no missing parents
2022-07-30 11:45:30.064  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_45 stored as values in memory (estimated size 11.0 KiB, free 897.0 MiB)
2022-07-30 11:45:30.065  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_45_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.0 MiB)
2022-07-30 11:45:30.066  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_45_piece0 in memory on host.docker.internal:58598 (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:45:30.067  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 45 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:45:30.067  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 87 (MapPartitionsRDD[463] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:45:30.067  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 87.0 with 1 tasks resource profile 0
2022-07-30 11:45:30.068  INFO   57 --- [er-event-loop-3] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 87.0 (TID 45) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:45:30.069  INFO   57 --- [e 87.0 (TID 45)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 87.0 (TID 45)
2022-07-30 11:45:30.073  INFO   57 --- [e 87.0 (TID 45)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:45:30.073  INFO   57 --- [e 87.0 (TID 45)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-30 11:45:30.074  INFO   57 --- [e 87.0 (TID 45)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 87.0 (TID 45). 2555 bytes result sent to driver
2022-07-30 11:45:30.075  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 87.0 (TID 45) in 7 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:45:30.075  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Removed TaskSet 87.0, whose tasks have all completed, from pool 
2022-07-30 11:45:30.076  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 87 (count at Application.java:147) finished in 0.013 s
2022-07-30 11:45:30.077  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 45 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:45:30.077  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 87: Stage finished
2022-07-30 11:45:30.077  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 45 finished: count at Application.java:147, took 0.016225 s
2022-07-30 11:45:30.078  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177930000 ms.0 from job set of time 1659177930000 ms
2022-07-30 11:45:30.079  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 0.078 s for time 1659177930000 ms (execution: 0.075 s)
2022-07-30 11:45:30.080  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 443 from persistence list
2022-07-30 11:45:30.081  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 442 from persistence list
2022-07-30 11:45:30.081  INFO   57 --- [-thread-pool-33] org.apache.spark.internal.Logging        : Removing RDD 443
2022-07-30 11:45:30.082  INFO   57 --- [-thread-pool-36] org.apache.spark.internal.Logging        : Removing RDD 442
2022-07-30 11:45:30.082  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[442] at receiverStream at Application.java:122 of time 1659177930000 ms
2022-07-30 11:45:30.082  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177928000 ms
2022-07-30 11:45:30.082  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177928000 ms
2022-07-30 11:45:31.001  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177931000 ms
2022-07-30 11:45:31.002  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177931000 ms.0 from job set of time 1659177931000 ms
2022-07-30 11:45:31.004  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:45:31.004  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:45:31.052  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:45:31.053  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 471 (count at Application.java:147) as input to shuffle 42
2022-07-30 11:45:31.053  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 46 (count at Application.java:147) with 1 output partitions
2022-07-30 11:45:31.054  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 89 (count at Application.java:147)
2022-07-30 11:45:31.054  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 88)
2022-07-30 11:45:31.054  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:45:31.054  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 89 (MapPartitionsRDD[474] at count at Application.java:147), which has no missing parents
2022-07-30 11:45:31.056  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_46 stored as values in memory (estimated size 11.0 KiB, free 897.0 MiB)
2022-07-30 11:45:31.057  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_46_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.0 MiB)
2022-07-30 11:45:31.058  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_46_piece0 in memory on host.docker.internal:58598 (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:45:31.058  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 46 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:45:31.058  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 89 (MapPartitionsRDD[474] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:45:31.058  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 89.0 with 1 tasks resource profile 0
2022-07-30 11:45:31.059  INFO   57 --- [er-event-loop-2] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 89.0 (TID 46) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:45:31.060  INFO   57 --- [e 89.0 (TID 46)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 89.0 (TID 46)
2022-07-30 11:45:31.061  INFO   57 --- [e 89.0 (TID 46)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:45:31.062  INFO   57 --- [e 89.0 (TID 46)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-30 11:45:31.063  INFO   57 --- [e 89.0 (TID 46)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 89.0 (TID 46). 2598 bytes result sent to driver
2022-07-30 11:45:31.063  INFO   57 --- [result-getter-1] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 89.0 (TID 46) in 4 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:45:31.063  INFO   57 --- [result-getter-1] org.apache.spark.internal.Logging        : Removed TaskSet 89.0, whose tasks have all completed, from pool 
2022-07-30 11:45:31.064  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 89 (count at Application.java:147) finished in 0.009 s
2022-07-30 11:45:31.064  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 46 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:45:31.064  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 89: Stage finished
2022-07-30 11:45:31.065  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 46 finished: count at Application.java:147, took 0.012426 s
2022-07-30 11:45:31.065  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177931000 ms.0 from job set of time 1659177931000 ms
2022-07-30 11:45:31.066  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 0.065 s for time 1659177931000 ms (execution: 0.063 s)
2022-07-30 11:45:31.066  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 454 from persistence list
2022-07-30 11:45:31.067  INFO   57 --- [-thread-pool-37] org.apache.spark.internal.Logging        : Removing RDD 454
2022-07-30 11:45:31.067  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 453 from persistence list
2022-07-30 11:45:31.068  INFO   57 --- [-thread-pool-38] org.apache.spark.internal.Logging        : Removing RDD 453
2022-07-30 11:45:31.068  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[453] at receiverStream at Application.java:122 of time 1659177931000 ms
2022-07-30 11:45:31.069  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177929000 ms
2022-07-30 11:45:31.069  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177929000 ms
2022-07-30 11:45:32.001  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177932000 ms
2022-07-30 11:45:32.001  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177932000 ms.0 from job set of time 1659177932000 ms
2022-07-30 11:45:32.004  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:45:32.005  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:45:32.058  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:45:32.059  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 482 (count at Application.java:147) as input to shuffle 43
2022-07-30 11:45:32.059  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 47 (count at Application.java:147) with 1 output partitions
2022-07-30 11:45:32.059  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 91 (count at Application.java:147)
2022-07-30 11:45:32.059  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 90)
2022-07-30 11:45:32.060  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:45:32.060  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 91 (MapPartitionsRDD[485] at count at Application.java:147), which has no missing parents
2022-07-30 11:45:32.061  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_47 stored as values in memory (estimated size 11.0 KiB, free 897.0 MiB)
2022-07-30 11:45:32.063  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_47_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.0 MiB)
2022-07-30 11:45:32.064  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_47_piece0 in memory on host.docker.internal:58598 (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:45:32.064  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 47 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:45:32.064  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 91 (MapPartitionsRDD[485] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:45:32.064  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 91.0 with 1 tasks resource profile 0
2022-07-30 11:45:32.065  INFO   57 --- [er-event-loop-1] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 91.0 (TID 47) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:45:32.065  INFO   57 --- [e 91.0 (TID 47)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 91.0 (TID 47)
2022-07-30 11:45:32.067  INFO   57 --- [e 91.0 (TID 47)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:45:32.067  INFO   57 --- [e 91.0 (TID 47)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-30 11:45:32.068  INFO   57 --- [e 91.0 (TID 47)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 91.0 (TID 47). 2555 bytes result sent to driver
2022-07-30 11:45:32.069  INFO   57 --- [result-getter-2] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 91.0 (TID 47) in 4 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:45:32.069  INFO   57 --- [result-getter-2] org.apache.spark.internal.Logging        : Removed TaskSet 91.0, whose tasks have all completed, from pool 
2022-07-30 11:45:32.069  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 91 (count at Application.java:147) finished in 0.009 s
2022-07-30 11:45:32.070  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 47 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:45:32.070  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 91: Stage finished
2022-07-30 11:45:32.070  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 47 finished: count at Application.java:147, took 0.011760 s
2022-07-30 11:45:32.088  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177932000 ms.0 from job set of time 1659177932000 ms
2022-07-30 11:45:32.089  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 0.088 s for time 1659177932000 ms (execution: 0.087 s)
2022-07-30 11:45:32.089  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 465 from persistence list
2022-07-30 11:45:32.090  INFO   57 --- [-thread-pool-43] org.apache.spark.internal.Logging        : Removing RDD 465
2022-07-30 11:45:32.090  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 464 from persistence list
2022-07-30 11:45:32.091  INFO   57 --- [-thread-pool-47] org.apache.spark.internal.Logging        : Removing RDD 464
2022-07-30 11:45:32.091  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[464] at receiverStream at Application.java:122 of time 1659177932000 ms
2022-07-30 11:45:32.091  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177930000 ms
2022-07-30 11:45:32.091  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177930000 ms
2022-07-30 11:45:33.005  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177933000 ms
2022-07-30 11:45:33.006  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177933000 ms.0 from job set of time 1659177933000 ms
2022-07-30 11:45:33.011  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:45:33.011  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:45:33.061  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:45:33.061  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 493 (count at Application.java:147) as input to shuffle 44
2022-07-30 11:45:33.062  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 48 (count at Application.java:147) with 1 output partitions
2022-07-30 11:45:33.062  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 93 (count at Application.java:147)
2022-07-30 11:45:33.062  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 92)
2022-07-30 11:45:33.062  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:45:33.062  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 93 (MapPartitionsRDD[496] at count at Application.java:147), which has no missing parents
2022-07-30 11:45:33.064  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_48 stored as values in memory (estimated size 11.0 KiB, free 897.0 MiB)
2022-07-30 11:45:33.065  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_48_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.0 MiB)
2022-07-30 11:45:33.066  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_48_piece0 in memory on host.docker.internal:58598 (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:45:33.066  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 48 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:45:33.067  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 93 (MapPartitionsRDD[496] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:45:33.067  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 93.0 with 1 tasks resource profile 0
2022-07-30 11:45:33.068  INFO   57 --- [er-event-loop-0] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 93.0 (TID 48) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:45:33.068  INFO   57 --- [e 93.0 (TID 48)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 93.0 (TID 48)
2022-07-30 11:45:33.070  INFO   57 --- [e 93.0 (TID 48)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:45:33.071  INFO   57 --- [e 93.0 (TID 48)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-30 11:45:33.071  INFO   57 --- [e 93.0 (TID 48)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 93.0 (TID 48). 2555 bytes result sent to driver
2022-07-30 11:45:33.072  INFO   57 --- [result-getter-3] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 93.0 (TID 48) in 4 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:45:33.072  INFO   57 --- [result-getter-3] org.apache.spark.internal.Logging        : Removed TaskSet 93.0, whose tasks have all completed, from pool 
2022-07-30 11:45:33.073  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 93 (count at Application.java:147) finished in 0.009 s
2022-07-30 11:45:33.073  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 48 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:45:33.073  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 93: Stage finished
2022-07-30 11:45:33.073  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 48 finished: count at Application.java:147, took 0.012295 s
2022-07-30 11:45:33.074  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177933000 ms.0 from job set of time 1659177933000 ms
2022-07-30 11:45:33.074  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 0.074 s for time 1659177933000 ms (execution: 0.068 s)
2022-07-30 11:45:33.074  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 476 from persistence list
2022-07-30 11:45:33.075  INFO   57 --- [-thread-pool-53] org.apache.spark.internal.Logging        : Removing RDD 476
2022-07-30 11:45:33.075  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 475 from persistence list
2022-07-30 11:45:33.076  INFO   57 --- [-thread-pool-51] org.apache.spark.internal.Logging        : Removing RDD 475
2022-07-30 11:45:33.076  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[475] at receiverStream at Application.java:122 of time 1659177933000 ms
2022-07-30 11:45:33.076  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177931000 ms
2022-07-30 11:45:33.076  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177931000 ms
2022-07-30 11:45:34.004  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177934000 ms
2022-07-30 11:45:34.004  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177934000 ms.0 from job set of time 1659177934000 ms
2022-07-30 11:45:34.010  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:45:34.011  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:45:34.076  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:45:34.077  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 504 (count at Application.java:147) as input to shuffle 45
2022-07-30 11:45:34.078  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 49 (count at Application.java:147) with 1 output partitions
2022-07-30 11:45:34.078  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 95 (count at Application.java:147)
2022-07-30 11:45:34.078  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 94)
2022-07-30 11:45:34.078  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:45:34.078  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 95 (MapPartitionsRDD[507] at count at Application.java:147), which has no missing parents
2022-07-30 11:45:34.080  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_49 stored as values in memory (estimated size 11.0 KiB, free 897.0 MiB)
2022-07-30 11:45:34.082  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_49_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.0 MiB)
2022-07-30 11:45:34.083  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_49_piece0 in memory on host.docker.internal:58598 (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:45:34.083  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 49 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:45:34.084  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 95 (MapPartitionsRDD[507] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:45:34.084  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 95.0 with 1 tasks resource profile 0
2022-07-30 11:45:34.085  INFO   57 --- [er-event-loop-3] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 95.0 (TID 49) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:45:34.087  INFO   57 --- [e 95.0 (TID 49)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 95.0 (TID 49)
2022-07-30 11:45:34.090  INFO   57 --- [e 95.0 (TID 49)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:45:34.090  INFO   57 --- [e 95.0 (TID 49)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-30 11:45:34.091  INFO   57 --- [e 95.0 (TID 49)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 95.0 (TID 49). 2555 bytes result sent to driver
2022-07-30 11:45:34.091  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 95.0 (TID 49) in 6 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:45:34.092  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Removed TaskSet 95.0, whose tasks have all completed, from pool 
2022-07-30 11:45:34.092  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 95 (count at Application.java:147) finished in 0.013 s
2022-07-30 11:45:34.093  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 49 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:45:34.093  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 95: Stage finished
2022-07-30 11:45:34.094  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 49 finished: count at Application.java:147, took 0.016666 s
2022-07-30 11:45:34.094  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177934000 ms.0 from job set of time 1659177934000 ms
2022-07-30 11:45:34.095  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 0.094 s for time 1659177934000 ms (execution: 0.090 s)
2022-07-30 11:45:34.096  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 487 from persistence list
2022-07-30 11:45:34.100  INFO   57 --- [-thread-pool-56] org.apache.spark.internal.Logging        : Removing RDD 487
2022-07-30 11:45:34.100  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 486 from persistence list
2022-07-30 11:45:34.101  INFO   57 --- [-thread-pool-58] org.apache.spark.internal.Logging        : Removing RDD 486
2022-07-30 11:45:34.101  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[486] at receiverStream at Application.java:122 of time 1659177934000 ms
2022-07-30 11:45:34.101  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177932000 ms
2022-07-30 11:45:34.102  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177932000 ms
2022-07-30 11:45:35.004  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177935000 ms
2022-07-30 11:45:35.005  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177935000 ms.0 from job set of time 1659177935000 ms
2022-07-30 11:45:35.010  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:45:35.010  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:45:35.081  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:45:35.082  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 515 (count at Application.java:147) as input to shuffle 46
2022-07-30 11:45:35.082  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 50 (count at Application.java:147) with 1 output partitions
2022-07-30 11:45:35.083  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 97 (count at Application.java:147)
2022-07-30 11:45:35.083  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 96)
2022-07-30 11:45:35.083  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:45:35.083  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 97 (MapPartitionsRDD[518] at count at Application.java:147), which has no missing parents
2022-07-30 11:45:35.085  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_50 stored as values in memory (estimated size 11.0 KiB, free 896.9 MiB)
2022-07-30 11:45:35.089  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_50_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 896.9 MiB)
2022-07-30 11:45:35.090  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_50_piece0 in memory on host.docker.internal:58598 (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:45:35.090  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 50 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:45:35.091  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 97 (MapPartitionsRDD[518] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:45:35.091  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 97.0 with 1 tasks resource profile 0
2022-07-30 11:45:35.092  INFO   57 --- [er-event-loop-2] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 97.0 (TID 50) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:45:35.093  INFO   57 --- [e 97.0 (TID 50)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 97.0 (TID 50)
2022-07-30 11:45:35.095  INFO   57 --- [e 97.0 (TID 50)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:45:35.096  INFO   57 --- [e 97.0 (TID 50)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-30 11:45:35.097  INFO   57 --- [e 97.0 (TID 50)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 97.0 (TID 50). 2555 bytes result sent to driver
2022-07-30 11:45:35.097  INFO   57 --- [result-getter-1] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 97.0 (TID 50) in 5 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:45:35.097  INFO   57 --- [result-getter-1] org.apache.spark.internal.Logging        : Removed TaskSet 97.0, whose tasks have all completed, from pool 
2022-07-30 11:45:35.098  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 97 (count at Application.java:147) finished in 0.014 s
2022-07-30 11:45:35.098  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 50 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:45:35.098  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 97: Stage finished
2022-07-30 11:45:35.099  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 50 finished: count at Application.java:147, took 0.017120 s
2022-07-30 11:45:35.100  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177935000 ms.0 from job set of time 1659177935000 ms
2022-07-30 11:45:35.100  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 0.100 s for time 1659177935000 ms (execution: 0.095 s)
2022-07-30 11:45:35.101  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 498 from persistence list
2022-07-30 11:45:35.101  INFO   57 --- [-thread-pool-60] org.apache.spark.internal.Logging        : Removing RDD 498
2022-07-30 11:45:35.101  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 497 from persistence list
2022-07-30 11:45:35.102  INFO   57 --- [-thread-pool-64] org.apache.spark.internal.Logging        : Removing RDD 497
2022-07-30 11:45:35.102  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[497] at receiverStream at Application.java:122 of time 1659177935000 ms
2022-07-30 11:45:35.103  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177933000 ms
2022-07-30 11:45:35.104  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177933000 ms
2022-07-30 11:45:36.001  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177936000 ms
2022-07-30 11:45:36.003  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177936000 ms.0 from job set of time 1659177936000 ms
2022-07-30 11:45:36.004  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:45:36.004  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:45:36.078  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:45:36.078  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 526 (count at Application.java:147) as input to shuffle 47
2022-07-30 11:45:36.079  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 51 (count at Application.java:147) with 1 output partitions
2022-07-30 11:45:36.079  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 99 (count at Application.java:147)
2022-07-30 11:45:36.079  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 98)
2022-07-30 11:45:36.079  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:45:36.080  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 99 (MapPartitionsRDD[529] at count at Application.java:147), which has no missing parents
2022-07-30 11:45:36.081  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_51 stored as values in memory (estimated size 11.0 KiB, free 896.9 MiB)
2022-07-30 11:45:36.083  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_51_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 896.9 MiB)
2022-07-30 11:45:36.084  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_51_piece0 in memory on host.docker.internal:58598 (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:45:36.086  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 51 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:45:36.087  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 99 (MapPartitionsRDD[529] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:45:36.087  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 99.0 with 1 tasks resource profile 0
2022-07-30 11:45:36.088  INFO   57 --- [er-event-loop-1] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 99.0 (TID 51) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:45:36.089  INFO   57 --- [e 99.0 (TID 51)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 99.0 (TID 51)
2022-07-30 11:45:36.092  INFO   57 --- [e 99.0 (TID 51)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:45:36.092  INFO   57 --- [e 99.0 (TID 51)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-30 11:45:36.093  INFO   57 --- [e 99.0 (TID 51)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 99.0 (TID 51). 2598 bytes result sent to driver
2022-07-30 11:45:36.094  INFO   57 --- [result-getter-2] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 99.0 (TID 51) in 6 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:45:36.095  INFO   57 --- [result-getter-2] org.apache.spark.internal.Logging        : Removed TaskSet 99.0, whose tasks have all completed, from pool 
2022-07-30 11:45:36.095  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 99 (count at Application.java:147) finished in 0.015 s
2022-07-30 11:45:36.096  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 51 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:45:36.096  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 99: Stage finished
2022-07-30 11:45:36.096  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 51 finished: count at Application.java:147, took 0.018244 s
2022-07-30 11:45:36.097  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177936000 ms.0 from job set of time 1659177936000 ms
2022-07-30 11:45:36.098  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 0.097 s for time 1659177936000 ms (execution: 0.094 s)
2022-07-30 11:45:36.098  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 509 from persistence list
2022-07-30 11:45:36.099  INFO   57 --- [-thread-pool-71] org.apache.spark.internal.Logging        : Removing RDD 509
2022-07-30 11:45:36.100  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 508 from persistence list
2022-07-30 11:45:36.100  INFO   57 --- [-thread-pool-69] org.apache.spark.internal.Logging        : Removing RDD 508
2022-07-30 11:45:36.100  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[508] at receiverStream at Application.java:122 of time 1659177936000 ms
2022-07-30 11:45:36.101  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177934000 ms
2022-07-30 11:45:36.101  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177934000 ms
2022-07-30 11:45:37.002  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177937000 ms
2022-07-30 11:45:37.002  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177937000 ms.0 from job set of time 1659177937000 ms
2022-07-30 11:45:37.004  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:45:37.004  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:45:37.050  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:45:37.051  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 537 (count at Application.java:147) as input to shuffle 48
2022-07-30 11:45:37.051  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 52 (count at Application.java:147) with 1 output partitions
2022-07-30 11:45:37.051  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 101 (count at Application.java:147)
2022-07-30 11:45:37.051  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 100)
2022-07-30 11:45:37.052  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:45:37.052  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 101 (MapPartitionsRDD[540] at count at Application.java:147), which has no missing parents
2022-07-30 11:45:37.054  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_52 stored as values in memory (estimated size 11.0 KiB, free 896.9 MiB)
2022-07-30 11:45:37.056  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_52_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 896.9 MiB)
2022-07-30 11:45:37.057  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_52_piece0 in memory on host.docker.internal:58598 (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:45:37.057  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 52 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:45:37.057  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 101 (MapPartitionsRDD[540] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:45:37.057  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 101.0 with 1 tasks resource profile 0
2022-07-30 11:45:37.058  INFO   57 --- [er-event-loop-0] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 101.0 (TID 52) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:45:37.059  INFO   57 --- [ 101.0 (TID 52)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 101.0 (TID 52)
2022-07-30 11:45:37.061  INFO   57 --- [ 101.0 (TID 52)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:45:37.061  INFO   57 --- [ 101.0 (TID 52)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-30 11:45:37.062  INFO   57 --- [ 101.0 (TID 52)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 101.0 (TID 52). 2598 bytes result sent to driver
2022-07-30 11:45:37.062  INFO   57 --- [result-getter-3] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 101.0 (TID 52) in 4 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:45:37.062  INFO   57 --- [result-getter-3] org.apache.spark.internal.Logging        : Removed TaskSet 101.0, whose tasks have all completed, from pool 
2022-07-30 11:45:37.063  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 101 (count at Application.java:147) finished in 0.009 s
2022-07-30 11:45:37.063  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 52 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:45:37.063  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 101: Stage finished
2022-07-30 11:45:37.064  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 52 finished: count at Application.java:147, took 0.013466 s
2022-07-30 11:45:37.065  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177937000 ms.0 from job set of time 1659177937000 ms
2022-07-30 11:45:37.065  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 0.065 s for time 1659177937000 ms (execution: 0.063 s)
2022-07-30 11:45:37.066  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 520 from persistence list
2022-07-30 11:45:37.066  INFO   57 --- [-thread-pool-74] org.apache.spark.internal.Logging        : Removing RDD 520
2022-07-30 11:45:37.067  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 519 from persistence list
2022-07-30 11:45:37.067  INFO   57 --- [-thread-pool-77] org.apache.spark.internal.Logging        : Removing RDD 519
2022-07-30 11:45:37.067  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[519] at receiverStream at Application.java:122 of time 1659177937000 ms
2022-07-30 11:45:37.068  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177935000 ms
2022-07-30 11:45:37.068  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177935000 ms
2022-07-30 11:45:38.002  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177938000 ms
2022-07-30 11:45:38.002  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177938000 ms.0 from job set of time 1659177938000 ms
2022-07-30 11:45:38.005  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:45:38.005  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:45:38.070  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:45:38.071  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 548 (count at Application.java:147) as input to shuffle 49
2022-07-30 11:45:38.072  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 53 (count at Application.java:147) with 1 output partitions
2022-07-30 11:45:38.072  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 103 (count at Application.java:147)
2022-07-30 11:45:38.072  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 102)
2022-07-30 11:45:38.072  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:45:38.072  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 103 (MapPartitionsRDD[551] at count at Application.java:147), which has no missing parents
2022-07-30 11:45:38.075  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_53 stored as values in memory (estimated size 11.0 KiB, free 896.9 MiB)
2022-07-30 11:45:38.076  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_53_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 896.9 MiB)
2022-07-30 11:45:38.077  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_53_piece0 in memory on host.docker.internal:58598 (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:45:38.078  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 53 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:45:38.078  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 103 (MapPartitionsRDD[551] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:45:38.078  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 103.0 with 1 tasks resource profile 0
2022-07-30 11:45:38.079  INFO   57 --- [er-event-loop-1] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 103.0 (TID 53) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:45:38.080  INFO   57 --- [ 103.0 (TID 53)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 103.0 (TID 53)
2022-07-30 11:45:38.083  INFO   57 --- [ 103.0 (TID 53)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:45:38.083  INFO   57 --- [ 103.0 (TID 53)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-30 11:45:38.084  INFO   57 --- [ 103.0 (TID 53)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 103.0 (TID 53). 2555 bytes result sent to driver
2022-07-30 11:45:38.087  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 103.0 (TID 53) in 8 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:45:38.087  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Removed TaskSet 103.0, whose tasks have all completed, from pool 
2022-07-30 11:45:38.088  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 103 (count at Application.java:147) finished in 0.014 s
2022-07-30 11:45:38.088  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 53 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:45:38.088  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 103: Stage finished
2022-07-30 11:45:38.089  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 53 finished: count at Application.java:147, took 0.017977 s
2022-07-30 11:45:38.090  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177938000 ms.0 from job set of time 1659177938000 ms
2022-07-30 11:45:38.090  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 0.090 s for time 1659177938000 ms (execution: 0.088 s)
2022-07-30 11:45:38.090  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 531 from persistence list
2022-07-30 11:45:38.091  INFO   57 --- [-thread-pool-79] org.apache.spark.internal.Logging        : Removing RDD 531
2022-07-30 11:45:38.091  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 530 from persistence list
2022-07-30 11:45:38.092  INFO   57 --- [-thread-pool-83] org.apache.spark.internal.Logging        : Removing RDD 530
2022-07-30 11:45:38.092  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[530] at receiverStream at Application.java:122 of time 1659177938000 ms
2022-07-30 11:45:38.092  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177936000 ms
2022-07-30 11:45:38.093  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177936000 ms
2022-07-30 11:45:39.002  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177939000 ms
2022-07-30 11:45:39.002  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177939000 ms.0 from job set of time 1659177939000 ms
2022-07-30 11:45:39.004  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:45:39.004  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:45:39.054  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:45:39.055  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 559 (count at Application.java:147) as input to shuffle 50
2022-07-30 11:45:39.055  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 54 (count at Application.java:147) with 1 output partitions
2022-07-30 11:45:39.056  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 105 (count at Application.java:147)
2022-07-30 11:45:39.056  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 104)
2022-07-30 11:45:39.056  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:45:39.056  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 105 (MapPartitionsRDD[562] at count at Application.java:147), which has no missing parents
2022-07-30 11:45:39.058  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_54 stored as values in memory (estimated size 11.0 KiB, free 896.9 MiB)
2022-07-30 11:45:39.059  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_54_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 896.9 MiB)
2022-07-30 11:45:39.060  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_54_piece0 in memory on host.docker.internal:58598 (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:45:39.061  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 54 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:45:39.061  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 105 (MapPartitionsRDD[562] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:45:39.061  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 105.0 with 1 tasks resource profile 0
2022-07-30 11:45:39.062  INFO   57 --- [er-event-loop-0] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 105.0 (TID 54) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:45:39.062  INFO   57 --- [ 105.0 (TID 54)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 105.0 (TID 54)
2022-07-30 11:45:39.064  INFO   57 --- [ 105.0 (TID 54)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:45:39.065  INFO   57 --- [ 105.0 (TID 54)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-30 11:45:39.066  INFO   57 --- [ 105.0 (TID 54)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 105.0 (TID 54). 2555 bytes result sent to driver
2022-07-30 11:45:39.066  INFO   57 --- [result-getter-1] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 105.0 (TID 54) in 4 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:45:39.066  INFO   57 --- [result-getter-1] org.apache.spark.internal.Logging        : Removed TaskSet 105.0, whose tasks have all completed, from pool 
2022-07-30 11:45:39.067  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 105 (count at Application.java:147) finished in 0.010 s
2022-07-30 11:45:39.067  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 54 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:45:39.067  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 105: Stage finished
2022-07-30 11:45:39.067  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 54 finished: count at Application.java:147, took 0.012802 s
2022-07-30 11:45:39.068  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177939000 ms.0 from job set of time 1659177939000 ms
2022-07-30 11:45:39.069  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 0.068 s for time 1659177939000 ms (execution: 0.066 s)
2022-07-30 11:45:39.069  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 542 from persistence list
2022-07-30 11:45:39.071  INFO   57 --- [-thread-pool-86] org.apache.spark.internal.Logging        : Removing RDD 542
2022-07-30 11:45:39.071  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 541 from persistence list
2022-07-30 11:45:39.072  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[541] at receiverStream at Application.java:122 of time 1659177939000 ms
2022-07-30 11:45:39.072  INFO   57 --- [-thread-pool-87] org.apache.spark.internal.Logging        : Removing RDD 541
2022-07-30 11:45:39.073  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177937000 ms
2022-07-30 11:45:39.074  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177937000 ms
2022-07-30 11:45:40.002  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177940000 ms
2022-07-30 11:45:40.003  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177940000 ms.0 from job set of time 1659177940000 ms
2022-07-30 11:45:40.005  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:45:40.005  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:45:40.066  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:45:40.066  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 570 (count at Application.java:147) as input to shuffle 51
2022-07-30 11:45:40.067  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 55 (count at Application.java:147) with 1 output partitions
2022-07-30 11:45:40.067  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 107 (count at Application.java:147)
2022-07-30 11:45:40.067  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 106)
2022-07-30 11:45:40.067  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:45:40.067  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 107 (MapPartitionsRDD[573] at count at Application.java:147), which has no missing parents
2022-07-30 11:45:40.069  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_55 stored as values in memory (estimated size 11.0 KiB, free 896.9 MiB)
2022-07-30 11:45:40.070  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_55_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 896.9 MiB)
2022-07-30 11:45:40.071  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_55_piece0 in memory on host.docker.internal:58598 (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:45:40.072  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 55 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:45:40.072  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 107 (MapPartitionsRDD[573] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:45:40.072  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 107.0 with 1 tasks resource profile 0
2022-07-30 11:45:40.073  INFO   57 --- [er-event-loop-3] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 107.0 (TID 55) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:45:40.074  INFO   57 --- [ 107.0 (TID 55)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 107.0 (TID 55)
2022-07-30 11:45:40.077  INFO   57 --- [ 107.0 (TID 55)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:45:40.077  INFO   57 --- [ 107.0 (TID 55)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-30 11:45:40.078  INFO   57 --- [ 107.0 (TID 55)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 107.0 (TID 55). 2598 bytes result sent to driver
2022-07-30 11:45:40.079  INFO   57 --- [result-getter-2] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 107.0 (TID 55) in 6 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:45:40.079  INFO   57 --- [result-getter-2] org.apache.spark.internal.Logging        : Removed TaskSet 107.0, whose tasks have all completed, from pool 
2022-07-30 11:45:40.080  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 107 (count at Application.java:147) finished in 0.011 s
2022-07-30 11:45:40.080  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 55 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:45:40.080  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 107: Stage finished
2022-07-30 11:45:40.081  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 55 finished: count at Application.java:147, took 0.014579 s
2022-07-30 11:45:40.082  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177940000 ms.0 from job set of time 1659177940000 ms
2022-07-30 11:45:40.082  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 0.081 s for time 1659177940000 ms (execution: 0.078 s)
2022-07-30 11:45:40.082  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 553 from persistence list
2022-07-30 11:45:40.083  INFO   57 --- [-thread-pool-96] org.apache.spark.internal.Logging        : Removing RDD 553
2022-07-30 11:45:40.083  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 552 from persistence list
2022-07-30 11:45:40.084  INFO   57 --- [-thread-pool-92] org.apache.spark.internal.Logging        : Removing RDD 552
2022-07-30 11:45:40.084  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[552] at receiverStream at Application.java:122 of time 1659177940000 ms
2022-07-30 11:45:40.084  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177938000 ms
2022-07-30 11:45:40.084  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177938000 ms
2022-07-30 11:45:41.003  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177941000 ms
2022-07-30 11:45:41.003  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177941000 ms.0 from job set of time 1659177941000 ms
2022-07-30 11:45:41.006  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:45:41.006  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:45:41.078  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:45:41.079  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 581 (count at Application.java:147) as input to shuffle 52
2022-07-30 11:45:41.080  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 56 (count at Application.java:147) with 1 output partitions
2022-07-30 11:45:41.080  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 109 (count at Application.java:147)
2022-07-30 11:45:41.080  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 108)
2022-07-30 11:45:41.080  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:45:41.080  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 109 (MapPartitionsRDD[584] at count at Application.java:147), which has no missing parents
2022-07-30 11:45:41.083  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_56 stored as values in memory (estimated size 11.0 KiB, free 896.8 MiB)
2022-07-30 11:45:41.086  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_56_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 896.8 MiB)
2022-07-30 11:45:41.088  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_56_piece0 in memory on host.docker.internal:58598 (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:45:41.089  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 56 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:45:41.089  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 109 (MapPartitionsRDD[584] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:45:41.089  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 109.0 with 1 tasks resource profile 0
2022-07-30 11:45:41.090  INFO   57 --- [er-event-loop-2] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 109.0 (TID 56) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:45:41.091  INFO   57 --- [ 109.0 (TID 56)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 109.0 (TID 56)
2022-07-30 11:45:41.095  INFO   57 --- [ 109.0 (TID 56)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:45:41.095  INFO   57 --- [ 109.0 (TID 56)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-30 11:45:41.096  INFO   57 --- [ 109.0 (TID 56)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 109.0 (TID 56). 2555 bytes result sent to driver
2022-07-30 11:45:41.099  INFO   57 --- [result-getter-3] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 109.0 (TID 56) in 9 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:45:41.099  INFO   57 --- [result-getter-3] org.apache.spark.internal.Logging        : Removed TaskSet 109.0, whose tasks have all completed, from pool 
2022-07-30 11:45:41.101  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 109 (count at Application.java:147) finished in 0.020 s
2022-07-30 11:45:41.102  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 56 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:45:41.102  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 109: Stage finished
2022-07-30 11:45:41.103  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 56 finished: count at Application.java:147, took 0.024335 s
2022-07-30 11:45:41.104  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177941000 ms.0 from job set of time 1659177941000 ms
2022-07-30 11:45:41.105  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 0.104 s for time 1659177941000 ms (execution: 0.101 s)
2022-07-30 11:45:41.106  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 564 from persistence list
2022-07-30 11:45:41.107  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 563 from persistence list
2022-07-30 11:45:41.107  INFO   57 --- [c-thread-pool-0] org.apache.spark.internal.Logging        : Removing RDD 564
2022-07-30 11:45:41.108  INFO   57 --- [-thread-pool-97] org.apache.spark.internal.Logging        : Removing RDD 563
2022-07-30 11:45:41.108  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[563] at receiverStream at Application.java:122 of time 1659177941000 ms
2022-07-30 11:45:41.109  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177939000 ms
2022-07-30 11:45:41.109  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177939000 ms
2022-07-30 11:45:42.001  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177942000 ms
2022-07-30 11:45:42.002  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177942000 ms.0 from job set of time 1659177942000 ms
2022-07-30 11:45:42.005  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:45:42.005  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:45:42.059  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:45:42.060  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 592 (count at Application.java:147) as input to shuffle 53
2022-07-30 11:45:42.061  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 57 (count at Application.java:147) with 1 output partitions
2022-07-30 11:45:42.061  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 111 (count at Application.java:147)
2022-07-30 11:45:42.061  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 110)
2022-07-30 11:45:42.061  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:45:42.061  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 111 (MapPartitionsRDD[595] at count at Application.java:147), which has no missing parents
2022-07-30 11:45:42.063  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_57 stored as values in memory (estimated size 11.0 KiB, free 896.8 MiB)
2022-07-30 11:45:42.065  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_57_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 896.8 MiB)
2022-07-30 11:45:42.066  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_57_piece0 in memory on host.docker.internal:58598 (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:45:42.067  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 57 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:45:42.067  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 111 (MapPartitionsRDD[595] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:45:42.067  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 111.0 with 1 tasks resource profile 0
2022-07-30 11:45:42.069  INFO   57 --- [er-event-loop-1] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 111.0 (TID 57) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:45:42.069  INFO   57 --- [ 111.0 (TID 57)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 111.0 (TID 57)
2022-07-30 11:45:42.072  INFO   57 --- [ 111.0 (TID 57)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:45:42.073  INFO   57 --- [ 111.0 (TID 57)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-30 11:45:42.074  INFO   57 --- [ 111.0 (TID 57)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 111.0 (TID 57). 2555 bytes result sent to driver
2022-07-30 11:45:42.075  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 111.0 (TID 57) in 6 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:45:42.075  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Removed TaskSet 111.0, whose tasks have all completed, from pool 
2022-07-30 11:45:42.075  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 111 (count at Application.java:147) finished in 0.013 s
2022-07-30 11:45:42.076  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 57 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:45:42.076  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 111: Stage finished
2022-07-30 11:45:42.076  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 57 finished: count at Application.java:147, took 0.016759 s
2022-07-30 11:45:42.077  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177942000 ms.0 from job set of time 1659177942000 ms
2022-07-30 11:45:42.078  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 0.077 s for time 1659177942000 ms (execution: 0.075 s)
2022-07-30 11:45:42.078  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 575 from persistence list
2022-07-30 11:45:42.078  INFO   57 --- [-thread-pool-99] org.apache.spark.internal.Logging        : Removing RDD 575
2022-07-30 11:45:42.079  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 574 from persistence list
2022-07-30 11:45:42.079  INFO   57 --- [c-thread-pool-5] org.apache.spark.internal.Logging        : Removing RDD 574
2022-07-30 11:45:42.079  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[574] at receiverStream at Application.java:122 of time 1659177942000 ms
2022-07-30 11:45:42.080  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177940000 ms
2022-07-30 11:45:42.080  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177940000 ms
2022-07-30 11:45:43.001  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177943000 ms
2022-07-30 11:45:43.001  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177943000 ms.0 from job set of time 1659177943000 ms
2022-07-30 11:45:43.003  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:45:43.003  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:45:43.049  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:45:43.050  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 603 (count at Application.java:147) as input to shuffle 54
2022-07-30 11:45:43.051  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 58 (count at Application.java:147) with 1 output partitions
2022-07-30 11:45:43.053  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 113 (count at Application.java:147)
2022-07-30 11:45:43.053  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 112)
2022-07-30 11:45:43.053  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:45:43.054  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 113 (MapPartitionsRDD[606] at count at Application.java:147), which has no missing parents
2022-07-30 11:45:43.056  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_58 stored as values in memory (estimated size 11.0 KiB, free 896.8 MiB)
2022-07-30 11:45:43.058  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_58_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 896.8 MiB)
2022-07-30 11:45:43.059  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_58_piece0 in memory on host.docker.internal:58598 (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:45:43.059  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 58 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:45:43.060  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 113 (MapPartitionsRDD[606] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:45:43.060  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 113.0 with 1 tasks resource profile 0
2022-07-30 11:45:43.061  INFO   57 --- [er-event-loop-0] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 113.0 (TID 58) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:45:43.062  INFO   57 --- [ 113.0 (TID 58)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 113.0 (TID 58)
2022-07-30 11:45:43.064  INFO   57 --- [ 113.0 (TID 58)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:45:43.065  INFO   57 --- [ 113.0 (TID 58)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-30 11:45:43.065  INFO   57 --- [ 113.0 (TID 58)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 113.0 (TID 58). 2555 bytes result sent to driver
2022-07-30 11:45:43.066  INFO   57 --- [result-getter-1] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 113.0 (TID 58) in 5 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:45:43.066  INFO   57 --- [result-getter-1] org.apache.spark.internal.Logging        : Removed TaskSet 113.0, whose tasks have all completed, from pool 
2022-07-30 11:45:43.067  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 113 (count at Application.java:147) finished in 0.012 s
2022-07-30 11:45:43.067  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 58 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:45:43.067  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 113: Stage finished
2022-07-30 11:45:43.068  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 58 finished: count at Application.java:147, took 0.018704 s
2022-07-30 11:45:43.069  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177943000 ms.0 from job set of time 1659177943000 ms
2022-07-30 11:45:43.070  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 0.069 s for time 1659177943000 ms (execution: 0.068 s)
2022-07-30 11:45:43.071  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 586 from persistence list
2022-07-30 11:45:43.071  INFO   57 --- [-thread-pool-11] org.apache.spark.internal.Logging        : Removing RDD 586
2022-07-30 11:45:43.072  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 585 from persistence list
2022-07-30 11:45:43.072  INFO   57 --- [-thread-pool-12] org.apache.spark.internal.Logging        : Removing RDD 585
2022-07-30 11:45:43.072  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[585] at receiverStream at Application.java:122 of time 1659177943000 ms
2022-07-30 11:45:43.073  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177941000 ms
2022-07-30 11:45:43.073  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177941000 ms
2022-07-30 11:45:44.003  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177944000 ms
2022-07-30 11:45:44.003  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177944000 ms.0 from job set of time 1659177944000 ms
2022-07-30 11:45:44.004  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:45:44.004  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:45:44.051  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:45:44.051  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 614 (count at Application.java:147) as input to shuffle 55
2022-07-30 11:45:44.051  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 59 (count at Application.java:147) with 1 output partitions
2022-07-30 11:45:44.051  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 115 (count at Application.java:147)
2022-07-30 11:45:44.051  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 114)
2022-07-30 11:45:44.051  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:45:44.052  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 115 (MapPartitionsRDD[617] at count at Application.java:147), which has no missing parents
2022-07-30 11:45:44.054  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_59 stored as values in memory (estimated size 11.0 KiB, free 896.8 MiB)
2022-07-30 11:45:44.055  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_59_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 896.8 MiB)
2022-07-30 11:45:44.056  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_59_piece0 in memory on host.docker.internal:58598 (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:45:44.056  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 59 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:45:44.056  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 115 (MapPartitionsRDD[617] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:45:44.056  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 115.0 with 1 tasks resource profile 0
2022-07-30 11:45:44.056  INFO   57 --- [er-event-loop-3] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 115.0 (TID 59) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:45:44.058  INFO   57 --- [ 115.0 (TID 59)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 115.0 (TID 59)
2022-07-30 11:45:44.059  INFO   57 --- [ 115.0 (TID 59)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:45:44.059  INFO   57 --- [ 115.0 (TID 59)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-30 11:45:44.060  INFO   57 --- [ 115.0 (TID 59)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 115.0 (TID 59). 2598 bytes result sent to driver
2022-07-30 11:45:44.061  INFO   57 --- [result-getter-2] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 115.0 (TID 59) in 4 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:45:44.061  INFO   57 --- [result-getter-2] org.apache.spark.internal.Logging        : Removed TaskSet 115.0, whose tasks have all completed, from pool 
2022-07-30 11:45:44.061  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 115 (count at Application.java:147) finished in 0.009 s
2022-07-30 11:45:44.062  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 59 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:45:44.062  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 115: Stage finished
2022-07-30 11:45:44.062  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 59 finished: count at Application.java:147, took 0.012051 s
2022-07-30 11:45:44.063  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177944000 ms.0 from job set of time 1659177944000 ms
2022-07-30 11:45:44.063  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 0.063 s for time 1659177944000 ms (execution: 0.060 s)
2022-07-30 11:45:44.065  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 597 from persistence list
2022-07-30 11:45:44.065  INFO   57 --- [-thread-pool-16] org.apache.spark.internal.Logging        : Removing RDD 597
2022-07-30 11:45:44.065  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 596 from persistence list
2022-07-30 11:45:44.065  INFO   57 --- [-thread-pool-18] org.apache.spark.internal.Logging        : Removing RDD 596
2022-07-30 11:45:44.065  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[596] at receiverStream at Application.java:122 of time 1659177944000 ms
2022-07-30 11:45:44.066  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177942000 ms
2022-07-30 11:45:44.066  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177942000 ms
2022-07-30 11:45:45.003  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177945000 ms
2022-07-30 11:45:45.003  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177945000 ms.0 from job set of time 1659177945000 ms
2022-07-30 11:45:45.005  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:45:45.005  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:45:45.071  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:45:45.072  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 625 (count at Application.java:147) as input to shuffle 56
2022-07-30 11:45:45.073  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 60 (count at Application.java:147) with 1 output partitions
2022-07-30 11:45:45.073  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 117 (count at Application.java:147)
2022-07-30 11:45:45.073  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 116)
2022-07-30 11:45:45.073  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:45:45.074  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 117 (MapPartitionsRDD[628] at count at Application.java:147), which has no missing parents
2022-07-30 11:45:45.075  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_60 stored as values in memory (estimated size 11.0 KiB, free 896.8 MiB)
2022-07-30 11:45:45.079  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_60_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 896.8 MiB)
2022-07-30 11:45:45.079  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_60_piece0 in memory on host.docker.internal:58598 (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:45:45.080  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 60 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:45:45.080  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 117 (MapPartitionsRDD[628] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:45:45.080  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 117.0 with 1 tasks resource profile 0
2022-07-30 11:45:45.081  INFO   57 --- [er-event-loop-2] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 117.0 (TID 60) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:45:45.082  INFO   57 --- [ 117.0 (TID 60)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 117.0 (TID 60)
2022-07-30 11:45:45.084  INFO   57 --- [ 117.0 (TID 60)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:45:45.085  INFO   57 --- [ 117.0 (TID 60)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-30 11:45:45.086  INFO   57 --- [ 117.0 (TID 60)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 117.0 (TID 60). 2555 bytes result sent to driver
2022-07-30 11:45:45.086  INFO   57 --- [result-getter-3] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 117.0 (TID 60) in 5 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:45:45.087  INFO   57 --- [result-getter-3] org.apache.spark.internal.Logging        : Removed TaskSet 117.0, whose tasks have all completed, from pool 
2022-07-30 11:45:45.087  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 117 (count at Application.java:147) finished in 0.013 s
2022-07-30 11:45:45.087  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 60 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:45:45.088  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 117: Stage finished
2022-07-30 11:45:45.088  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 60 finished: count at Application.java:147, took 0.015944 s
2022-07-30 11:45:45.089  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177945000 ms.0 from job set of time 1659177945000 ms
2022-07-30 11:45:45.089  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 0.089 s for time 1659177945000 ms (execution: 0.086 s)
2022-07-30 11:45:45.089  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 608 from persistence list
2022-07-30 11:45:45.090  INFO   57 --- [-thread-pool-20] org.apache.spark.internal.Logging        : Removing RDD 608
2022-07-30 11:45:45.090  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 607 from persistence list
2022-07-30 11:45:45.091  INFO   57 --- [-thread-pool-23] org.apache.spark.internal.Logging        : Removing RDD 607
2022-07-30 11:45:45.091  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[607] at receiverStream at Application.java:122 of time 1659177945000 ms
2022-07-30 11:45:45.092  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177943000 ms
2022-07-30 11:45:45.092  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177943000 ms
2022-07-30 11:45:46.002  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177946000 ms
2022-07-30 11:45:46.002  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177946000 ms.0 from job set of time 1659177946000 ms
2022-07-30 11:45:46.004  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:45:46.004  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:45:46.097  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:45:46.098  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 636 (count at Application.java:147) as input to shuffle 57
2022-07-30 11:45:46.098  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 61 (count at Application.java:147) with 1 output partitions
2022-07-30 11:45:46.098  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 119 (count at Application.java:147)
2022-07-30 11:45:46.098  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 118)
2022-07-30 11:45:46.099  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:45:46.099  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 119 (MapPartitionsRDD[639] at count at Application.java:147), which has no missing parents
2022-07-30 11:45:46.100  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_61 stored as values in memory (estimated size 11.0 KiB, free 896.8 MiB)
2022-07-30 11:45:46.104  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_61_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 896.8 MiB)
2022-07-30 11:45:46.105  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_61_piece0 in memory on host.docker.internal:58598 (size: 5.4 KiB, free: 897.3 MiB)
2022-07-30 11:45:46.105  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 61 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:45:46.105  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 119 (MapPartitionsRDD[639] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:45:46.106  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 119.0 with 1 tasks resource profile 0
2022-07-30 11:45:46.106  INFO   57 --- [er-event-loop-2] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 119.0 (TID 61) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:45:46.108  INFO   57 --- [ 119.0 (TID 61)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 119.0 (TID 61)
2022-07-30 11:45:46.110  INFO   57 --- [ 119.0 (TID 61)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:45:46.110  INFO   57 --- [ 119.0 (TID 61)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-30 11:45:46.112  INFO   57 --- [ 119.0 (TID 61)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 119.0 (TID 61). 2555 bytes result sent to driver
2022-07-30 11:45:46.112  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 119.0 (TID 61) in 6 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:45:46.113  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Removed TaskSet 119.0, whose tasks have all completed, from pool 
2022-07-30 11:45:46.113  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 119 (count at Application.java:147) finished in 0.013 s
2022-07-30 11:45:46.113  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 61 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:45:46.114  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 119: Stage finished
2022-07-30 11:45:46.114  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 61 finished: count at Application.java:147, took 0.016179 s
2022-07-30 11:45:46.115  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177946000 ms.0 from job set of time 1659177946000 ms
2022-07-30 11:45:46.115  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 0.115 s for time 1659177946000 ms (execution: 0.113 s)
2022-07-30 11:45:46.116  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 619 from persistence list
2022-07-30 11:45:46.117  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 618 from persistence list
2022-07-30 11:45:46.118  INFO   57 --- [-thread-pool-25] org.apache.spark.internal.Logging        : Removing RDD 619
2022-07-30 11:45:46.119  INFO   57 --- [-thread-pool-32] org.apache.spark.internal.Logging        : Removing RDD 618
2022-07-30 11:45:46.120  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[618] at receiverStream at Application.java:122 of time 1659177946000 ms
2022-07-30 11:45:46.120  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177944000 ms
2022-07-30 11:45:46.120  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177944000 ms
2022-07-30 11:45:47.003  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177947000 ms
2022-07-30 11:45:47.003  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177947000 ms.0 from job set of time 1659177947000 ms
2022-07-30 11:45:47.007  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:45:47.007  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:45:47.108  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:45:47.109  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 647 (count at Application.java:147) as input to shuffle 58
2022-07-30 11:45:47.109  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 62 (count at Application.java:147) with 1 output partitions
2022-07-30 11:45:47.109  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 121 (count at Application.java:147)
2022-07-30 11:45:47.109  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 120)
2022-07-30 11:45:47.109  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:45:47.110  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 121 (MapPartitionsRDD[650] at count at Application.java:147), which has no missing parents
2022-07-30 11:45:47.111  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_62 stored as values in memory (estimated size 11.0 KiB, free 896.8 MiB)
2022-07-30 11:45:47.115  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_62_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 896.7 MiB)
2022-07-30 11:45:47.115  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_62_piece0 in memory on host.docker.internal:58598 (size: 5.4 KiB, free: 897.3 MiB)
2022-07-30 11:45:47.116  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 62 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:45:47.116  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 121 (MapPartitionsRDD[650] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:45:47.117  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 121.0 with 1 tasks resource profile 0
2022-07-30 11:45:47.117  INFO   57 --- [er-event-loop-1] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 121.0 (TID 62) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:45:47.119  INFO   57 --- [ 121.0 (TID 62)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 121.0 (TID 62)
2022-07-30 11:45:47.124  INFO   57 --- [ 121.0 (TID 62)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:45:47.124  INFO   57 --- [ 121.0 (TID 62)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-30 11:45:47.126  INFO   57 --- [ 121.0 (TID 62)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 121.0 (TID 62). 2598 bytes result sent to driver
2022-07-30 11:45:47.127  INFO   57 --- [result-getter-1] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 121.0 (TID 62) in 10 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:45:47.127  INFO   57 --- [result-getter-1] org.apache.spark.internal.Logging        : Removed TaskSet 121.0, whose tasks have all completed, from pool 
2022-07-30 11:45:47.127  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 121 (count at Application.java:147) finished in 0.017 s
2022-07-30 11:45:47.128  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 62 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:45:47.128  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 121: Stage finished
2022-07-30 11:45:47.128  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 62 finished: count at Application.java:147, took 0.019863 s
2022-07-30 11:45:47.129  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177947000 ms.0 from job set of time 1659177947000 ms
2022-07-30 11:45:47.129  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 0.129 s for time 1659177947000 ms (execution: 0.126 s)
2022-07-30 11:45:47.130  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 630 from persistence list
2022-07-30 11:45:47.130  INFO   57 --- [-thread-pool-35] org.apache.spark.internal.Logging        : Removing RDD 630
2022-07-30 11:45:47.130  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 629 from persistence list
2022-07-30 11:45:47.132  INFO   57 --- [-thread-pool-39] org.apache.spark.internal.Logging        : Removing RDD 629
2022-07-30 11:45:47.132  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[629] at receiverStream at Application.java:122 of time 1659177947000 ms
2022-07-30 11:45:47.132  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177945000 ms
2022-07-30 11:45:47.132  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177945000 ms
2022-07-30 11:45:48.003  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177948000 ms
2022-07-30 11:45:48.003  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177948000 ms.0 from job set of time 1659177948000 ms
2022-07-30 11:45:48.006  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:45:48.006  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:45:48.115  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_37_piece0 on host.docker.internal:58598 in memory (size: 5.4 KiB, free: 897.3 MiB)
2022-07-30 11:45:48.135  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_40_piece0 on host.docker.internal:58598 in memory (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:45:48.139  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_43_piece0 on host.docker.internal:58598 in memory (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:45:48.145  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_55_piece0 on host.docker.internal:58598 in memory (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:45:48.150  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_53_piece0 on host.docker.internal:58598 in memory (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:45:48.152  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_47_piece0 on host.docker.internal:58598 in memory (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:45:48.156  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_58_piece0 on host.docker.internal:58598 in memory (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:45:48.159  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_50_piece0 on host.docker.internal:58598 in memory (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:45:48.163  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_61_piece0 on host.docker.internal:58598 in memory (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:45:48.167  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_51_piece0 on host.docker.internal:58598 in memory (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:45:48.171  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_49_piece0 on host.docker.internal:58598 in memory (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:45:48.173  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_45_piece0 on host.docker.internal:58598 in memory (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:45:48.176  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_41_piece0 on host.docker.internal:58598 in memory (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:45:48.177  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:45:48.178  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_60_piece0 on host.docker.internal:58598 in memory (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:45:48.178  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 658 (count at Application.java:147) as input to shuffle 59
2022-07-30 11:45:48.179  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 63 (count at Application.java:147) with 1 output partitions
2022-07-30 11:45:48.179  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 123 (count at Application.java:147)
2022-07-30 11:45:48.179  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 122)
2022-07-30 11:45:48.180  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:45:48.180  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 123 (MapPartitionsRDD[661] at count at Application.java:147), which has no missing parents
2022-07-30 11:45:48.182  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_63 stored as values in memory (estimated size 11.0 KiB, free 897.0 MiB)
2022-07-30 11:45:48.184  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_63_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.0 MiB)
2022-07-30 11:45:48.185  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_63_piece0 in memory on host.docker.internal:58598 (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:45:48.186  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 63 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:45:48.187  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 123 (MapPartitionsRDD[661] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:45:48.187  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 123.0 with 1 tasks resource profile 0
2022-07-30 11:45:48.188  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_59_piece0 on host.docker.internal:58598 in memory (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:45:48.189  INFO   57 --- [er-event-loop-2] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 123.0 (TID 63) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:45:48.190  INFO   57 --- [ 123.0 (TID 63)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 123.0 (TID 63)
2022-07-30 11:45:48.191  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_56_piece0 on host.docker.internal:58598 in memory (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:45:48.194  INFO   57 --- [ 123.0 (TID 63)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:45:48.194  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_42_piece0 on host.docker.internal:58598 in memory (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:45:48.194  INFO   57 --- [ 123.0 (TID 63)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-30 11:45:48.195  INFO   57 --- [ 123.0 (TID 63)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 123.0 (TID 63). 2555 bytes result sent to driver
2022-07-30 11:45:48.197  INFO   57 --- [result-getter-2] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 123.0 (TID 63) in 9 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:45:48.198  INFO   57 --- [result-getter-2] org.apache.spark.internal.Logging        : Removed TaskSet 123.0, whose tasks have all completed, from pool 
2022-07-30 11:45:48.198  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_52_piece0 on host.docker.internal:58598 in memory (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:45:48.198  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 123 (count at Application.java:147) finished in 0.017 s
2022-07-30 11:45:48.199  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 63 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:45:48.200  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 123: Stage finished
2022-07-30 11:45:48.200  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 63 finished: count at Application.java:147, took 0.021929 s
2022-07-30 11:45:48.202  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177948000 ms.0 from job set of time 1659177948000 ms
2022-07-30 11:45:48.203  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 0.202 s for time 1659177948000 ms (execution: 0.199 s)
2022-07-30 11:45:48.203  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_54_piece0 on host.docker.internal:58598 in memory (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:45:48.204  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 641 from persistence list
2022-07-30 11:45:48.205  INFO   57 --- [-thread-pool-36] org.apache.spark.internal.Logging        : Removing RDD 641
2022-07-30 11:45:48.205  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 640 from persistence list
2022-07-30 11:45:48.207  INFO   57 --- [-thread-pool-44] org.apache.spark.internal.Logging        : Removing RDD 640
2022-07-30 11:45:48.207  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[640] at receiverStream at Application.java:122 of time 1659177948000 ms
2022-07-30 11:45:48.208  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177946000 ms
2022-07-30 11:45:48.208  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177946000 ms
2022-07-30 11:45:48.212  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_39_piece0 on host.docker.internal:58598 in memory (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:45:48.213  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_57_piece0 on host.docker.internal:58598 in memory (size: 5.4 KiB, free: 897.5 MiB)
2022-07-30 11:45:48.215  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_38_piece0 on host.docker.internal:58598 in memory (size: 5.4 KiB, free: 897.5 MiB)
2022-07-30 11:45:48.217  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_48_piece0 on host.docker.internal:58598 in memory (size: 5.4 KiB, free: 897.5 MiB)
2022-07-30 11:45:48.220  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_46_piece0 on host.docker.internal:58598 in memory (size: 5.4 KiB, free: 897.5 MiB)
2022-07-30 11:45:48.224  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_62_piece0 on host.docker.internal:58598 in memory (size: 5.4 KiB, free: 897.5 MiB)
2022-07-30 11:45:48.231  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_44_piece0 on host.docker.internal:58598 in memory (size: 5.4 KiB, free: 897.5 MiB)
2022-07-30 11:45:49.004  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177949000 ms
2022-07-30 11:45:49.004  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177949000 ms.0 from job set of time 1659177949000 ms
2022-07-30 11:45:49.009  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:45:49.009  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:45:49.058  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:45:49.059  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 669 (count at Application.java:147) as input to shuffle 60
2022-07-30 11:45:49.059  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 64 (count at Application.java:147) with 1 output partitions
2022-07-30 11:45:49.059  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 125 (count at Application.java:147)
2022-07-30 11:45:49.059  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 124)
2022-07-30 11:45:49.059  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:45:49.060  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 125 (MapPartitionsRDD[672] at count at Application.java:147), which has no missing parents
2022-07-30 11:45:49.061  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_64 stored as values in memory (estimated size 11.0 KiB, free 897.1 MiB)
2022-07-30 11:45:49.066  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_64_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.1 MiB)
2022-07-30 11:45:49.066  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_64_piece0 in memory on host.docker.internal:58598 (size: 5.4 KiB, free: 897.5 MiB)
2022-07-30 11:45:49.067  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 64 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:45:49.067  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 125 (MapPartitionsRDD[672] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:45:49.067  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 125.0 with 1 tasks resource profile 0
2022-07-30 11:45:49.069  INFO   57 --- [er-event-loop-1] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 125.0 (TID 64) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:45:49.069  INFO   57 --- [ 125.0 (TID 64)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 125.0 (TID 64)
2022-07-30 11:45:49.072  INFO   57 --- [ 125.0 (TID 64)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:45:49.072  INFO   57 --- [ 125.0 (TID 64)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-30 11:45:49.073  INFO   57 --- [ 125.0 (TID 64)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 125.0 (TID 64). 2555 bytes result sent to driver
2022-07-30 11:45:49.074  INFO   57 --- [result-getter-3] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 125.0 (TID 64) in 6 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:45:49.074  INFO   57 --- [result-getter-3] org.apache.spark.internal.Logging        : Removed TaskSet 125.0, whose tasks have all completed, from pool 
2022-07-30 11:45:49.075  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 125 (count at Application.java:147) finished in 0.015 s
2022-07-30 11:45:49.075  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 64 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:45:49.075  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 125: Stage finished
2022-07-30 11:45:49.076  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 64 finished: count at Application.java:147, took 0.017407 s
2022-07-30 11:45:49.076  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177949000 ms.0 from job set of time 1659177949000 ms
2022-07-30 11:45:49.077  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 0.076 s for time 1659177949000 ms (execution: 0.072 s)
2022-07-30 11:45:49.077  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 652 from persistence list
2022-07-30 11:45:49.078  INFO   57 --- [-thread-pool-97] org.apache.spark.internal.Logging        : Removing RDD 652
2022-07-30 11:45:49.078  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 651 from persistence list
2022-07-30 11:45:49.078  INFO   57 --- [-thread-pool-99] org.apache.spark.internal.Logging        : Removing RDD 651
2022-07-30 11:45:49.078  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[651] at receiverStream at Application.java:122 of time 1659177949000 ms
2022-07-30 11:45:49.079  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177947000 ms
2022-07-30 11:45:49.079  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177947000 ms
2022-07-30 11:45:50.008  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177950000 ms
2022-07-30 11:45:50.009  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177950000 ms.0 from job set of time 1659177950000 ms
2022-07-30 11:45:50.016  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:45:50.016  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:45:50.122  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:45:50.123  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 680 (count at Application.java:147) as input to shuffle 61
2022-07-30 11:45:50.123  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 65 (count at Application.java:147) with 1 output partitions
2022-07-30 11:45:50.123  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 127 (count at Application.java:147)
2022-07-30 11:45:50.123  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 126)
2022-07-30 11:45:50.124  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:45:50.124  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 127 (MapPartitionsRDD[683] at count at Application.java:147), which has no missing parents
2022-07-30 11:45:50.125  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_65 stored as values in memory (estimated size 11.0 KiB, free 897.1 MiB)
2022-07-30 11:45:50.127  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_65_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.1 MiB)
2022-07-30 11:45:50.128  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_65_piece0 in memory on host.docker.internal:58598 (size: 5.4 KiB, free: 897.5 MiB)
2022-07-30 11:45:50.128  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 65 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:45:50.129  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 127 (MapPartitionsRDD[683] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:45:50.129  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 127.0 with 1 tasks resource profile 0
2022-07-30 11:45:50.130  INFO   57 --- [er-event-loop-0] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 127.0 (TID 65) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:45:50.131  INFO   57 --- [ 127.0 (TID 65)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 127.0 (TID 65)
2022-07-30 11:45:50.133  INFO   57 --- [ 127.0 (TID 65)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:45:50.133  INFO   57 --- [ 127.0 (TID 65)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-30 11:45:50.134  INFO   57 --- [ 127.0 (TID 65)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 127.0 (TID 65). 2555 bytes result sent to driver
2022-07-30 11:45:50.135  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 127.0 (TID 65) in 5 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:45:50.135  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Removed TaskSet 127.0, whose tasks have all completed, from pool 
2022-07-30 11:45:50.136  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 127 (count at Application.java:147) finished in 0.011 s
2022-07-30 11:45:50.136  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 65 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:45:50.136  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 127: Stage finished
2022-07-30 11:45:50.137  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 65 finished: count at Application.java:147, took 0.014251 s
2022-07-30 11:45:50.138  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177950000 ms.0 from job set of time 1659177950000 ms
2022-07-30 11:45:50.138  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 0.138 s for time 1659177950000 ms (execution: 0.130 s)
2022-07-30 11:45:50.138  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 663 from persistence list
2022-07-30 11:45:50.139  INFO   57 --- [c-thread-pool-9] org.apache.spark.internal.Logging        : Removing RDD 663
2022-07-30 11:45:50.139  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 662 from persistence list
2022-07-30 11:45:50.140  INFO   57 --- [-thread-pool-10] org.apache.spark.internal.Logging        : Removing RDD 662
2022-07-30 11:45:50.140  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[662] at receiverStream at Application.java:122 of time 1659177950000 ms
2022-07-30 11:45:50.141  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177948000 ms
2022-07-30 11:45:50.141  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177948000 ms
2022-07-30 11:45:51.008  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177951000 ms
2022-07-30 11:45:51.008  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177951000 ms.0 from job set of time 1659177951000 ms
2022-07-30 11:45:51.013  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:45:51.014  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:45:51.109  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:45:51.110  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 691 (count at Application.java:147) as input to shuffle 62
2022-07-30 11:45:51.110  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 66 (count at Application.java:147) with 1 output partitions
2022-07-30 11:45:51.110  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 129 (count at Application.java:147)
2022-07-30 11:45:51.110  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 128)
2022-07-30 11:45:51.111  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:45:51.111  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 129 (MapPartitionsRDD[694] at count at Application.java:147), which has no missing parents
2022-07-30 11:45:51.112  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_66 stored as values in memory (estimated size 11.0 KiB, free 897.1 MiB)
2022-07-30 11:45:51.116  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_66_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.1 MiB)
2022-07-30 11:45:51.117  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_66_piece0 in memory on host.docker.internal:58598 (size: 5.4 KiB, free: 897.5 MiB)
2022-07-30 11:45:51.117  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 66 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:45:51.118  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 129 (MapPartitionsRDD[694] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:45:51.119  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 129.0 with 1 tasks resource profile 0
2022-07-30 11:45:51.120  INFO   57 --- [er-event-loop-3] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 129.0 (TID 66) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:45:51.120  INFO   57 --- [ 129.0 (TID 66)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 129.0 (TID 66)
2022-07-30 11:45:51.123  INFO   57 --- [ 129.0 (TID 66)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:45:51.123  INFO   57 --- [ 129.0 (TID 66)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-30 11:45:51.124  INFO   57 --- [ 129.0 (TID 66)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 129.0 (TID 66). 2598 bytes result sent to driver
2022-07-30 11:45:51.125  INFO   57 --- [result-getter-1] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 129.0 (TID 66) in 5 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:45:51.125  INFO   57 --- [result-getter-1] org.apache.spark.internal.Logging        : Removed TaskSet 129.0, whose tasks have all completed, from pool 
2022-07-30 11:45:51.125  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 129 (count at Application.java:147) finished in 0.014 s
2022-07-30 11:45:51.126  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 66 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:45:51.126  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 129: Stage finished
2022-07-30 11:45:51.126  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 66 finished: count at Application.java:147, took 0.016823 s
2022-07-30 11:45:51.127  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177951000 ms.0 from job set of time 1659177951000 ms
2022-07-30 11:45:51.127  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 0.127 s for time 1659177951000 ms (execution: 0.119 s)
2022-07-30 11:45:51.127  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 674 from persistence list
2022-07-30 11:45:51.128  INFO   57 --- [-thread-pool-13] org.apache.spark.internal.Logging        : Removing RDD 674
2022-07-30 11:45:51.128  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 673 from persistence list
2022-07-30 11:45:51.128  INFO   57 --- [-thread-pool-15] org.apache.spark.internal.Logging        : Removing RDD 673
2022-07-30 11:45:51.128  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[673] at receiverStream at Application.java:122 of time 1659177951000 ms
2022-07-30 11:45:51.129  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177949000 ms
2022-07-30 11:45:51.129  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177949000 ms
2022-07-30 11:45:52.003  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177952000 ms
2022-07-30 11:45:52.003  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177952000 ms.0 from job set of time 1659177952000 ms
2022-07-30 11:45:52.008  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:45:52.009  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:45:52.075  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:45:52.076  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 702 (count at Application.java:147) as input to shuffle 63
2022-07-30 11:45:52.076  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 67 (count at Application.java:147) with 1 output partitions
2022-07-30 11:45:52.076  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 131 (count at Application.java:147)
2022-07-30 11:45:52.077  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 130)
2022-07-30 11:45:52.077  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:45:52.077  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 131 (MapPartitionsRDD[705] at count at Application.java:147), which has no missing parents
2022-07-30 11:45:52.079  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_67 stored as values in memory (estimated size 11.0 KiB, free 897.1 MiB)
2022-07-30 11:45:52.085  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_67_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.1 MiB)
2022-07-30 11:45:52.086  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_67_piece0 in memory on host.docker.internal:58598 (size: 5.4 KiB, free: 897.5 MiB)
2022-07-30 11:45:52.087  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 67 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:45:52.087  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 131 (MapPartitionsRDD[705] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:45:52.087  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 131.0 with 1 tasks resource profile 0
2022-07-30 11:45:52.088  INFO   57 --- [er-event-loop-2] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 131.0 (TID 67) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:45:52.089  INFO   57 --- [ 131.0 (TID 67)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 131.0 (TID 67)
2022-07-30 11:45:52.091  INFO   57 --- [ 131.0 (TID 67)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:45:52.092  INFO   57 --- [ 131.0 (TID 67)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-30 11:45:52.093  INFO   57 --- [ 131.0 (TID 67)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 131.0 (TID 67). 2598 bytes result sent to driver
2022-07-30 11:45:52.093  INFO   57 --- [result-getter-2] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 131.0 (TID 67) in 5 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:45:52.093  INFO   57 --- [result-getter-2] org.apache.spark.internal.Logging        : Removed TaskSet 131.0, whose tasks have all completed, from pool 
2022-07-30 11:45:52.094  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 131 (count at Application.java:147) finished in 0.016 s
2022-07-30 11:45:52.094  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 67 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:45:52.094  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 131: Stage finished
2022-07-30 11:45:52.095  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 67 finished: count at Application.java:147, took 0.019088 s
2022-07-30 11:45:52.096  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177952000 ms.0 from job set of time 1659177952000 ms
2022-07-30 11:45:52.096  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 0.096 s for time 1659177952000 ms (execution: 0.093 s)
2022-07-30 11:45:52.097  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 685 from persistence list
2022-07-30 11:45:52.098  INFO   57 --- [-thread-pool-18] org.apache.spark.internal.Logging        : Removing RDD 685
2022-07-30 11:45:52.098  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 684 from persistence list
2022-07-30 11:45:52.099  INFO   57 --- [-thread-pool-24] org.apache.spark.internal.Logging        : Removing RDD 684
2022-07-30 11:45:52.099  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[684] at receiverStream at Application.java:122 of time 1659177952000 ms
2022-07-30 11:45:52.099  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177950000 ms
2022-07-30 11:45:52.099  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177950000 ms
2022-07-30 11:45:53.004  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177953000 ms
2022-07-30 11:45:53.005  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177953000 ms.0 from job set of time 1659177953000 ms
2022-07-30 11:45:53.011  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:45:53.011  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:45:53.070  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:45:53.071  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 713 (count at Application.java:147) as input to shuffle 64
2022-07-30 11:45:53.073  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 68 (count at Application.java:147) with 1 output partitions
2022-07-30 11:45:53.073  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 133 (count at Application.java:147)
2022-07-30 11:45:53.073  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 132)
2022-07-30 11:45:53.073  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:45:53.074  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 133 (MapPartitionsRDD[716] at count at Application.java:147), which has no missing parents
2022-07-30 11:45:53.076  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_68 stored as values in memory (estimated size 11.0 KiB, free 897.1 MiB)
2022-07-30 11:45:53.078  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_68_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.1 MiB)
2022-07-30 11:45:53.079  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_68_piece0 in memory on host.docker.internal:58598 (size: 5.4 KiB, free: 897.5 MiB)
2022-07-30 11:45:53.080  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 68 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:45:53.080  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 133 (MapPartitionsRDD[716] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:45:53.081  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 133.0 with 1 tasks resource profile 0
2022-07-30 11:45:53.082  INFO   57 --- [er-event-loop-1] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 133.0 (TID 68) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:45:53.083  INFO   57 --- [ 133.0 (TID 68)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 133.0 (TID 68)
2022-07-30 11:45:53.086  INFO   57 --- [ 133.0 (TID 68)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:45:53.086  INFO   57 --- [ 133.0 (TID 68)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-30 11:45:53.087  INFO   57 --- [ 133.0 (TID 68)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 133.0 (TID 68). 2555 bytes result sent to driver
2022-07-30 11:45:53.088  INFO   57 --- [result-getter-3] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 133.0 (TID 68) in 7 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:45:53.088  INFO   57 --- [result-getter-3] org.apache.spark.internal.Logging        : Removed TaskSet 133.0, whose tasks have all completed, from pool 
2022-07-30 11:45:53.089  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 133 (count at Application.java:147) finished in 0.014 s
2022-07-30 11:45:53.089  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 68 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:45:53.090  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 133: Stage finished
2022-07-30 11:45:53.090  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 68 finished: count at Application.java:147, took 0.019752 s
2022-07-30 11:45:53.091  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177953000 ms.0 from job set of time 1659177953000 ms
2022-07-30 11:45:53.091  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 0.091 s for time 1659177953000 ms (execution: 0.086 s)
2022-07-30 11:45:53.092  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 696 from persistence list
2022-07-30 11:45:53.095  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 695 from persistence list
2022-07-30 11:45:53.098  INFO   57 --- [-thread-pool-27] org.apache.spark.internal.Logging        : Removing RDD 696
2022-07-30 11:45:53.099  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[695] at receiverStream at Application.java:122 of time 1659177953000 ms
2022-07-30 11:45:53.100  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177951000 ms
2022-07-30 11:45:53.100  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177951000 ms
2022-07-30 11:45:53.100  INFO   57 --- [-thread-pool-25] org.apache.spark.internal.Logging        : Removing RDD 695
2022-07-30 11:45:53.853  INFO  571 --- [ool Maintenance] g.apache.nifi.remote.client.PeerSelector : Successfully refreshed peer status cache; remote group consists of 1 peers
2022-07-30 11:45:54.001  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177954000 ms
2022-07-30 11:45:54.001  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177954000 ms.0 from job set of time 1659177954000 ms
2022-07-30 11:45:54.003  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:45:54.003  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:45:54.052  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:45:54.052  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 724 (count at Application.java:147) as input to shuffle 65
2022-07-30 11:45:54.053  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 69 (count at Application.java:147) with 1 output partitions
2022-07-30 11:45:54.053  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 135 (count at Application.java:147)
2022-07-30 11:45:54.053  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 134)
2022-07-30 11:45:54.053  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:45:54.053  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 135 (MapPartitionsRDD[727] at count at Application.java:147), which has no missing parents
2022-07-30 11:45:54.055  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_69 stored as values in memory (estimated size 11.0 KiB, free 897.1 MiB)
2022-07-30 11:45:54.057  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_69_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.0 MiB)
2022-07-30 11:45:54.058  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_69_piece0 in memory on host.docker.internal:58598 (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:45:54.058  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 69 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:45:54.059  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 135 (MapPartitionsRDD[727] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:45:54.059  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 135.0 with 1 tasks resource profile 0
2022-07-30 11:45:54.059  INFO   57 --- [er-event-loop-0] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 135.0 (TID 69) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:45:54.060  INFO   57 --- [ 135.0 (TID 69)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 135.0 (TID 69)
2022-07-30 11:45:54.062  INFO   57 --- [ 135.0 (TID 69)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:45:54.062  INFO   57 --- [ 135.0 (TID 69)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-30 11:45:54.063  INFO   57 --- [ 135.0 (TID 69)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 135.0 (TID 69). 2555 bytes result sent to driver
2022-07-30 11:45:54.064  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 135.0 (TID 69) in 5 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:45:54.064  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Removed TaskSet 135.0, whose tasks have all completed, from pool 
2022-07-30 11:45:54.065  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 135 (count at Application.java:147) finished in 0.011 s
2022-07-30 11:45:54.065  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 69 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:45:54.066  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 135: Stage finished
2022-07-30 11:45:54.066  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 69 finished: count at Application.java:147, took 0.014113 s
2022-07-30 11:45:54.067  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177954000 ms.0 from job set of time 1659177954000 ms
2022-07-30 11:45:54.067  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 0.067 s for time 1659177954000 ms (execution: 0.066 s)
2022-07-30 11:45:54.068  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 707 from persistence list
2022-07-30 11:45:54.069  INFO   57 --- [-thread-pool-33] org.apache.spark.internal.Logging        : Removing RDD 707
2022-07-30 11:45:54.069  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 706 from persistence list
2022-07-30 11:45:54.069  INFO   57 --- [-thread-pool-36] org.apache.spark.internal.Logging        : Removing RDD 706
2022-07-30 11:45:54.069  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[706] at receiverStream at Application.java:122 of time 1659177954000 ms
2022-07-30 11:45:54.070  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177952000 ms
2022-07-30 11:45:54.070  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177952000 ms
2022-07-30 11:45:55.004  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177955000 ms
2022-07-30 11:45:55.004  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177955000 ms.0 from job set of time 1659177955000 ms
2022-07-30 11:45:55.010  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:45:55.012  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:45:55.166  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:45:55.168  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 735 (count at Application.java:147) as input to shuffle 66
2022-07-30 11:45:55.168  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 70 (count at Application.java:147) with 1 output partitions
2022-07-30 11:45:55.169  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 137 (count at Application.java:147)
2022-07-30 11:45:55.169  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 136)
2022-07-30 11:45:55.169  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:45:55.170  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 137 (MapPartitionsRDD[738] at count at Application.java:147), which has no missing parents
2022-07-30 11:45:55.171  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_70 stored as values in memory (estimated size 11.0 KiB, free 897.0 MiB)
2022-07-30 11:45:55.175  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_70_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.0 MiB)
2022-07-30 11:45:55.177  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_70_piece0 in memory on host.docker.internal:58598 (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:45:55.178  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 70 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:45:55.178  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 137 (MapPartitionsRDD[738] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:45:55.179  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 137.0 with 1 tasks resource profile 0
2022-07-30 11:45:55.180  INFO   57 --- [er-event-loop-3] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 137.0 (TID 70) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:45:55.180  INFO   57 --- [ 137.0 (TID 70)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 137.0 (TID 70)
2022-07-30 11:45:55.184  INFO   57 --- [ 137.0 (TID 70)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:45:55.185  INFO   57 --- [ 137.0 (TID 70)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-30 11:45:55.186  INFO   57 --- [ 137.0 (TID 70)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 137.0 (TID 70). 2598 bytes result sent to driver
2022-07-30 11:45:55.191  INFO   57 --- [result-getter-1] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 137.0 (TID 70) in 11 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:45:55.191  INFO   57 --- [result-getter-1] org.apache.spark.internal.Logging        : Removed TaskSet 137.0, whose tasks have all completed, from pool 
2022-07-30 11:45:55.192  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 137 (count at Application.java:147) finished in 0.022 s
2022-07-30 11:45:55.193  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 70 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:45:55.193  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 137: Stage finished
2022-07-30 11:45:55.194  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 70 finished: count at Application.java:147, took 0.027222 s
2022-07-30 11:45:55.196  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177955000 ms.0 from job set of time 1659177955000 ms
2022-07-30 11:45:55.196  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 0.196 s for time 1659177955000 ms (execution: 0.192 s)
2022-07-30 11:45:55.196  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 718 from persistence list
2022-07-30 11:45:55.197  INFO   57 --- [-thread-pool-40] org.apache.spark.internal.Logging        : Removing RDD 718
2022-07-30 11:45:55.197  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 717 from persistence list
2022-07-30 11:45:55.198  INFO   57 --- [-thread-pool-41] org.apache.spark.internal.Logging        : Removing RDD 717
2022-07-30 11:45:55.198  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[717] at receiverStream at Application.java:122 of time 1659177955000 ms
2022-07-30 11:45:55.198  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177953000 ms
2022-07-30 11:45:55.198  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177953000 ms
2022-07-30 11:45:56.005  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177956000 ms
2022-07-30 11:45:56.005  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177956000 ms.0 from job set of time 1659177956000 ms
2022-07-30 11:45:56.016  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:45:56.017  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:45:56.066  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:45:56.067  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 746 (count at Application.java:147) as input to shuffle 67
2022-07-30 11:45:56.067  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 71 (count at Application.java:147) with 1 output partitions
2022-07-30 11:45:56.067  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 139 (count at Application.java:147)
2022-07-30 11:45:56.067  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 138)
2022-07-30 11:45:56.067  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:45:56.068  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 139 (MapPartitionsRDD[749] at count at Application.java:147), which has no missing parents
2022-07-30 11:45:56.069  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_71 stored as values in memory (estimated size 11.0 KiB, free 897.0 MiB)
2022-07-30 11:45:56.071  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_71_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.0 MiB)
2022-07-30 11:45:56.071  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_71_piece0 in memory on host.docker.internal:58598 (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:45:56.072  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 71 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:45:56.072  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 139 (MapPartitionsRDD[749] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:45:56.072  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 139.0 with 1 tasks resource profile 0
2022-07-30 11:45:56.073  INFO   57 --- [er-event-loop-2] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 139.0 (TID 71) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:45:56.073  INFO   57 --- [ 139.0 (TID 71)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 139.0 (TID 71)
2022-07-30 11:45:56.075  INFO   57 --- [ 139.0 (TID 71)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:45:56.075  INFO   57 --- [ 139.0 (TID 71)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-30 11:45:56.076  INFO   57 --- [ 139.0 (TID 71)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 139.0 (TID 71). 2598 bytes result sent to driver
2022-07-30 11:45:56.077  INFO   57 --- [result-getter-2] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 139.0 (TID 71) in 4 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:45:56.077  INFO   57 --- [result-getter-2] org.apache.spark.internal.Logging        : Removed TaskSet 139.0, whose tasks have all completed, from pool 
2022-07-30 11:45:56.078  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 139 (count at Application.java:147) finished in 0.008 s
2022-07-30 11:45:56.078  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 71 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:45:56.078  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 139: Stage finished
2022-07-30 11:45:56.078  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 71 finished: count at Application.java:147, took 0.011772 s
2022-07-30 11:45:56.079  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177956000 ms.0 from job set of time 1659177956000 ms
2022-07-30 11:45:56.079  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 0.079 s for time 1659177956000 ms (execution: 0.074 s)
2022-07-30 11:45:56.079  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 729 from persistence list
2022-07-30 11:45:56.080  INFO   57 --- [-thread-pool-50] org.apache.spark.internal.Logging        : Removing RDD 729
2022-07-30 11:45:56.080  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 728 from persistence list
2022-07-30 11:45:56.080  INFO   57 --- [-thread-pool-47] org.apache.spark.internal.Logging        : Removing RDD 728
2022-07-30 11:45:56.081  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[728] at receiverStream at Application.java:122 of time 1659177956000 ms
2022-07-30 11:45:56.081  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177954000 ms
2022-07-30 11:45:56.081  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177954000 ms
2022-07-30 11:45:57.002  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177957000 ms
2022-07-30 11:45:57.002  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177957000 ms.0 from job set of time 1659177957000 ms
2022-07-30 11:45:57.007  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:45:57.007  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:45:57.064  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:45:57.065  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 757 (count at Application.java:147) as input to shuffle 68
2022-07-30 11:45:57.065  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 72 (count at Application.java:147) with 1 output partitions
2022-07-30 11:45:57.065  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 141 (count at Application.java:147)
2022-07-30 11:45:57.065  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 140)
2022-07-30 11:45:57.065  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:45:57.065  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 141 (MapPartitionsRDD[760] at count at Application.java:147), which has no missing parents
2022-07-30 11:45:57.067  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_72 stored as values in memory (estimated size 11.0 KiB, free 897.0 MiB)
2022-07-30 11:45:57.068  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_72_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.0 MiB)
2022-07-30 11:45:57.069  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_72_piece0 in memory on host.docker.internal:58598 (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:45:57.069  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 72 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:45:57.069  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 141 (MapPartitionsRDD[760] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:45:57.069  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 141.0 with 1 tasks resource profile 0
2022-07-30 11:45:57.070  INFO   57 --- [er-event-loop-1] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 141.0 (TID 72) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:45:57.070  INFO   57 --- [ 141.0 (TID 72)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 141.0 (TID 72)
2022-07-30 11:45:57.072  INFO   57 --- [ 141.0 (TID 72)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:45:57.072  INFO   57 --- [ 141.0 (TID 72)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-30 11:45:57.073  INFO   57 --- [ 141.0 (TID 72)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 141.0 (TID 72). 2555 bytes result sent to driver
2022-07-30 11:45:57.073  INFO   57 --- [result-getter-3] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 141.0 (TID 72) in 3 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:45:57.073  INFO   57 --- [result-getter-3] org.apache.spark.internal.Logging        : Removed TaskSet 141.0, whose tasks have all completed, from pool 
2022-07-30 11:45:57.074  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 141 (count at Application.java:147) finished in 0.008 s
2022-07-30 11:45:57.074  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 72 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:45:57.074  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 141: Stage finished
2022-07-30 11:45:57.075  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 72 finished: count at Application.java:147, took 0.010127 s
2022-07-30 11:45:57.075  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177957000 ms.0 from job set of time 1659177957000 ms
2022-07-30 11:45:57.075  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 0.075 s for time 1659177957000 ms (execution: 0.073 s)
2022-07-30 11:45:57.076  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 740 from persistence list
2022-07-30 11:45:57.076  INFO   57 --- [-thread-pool-46] org.apache.spark.internal.Logging        : Removing RDD 740
2022-07-30 11:45:57.076  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 739 from persistence list
2022-07-30 11:45:57.077  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[739] at receiverStream at Application.java:122 of time 1659177957000 ms
2022-07-30 11:45:57.077  INFO   57 --- [-thread-pool-55] org.apache.spark.internal.Logging        : Removing RDD 739
2022-07-30 11:45:57.077  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177955000 ms
2022-07-30 11:45:57.077  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177955000 ms
2022-07-30 11:45:58.002  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177958000 ms
2022-07-30 11:45:58.002  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177958000 ms.0 from job set of time 1659177958000 ms
2022-07-30 11:45:58.005  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:45:58.006  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:45:58.054  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:45:58.055  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 768 (count at Application.java:147) as input to shuffle 69
2022-07-30 11:45:58.055  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 73 (count at Application.java:147) with 1 output partitions
2022-07-30 11:45:58.055  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 143 (count at Application.java:147)
2022-07-30 11:45:58.055  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 142)
2022-07-30 11:45:58.056  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:45:58.056  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 143 (MapPartitionsRDD[771] at count at Application.java:147), which has no missing parents
2022-07-30 11:45:58.057  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_73 stored as values in memory (estimated size 11.0 KiB, free 897.0 MiB)
2022-07-30 11:45:58.059  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_73_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.0 MiB)
2022-07-30 11:45:58.060  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_73_piece0 in memory on host.docker.internal:58598 (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:45:58.060  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 73 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:45:58.061  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 143 (MapPartitionsRDD[771] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:45:58.061  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 143.0 with 1 tasks resource profile 0
2022-07-30 11:45:58.062  INFO   57 --- [er-event-loop-2] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 143.0 (TID 73) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:45:58.062  INFO   57 --- [ 143.0 (TID 73)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 143.0 (TID 73)
2022-07-30 11:45:58.064  INFO   57 --- [ 143.0 (TID 73)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:45:58.064  INFO   57 --- [ 143.0 (TID 73)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-30 11:45:58.064  INFO   57 --- [ 143.0 (TID 73)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 143.0 (TID 73). 2555 bytes result sent to driver
2022-07-30 11:45:58.065  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 143.0 (TID 73) in 4 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:45:58.065  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Removed TaskSet 143.0, whose tasks have all completed, from pool 
2022-07-30 11:45:58.065  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 143 (count at Application.java:147) finished in 0.009 s
2022-07-30 11:45:58.066  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 73 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:45:58.066  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 143: Stage finished
2022-07-30 11:45:58.066  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 73 finished: count at Application.java:147, took 0.011068 s
2022-07-30 11:45:58.066  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177958000 ms.0 from job set of time 1659177958000 ms
2022-07-30 11:45:58.067  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 0.066 s for time 1659177958000 ms (execution: 0.064 s)
2022-07-30 11:45:58.067  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 751 from persistence list
2022-07-30 11:45:58.067  INFO   57 --- [-thread-pool-56] org.apache.spark.internal.Logging        : Removing RDD 751
2022-07-30 11:45:58.067  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 750 from persistence list
2022-07-30 11:45:58.068  INFO   57 --- [-thread-pool-61] org.apache.spark.internal.Logging        : Removing RDD 750
2022-07-30 11:45:58.068  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[750] at receiverStream at Application.java:122 of time 1659177958000 ms
2022-07-30 11:45:58.068  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177956000 ms
2022-07-30 11:45:58.069  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177956000 ms
2022-07-30 11:45:59.001  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177959000 ms
2022-07-30 11:45:59.001  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177959000 ms.0 from job set of time 1659177959000 ms
2022-07-30 11:45:59.003  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:45:59.003  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:45:59.042  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:45:59.043  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 779 (count at Application.java:147) as input to shuffle 70
2022-07-30 11:45:59.043  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 74 (count at Application.java:147) with 1 output partitions
2022-07-30 11:45:59.043  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 145 (count at Application.java:147)
2022-07-30 11:45:59.043  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 144)
2022-07-30 11:45:59.043  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:45:59.043  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 145 (MapPartitionsRDD[782] at count at Application.java:147), which has no missing parents
2022-07-30 11:45:59.045  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_74 stored as values in memory (estimated size 11.0 KiB, free 897.0 MiB)
2022-07-30 11:45:59.046  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_74_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.0 MiB)
2022-07-30 11:45:59.046  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_74_piece0 in memory on host.docker.internal:58598 (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:45:59.047  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 74 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:45:59.047  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 145 (MapPartitionsRDD[782] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:45:59.047  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 145.0 with 1 tasks resource profile 0
2022-07-30 11:45:59.048  INFO   57 --- [er-event-loop-1] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 145.0 (TID 74) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:45:59.048  INFO   57 --- [ 145.0 (TID 74)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 145.0 (TID 74)
2022-07-30 11:45:59.050  INFO   57 --- [ 145.0 (TID 74)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:45:59.050  INFO   57 --- [ 145.0 (TID 74)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-30 11:45:59.051  INFO   57 --- [ 145.0 (TID 74)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 145.0 (TID 74). 2555 bytes result sent to driver
2022-07-30 11:45:59.052  INFO   57 --- [result-getter-1] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 145.0 (TID 74) in 4 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:45:59.053  INFO   57 --- [result-getter-1] org.apache.spark.internal.Logging        : Removed TaskSet 145.0, whose tasks have all completed, from pool 
2022-07-30 11:45:59.053  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 145 (count at Application.java:147) finished in 0.009 s
2022-07-30 11:45:59.053  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 74 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:45:59.053  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 145: Stage finished
2022-07-30 11:45:59.054  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 74 finished: count at Application.java:147, took 0.011073 s
2022-07-30 11:45:59.054  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177959000 ms.0 from job set of time 1659177959000 ms
2022-07-30 11:45:59.054  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 0.054 s for time 1659177959000 ms (execution: 0.053 s)
2022-07-30 11:45:59.055  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 762 from persistence list
2022-07-30 11:45:59.055  INFO   57 --- [-thread-pool-60] org.apache.spark.internal.Logging        : Removing RDD 762
2022-07-30 11:45:59.055  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 761 from persistence list
2022-07-30 11:45:59.056  INFO   57 --- [-thread-pool-59] org.apache.spark.internal.Logging        : Removing RDD 761
2022-07-30 11:45:59.056  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[761] at receiverStream at Application.java:122 of time 1659177959000 ms
2022-07-30 11:45:59.056  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177957000 ms
2022-07-30 11:45:59.057  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177957000 ms
2022-07-30 11:46:00.003  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177960000 ms
2022-07-30 11:46:00.003  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177960000 ms.0 from job set of time 1659177960000 ms
2022-07-30 11:46:00.006  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:46:00.006  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:46:00.055  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:46:00.056  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 790 (count at Application.java:147) as input to shuffle 71
2022-07-30 11:46:00.056  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 75 (count at Application.java:147) with 1 output partitions
2022-07-30 11:46:00.056  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 147 (count at Application.java:147)
2022-07-30 11:46:00.056  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 146)
2022-07-30 11:46:00.056  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:46:00.056  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 147 (MapPartitionsRDD[793] at count at Application.java:147), which has no missing parents
2022-07-30 11:46:00.057  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_75 stored as values in memory (estimated size 11.0 KiB, free 897.0 MiB)
2022-07-30 11:46:00.059  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_75_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.0 MiB)
2022-07-30 11:46:00.060  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_75_piece0 in memory on host.docker.internal:58598 (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:46:00.060  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 75 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:46:00.060  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 147 (MapPartitionsRDD[793] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:46:00.060  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 147.0 with 1 tasks resource profile 0
2022-07-30 11:46:00.061  INFO   57 --- [er-event-loop-0] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 147.0 (TID 75) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:46:00.061  INFO   57 --- [ 147.0 (TID 75)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 147.0 (TID 75)
2022-07-30 11:46:00.064  INFO   57 --- [ 147.0 (TID 75)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:46:00.064  INFO   57 --- [ 147.0 (TID 75)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-30 11:46:00.065  INFO   57 --- [ 147.0 (TID 75)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 147.0 (TID 75). 2555 bytes result sent to driver
2022-07-30 11:46:00.065  INFO   57 --- [result-getter-2] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 147.0 (TID 75) in 4 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:46:00.066  INFO   57 --- [result-getter-2] org.apache.spark.internal.Logging        : Removed TaskSet 147.0, whose tasks have all completed, from pool 
2022-07-30 11:46:00.066  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 147 (count at Application.java:147) finished in 0.009 s
2022-07-30 11:46:00.066  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 75 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:46:00.067  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 147: Stage finished
2022-07-30 11:46:00.067  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 75 finished: count at Application.java:147, took 0.011770 s
2022-07-30 11:46:00.069  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177960000 ms.0 from job set of time 1659177960000 ms
2022-07-30 11:46:00.069  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 0.069 s for time 1659177960000 ms (execution: 0.066 s)
2022-07-30 11:46:00.069  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 773 from persistence list
2022-07-30 11:46:00.070  INFO   57 --- [-thread-pool-71] org.apache.spark.internal.Logging        : Removing RDD 773
2022-07-30 11:46:00.070  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 772 from persistence list
2022-07-30 11:46:00.070  INFO   57 --- [-thread-pool-66] org.apache.spark.internal.Logging        : Removing RDD 772
2022-07-30 11:46:00.071  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[772] at receiverStream at Application.java:122 of time 1659177960000 ms
2022-07-30 11:46:00.071  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177958000 ms
2022-07-30 11:46:00.071  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177958000 ms
2022-07-30 11:46:01.002  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177961000 ms
2022-07-30 11:46:01.002  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177961000 ms.0 from job set of time 1659177961000 ms
2022-07-30 11:46:01.004  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:46:01.004  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:46:01.048  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:46:01.049  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 801 (count at Application.java:147) as input to shuffle 72
2022-07-30 11:46:01.049  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 76 (count at Application.java:147) with 1 output partitions
2022-07-30 11:46:01.049  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 149 (count at Application.java:147)
2022-07-30 11:46:01.049  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 148)
2022-07-30 11:46:01.050  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:46:01.051  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 149 (MapPartitionsRDD[804] at count at Application.java:147), which has no missing parents
2022-07-30 11:46:01.052  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_76 stored as values in memory (estimated size 11.0 KiB, free 896.9 MiB)
2022-07-30 11:46:01.054  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_76_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 896.9 MiB)
2022-07-30 11:46:01.054  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_76_piece0 in memory on host.docker.internal:58598 (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:46:01.055  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 76 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:46:01.055  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 149 (MapPartitionsRDD[804] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:46:01.055  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 149.0 with 1 tasks resource profile 0
2022-07-30 11:46:01.056  INFO   57 --- [er-event-loop-3] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 149.0 (TID 76) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:46:01.056  INFO   57 --- [ 149.0 (TID 76)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 149.0 (TID 76)
2022-07-30 11:46:01.059  INFO   57 --- [ 149.0 (TID 76)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:46:01.059  INFO   57 --- [ 149.0 (TID 76)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-30 11:46:01.074  INFO   57 --- [ 149.0 (TID 76)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 149.0 (TID 76). 2598 bytes result sent to driver
2022-07-30 11:46:01.074  INFO   57 --- [result-getter-3] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 149.0 (TID 76) in 18 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:46:01.074  INFO   57 --- [result-getter-3] org.apache.spark.internal.Logging        : Removed TaskSet 149.0, whose tasks have all completed, from pool 
2022-07-30 11:46:01.075  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 149 (count at Application.java:147) finished in 0.024 s
2022-07-30 11:46:01.075  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 76 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:46:01.075  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 149: Stage finished
2022-07-30 11:46:01.075  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 76 finished: count at Application.java:147, took 0.026781 s
2022-07-30 11:46:01.076  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177961000 ms.0 from job set of time 1659177961000 ms
2022-07-30 11:46:01.076  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 0.076 s for time 1659177961000 ms (execution: 0.074 s)
2022-07-30 11:46:01.077  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 784 from persistence list
2022-07-30 11:46:01.078  INFO   57 --- [-thread-pool-74] org.apache.spark.internal.Logging        : Removing RDD 784
2022-07-30 11:46:01.078  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 783 from persistence list
2022-07-30 11:46:01.078  INFO   57 --- [-thread-pool-76] org.apache.spark.internal.Logging        : Removing RDD 783
2022-07-30 11:46:01.078  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[783] at receiverStream at Application.java:122 of time 1659177961000 ms
2022-07-30 11:46:01.079  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177959000 ms
2022-07-30 11:46:01.079  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177959000 ms
2022-07-30 11:46:02.004  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177962000 ms
2022-07-30 11:46:02.004  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177962000 ms.0 from job set of time 1659177962000 ms
2022-07-30 11:46:02.009  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:46:02.010  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:46:02.063  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:46:02.064  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 812 (count at Application.java:147) as input to shuffle 73
2022-07-30 11:46:02.064  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 77 (count at Application.java:147) with 1 output partitions
2022-07-30 11:46:02.064  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 151 (count at Application.java:147)
2022-07-30 11:46:02.064  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 150)
2022-07-30 11:46:02.064  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:46:02.065  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 151 (MapPartitionsRDD[815] at count at Application.java:147), which has no missing parents
2022-07-30 11:46:02.066  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_77 stored as values in memory (estimated size 11.0 KiB, free 896.9 MiB)
2022-07-30 11:46:02.068  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_77_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 896.9 MiB)
2022-07-30 11:46:02.068  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_77_piece0 in memory on host.docker.internal:58598 (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:46:02.069  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 77 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:46:02.069  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 151 (MapPartitionsRDD[815] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:46:02.069  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 151.0 with 1 tasks resource profile 0
2022-07-30 11:46:02.070  INFO   57 --- [er-event-loop-2] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 151.0 (TID 77) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:46:02.071  INFO   57 --- [ 151.0 (TID 77)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 151.0 (TID 77)
2022-07-30 11:46:02.072  INFO   57 --- [ 151.0 (TID 77)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:46:02.073  INFO   57 --- [ 151.0 (TID 77)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-30 11:46:02.073  INFO   57 --- [ 151.0 (TID 77)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 151.0 (TID 77). 2555 bytes result sent to driver
2022-07-30 11:46:02.074  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 151.0 (TID 77) in 4 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:46:02.074  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Removed TaskSet 151.0, whose tasks have all completed, from pool 
2022-07-30 11:46:02.075  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 151 (count at Application.java:147) finished in 0.010 s
2022-07-30 11:46:02.075  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 77 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:46:02.075  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 151: Stage finished
2022-07-30 11:46:02.075  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 77 finished: count at Application.java:147, took 0.011639 s
2022-07-30 11:46:02.076  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177962000 ms.0 from job set of time 1659177962000 ms
2022-07-30 11:46:02.076  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 0.076 s for time 1659177962000 ms (execution: 0.072 s)
2022-07-30 11:46:02.076  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 795 from persistence list
2022-07-30 11:46:02.077  INFO   57 --- [-thread-pool-78] org.apache.spark.internal.Logging        : Removing RDD 795
2022-07-30 11:46:02.077  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 794 from persistence list
2022-07-30 11:46:02.077  INFO   57 --- [-thread-pool-84] org.apache.spark.internal.Logging        : Removing RDD 794
2022-07-30 11:46:02.078  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[794] at receiverStream at Application.java:122 of time 1659177962000 ms
2022-07-30 11:46:02.078  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177960000 ms
2022-07-30 11:46:02.078  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177960000 ms
2022-07-30 11:46:03.004  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177963000 ms
2022-07-30 11:46:03.004  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177963000 ms.0 from job set of time 1659177963000 ms
2022-07-30 11:46:03.009  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:46:03.010  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:46:03.057  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:46:03.058  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 823 (count at Application.java:147) as input to shuffle 74
2022-07-30 11:46:03.058  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 78 (count at Application.java:147) with 1 output partitions
2022-07-30 11:46:03.058  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 153 (count at Application.java:147)
2022-07-30 11:46:03.058  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 152)
2022-07-30 11:46:03.058  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:46:03.059  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 153 (MapPartitionsRDD[826] at count at Application.java:147), which has no missing parents
2022-07-30 11:46:03.060  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_78 stored as values in memory (estimated size 11.0 KiB, free 896.9 MiB)
2022-07-30 11:46:03.061  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_78_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 896.9 MiB)
2022-07-30 11:46:03.062  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_78_piece0 in memory on host.docker.internal:58598 (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:46:03.062  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 78 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:46:03.062  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 153 (MapPartitionsRDD[826] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:46:03.062  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 153.0 with 1 tasks resource profile 0
2022-07-30 11:46:03.063  INFO   57 --- [er-event-loop-1] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 153.0 (TID 78) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:46:03.063  INFO   57 --- [ 153.0 (TID 78)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 153.0 (TID 78)
2022-07-30 11:46:03.065  INFO   57 --- [ 153.0 (TID 78)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:46:03.065  INFO   57 --- [ 153.0 (TID 78)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-30 11:46:03.067  INFO   57 --- [ 153.0 (TID 78)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 153.0 (TID 78). 2555 bytes result sent to driver
2022-07-30 11:46:03.067  INFO   57 --- [result-getter-1] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 153.0 (TID 78) in 4 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:46:03.068  INFO   57 --- [result-getter-1] org.apache.spark.internal.Logging        : Removed TaskSet 153.0, whose tasks have all completed, from pool 
2022-07-30 11:46:03.068  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 153 (count at Application.java:147) finished in 0.009 s
2022-07-30 11:46:03.069  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 78 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:46:03.069  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 153: Stage finished
2022-07-30 11:46:03.070  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 78 finished: count at Application.java:147, took 0.012006 s
2022-07-30 11:46:03.071  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177963000 ms.0 from job set of time 1659177963000 ms
2022-07-30 11:46:03.071  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 0.070 s for time 1659177963000 ms (execution: 0.066 s)
2022-07-30 11:46:03.071  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 806 from persistence list
2022-07-30 11:46:03.072  INFO   57 --- [-thread-pool-88] org.apache.spark.internal.Logging        : Removing RDD 806
2022-07-30 11:46:03.072  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 805 from persistence list
2022-07-30 11:46:03.073  INFO   57 --- [-thread-pool-90] org.apache.spark.internal.Logging        : Removing RDD 805
2022-07-30 11:46:03.073  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[805] at receiverStream at Application.java:122 of time 1659177963000 ms
2022-07-30 11:46:03.073  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177961000 ms
2022-07-30 11:46:03.073  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177961000 ms
2022-07-30 11:46:04.004  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177964000 ms
2022-07-30 11:46:04.004  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177964000 ms.0 from job set of time 1659177964000 ms
2022-07-30 11:46:04.008  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:46:04.008  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:46:04.065  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:46:04.065  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 834 (count at Application.java:147) as input to shuffle 75
2022-07-30 11:46:04.066  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 79 (count at Application.java:147) with 1 output partitions
2022-07-30 11:46:04.066  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 155 (count at Application.java:147)
2022-07-30 11:46:04.066  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 154)
2022-07-30 11:46:04.066  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:46:04.067  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 155 (MapPartitionsRDD[837] at count at Application.java:147), which has no missing parents
2022-07-30 11:46:04.069  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_79 stored as values in memory (estimated size 11.0 KiB, free 896.9 MiB)
2022-07-30 11:46:04.070  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_79_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 896.9 MiB)
2022-07-30 11:46:04.071  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_79_piece0 in memory on host.docker.internal:58598 (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:46:04.071  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 79 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:46:04.071  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 155 (MapPartitionsRDD[837] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:46:04.072  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 155.0 with 1 tasks resource profile 0
2022-07-30 11:46:04.072  INFO   57 --- [er-event-loop-0] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 155.0 (TID 79) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:46:04.073  INFO   57 --- [ 155.0 (TID 79)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 155.0 (TID 79)
2022-07-30 11:46:04.075  INFO   57 --- [ 155.0 (TID 79)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:46:04.075  INFO   57 --- [ 155.0 (TID 79)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-30 11:46:04.076  INFO   57 --- [ 155.0 (TID 79)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 155.0 (TID 79). 2598 bytes result sent to driver
2022-07-30 11:46:04.077  INFO   57 --- [result-getter-2] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 155.0 (TID 79) in 5 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:46:04.077  INFO   57 --- [result-getter-2] org.apache.spark.internal.Logging        : Removed TaskSet 155.0, whose tasks have all completed, from pool 
2022-07-30 11:46:04.078  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 155 (count at Application.java:147) finished in 0.009 s
2022-07-30 11:46:04.078  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 79 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:46:04.078  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 155: Stage finished
2022-07-30 11:46:04.079  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 79 finished: count at Application.java:147, took 0.013410 s
2022-07-30 11:46:04.079  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177964000 ms.0 from job set of time 1659177964000 ms
2022-07-30 11:46:04.080  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 0.079 s for time 1659177964000 ms (execution: 0.075 s)
2022-07-30 11:46:04.080  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 817 from persistence list
2022-07-30 11:46:04.080  INFO   57 --- [-thread-pool-96] org.apache.spark.internal.Logging        : Removing RDD 817
2022-07-30 11:46:04.080  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 816 from persistence list
2022-07-30 11:46:04.081  INFO   57 --- [-thread-pool-98] org.apache.spark.internal.Logging        : Removing RDD 816
2022-07-30 11:46:04.081  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[816] at receiverStream at Application.java:122 of time 1659177964000 ms
2022-07-30 11:46:04.082  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177962000 ms
2022-07-30 11:46:04.082  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177962000 ms
2022-07-30 11:46:05.004  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177965000 ms
2022-07-30 11:46:05.004  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177965000 ms.0 from job set of time 1659177965000 ms
2022-07-30 11:46:05.011  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:46:05.011  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:46:05.085  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:46:05.086  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 845 (count at Application.java:147) as input to shuffle 76
2022-07-30 11:46:05.086  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 80 (count at Application.java:147) with 1 output partitions
2022-07-30 11:46:05.086  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 157 (count at Application.java:147)
2022-07-30 11:46:05.086  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 156)
2022-07-30 11:46:05.087  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:46:05.087  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 157 (MapPartitionsRDD[848] at count at Application.java:147), which has no missing parents
2022-07-30 11:46:05.088  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_80 stored as values in memory (estimated size 11.0 KiB, free 896.9 MiB)
2022-07-30 11:46:05.089  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_80_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 896.9 MiB)
2022-07-30 11:46:05.090  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_80_piece0 in memory on host.docker.internal:58598 (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:46:05.090  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 80 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:46:05.091  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 157 (MapPartitionsRDD[848] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:46:05.091  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 157.0 with 1 tasks resource profile 0
2022-07-30 11:46:05.092  INFO   57 --- [er-event-loop-3] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 157.0 (TID 80) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:46:05.092  INFO   57 --- [ 157.0 (TID 80)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 157.0 (TID 80)
2022-07-30 11:46:05.094  INFO   57 --- [ 157.0 (TID 80)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:46:05.094  INFO   57 --- [ 157.0 (TID 80)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-30 11:46:05.095  INFO   57 --- [ 157.0 (TID 80)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 157.0 (TID 80). 2555 bytes result sent to driver
2022-07-30 11:46:05.096  INFO   57 --- [result-getter-3] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 157.0 (TID 80) in 5 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:46:05.096  INFO   57 --- [result-getter-3] org.apache.spark.internal.Logging        : Removed TaskSet 157.0, whose tasks have all completed, from pool 
2022-07-30 11:46:05.096  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 157 (count at Application.java:147) finished in 0.009 s
2022-07-30 11:46:05.097  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 80 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:46:05.097  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 157: Stage finished
2022-07-30 11:46:05.097  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 80 finished: count at Application.java:147, took 0.011291 s
2022-07-30 11:46:05.098  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177965000 ms.0 from job set of time 1659177965000 ms
2022-07-30 11:46:05.098  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 0.098 s for time 1659177965000 ms (execution: 0.094 s)
2022-07-30 11:46:05.099  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 828 from persistence list
2022-07-30 11:46:05.099  INFO   57 --- [c-thread-pool-1] org.apache.spark.internal.Logging        : Removing RDD 828
2022-07-30 11:46:05.099  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 827 from persistence list
2022-07-30 11:46:05.100  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[827] at receiverStream at Application.java:122 of time 1659177965000 ms
2022-07-30 11:46:05.100  INFO   57 --- [c-thread-pool-3] org.apache.spark.internal.Logging        : Removing RDD 827
2022-07-30 11:46:05.101  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177963000 ms
2022-07-30 11:46:05.101  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177963000 ms
2022-07-30 11:46:06.002  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177966000 ms
2022-07-30 11:46:06.003  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177966000 ms.0 from job set of time 1659177966000 ms
2022-07-30 11:46:06.004  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:46:06.004  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:46:06.049  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:46:06.050  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 856 (count at Application.java:147) as input to shuffle 77
2022-07-30 11:46:06.050  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 81 (count at Application.java:147) with 1 output partitions
2022-07-30 11:46:06.051  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 159 (count at Application.java:147)
2022-07-30 11:46:06.051  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 158)
2022-07-30 11:46:06.051  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:46:06.051  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 159 (MapPartitionsRDD[859] at count at Application.java:147), which has no missing parents
2022-07-30 11:46:06.053  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_81 stored as values in memory (estimated size 11.0 KiB, free 896.9 MiB)
2022-07-30 11:46:06.055  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_81_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 896.9 MiB)
2022-07-30 11:46:06.055  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_81_piece0 in memory on host.docker.internal:58598 (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:46:06.056  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 81 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:46:06.056  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 159 (MapPartitionsRDD[859] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:46:06.056  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 159.0 with 1 tasks resource profile 0
2022-07-30 11:46:06.057  INFO   57 --- [er-event-loop-2] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 159.0 (TID 81) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:46:06.058  INFO   57 --- [ 159.0 (TID 81)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 159.0 (TID 81)
2022-07-30 11:46:06.060  INFO   57 --- [ 159.0 (TID 81)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:46:06.060  INFO   57 --- [ 159.0 (TID 81)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-30 11:46:06.061  INFO   57 --- [ 159.0 (TID 81)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 159.0 (TID 81). 2598 bytes result sent to driver
2022-07-30 11:46:06.062  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 159.0 (TID 81) in 5 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:46:06.062  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Removed TaskSet 159.0, whose tasks have all completed, from pool 
2022-07-30 11:46:06.062  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 159 (count at Application.java:147) finished in 0.010 s
2022-07-30 11:46:06.063  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 81 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:46:06.063  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 159: Stage finished
2022-07-30 11:46:06.063  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 81 finished: count at Application.java:147, took 0.013482 s
2022-07-30 11:46:06.064  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177966000 ms.0 from job set of time 1659177966000 ms
2022-07-30 11:46:06.064  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 0.064 s for time 1659177966000 ms (execution: 0.061 s)
2022-07-30 11:46:06.064  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 839 from persistence list
2022-07-30 11:46:06.065  INFO   57 --- [c-thread-pool-4] org.apache.spark.internal.Logging        : Removing RDD 839
2022-07-30 11:46:06.065  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 838 from persistence list
2022-07-30 11:46:06.065  INFO   57 --- [c-thread-pool-6] org.apache.spark.internal.Logging        : Removing RDD 838
2022-07-30 11:46:06.065  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[838] at receiverStream at Application.java:122 of time 1659177966000 ms
2022-07-30 11:46:06.066  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177964000 ms
2022-07-30 11:46:06.066  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177964000 ms
2022-07-30 11:46:07.004  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177967000 ms
2022-07-30 11:46:07.004  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177967000 ms.0 from job set of time 1659177967000 ms
2022-07-30 11:46:07.006  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:46:07.006  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:46:07.072  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:46:07.073  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 867 (count at Application.java:147) as input to shuffle 78
2022-07-30 11:46:07.073  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 82 (count at Application.java:147) with 1 output partitions
2022-07-30 11:46:07.073  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 161 (count at Application.java:147)
2022-07-30 11:46:07.074  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 160)
2022-07-30 11:46:07.074  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:46:07.074  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 161 (MapPartitionsRDD[870] at count at Application.java:147), which has no missing parents
2022-07-30 11:46:07.075  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_82 stored as values in memory (estimated size 11.0 KiB, free 896.8 MiB)
2022-07-30 11:46:07.077  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_82_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 896.8 MiB)
2022-07-30 11:46:07.078  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_82_piece0 in memory on host.docker.internal:58598 (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:46:07.079  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 82 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:46:07.079  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 161 (MapPartitionsRDD[870] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:46:07.079  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 161.0 with 1 tasks resource profile 0
2022-07-30 11:46:07.080  INFO   57 --- [er-event-loop-1] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 161.0 (TID 82) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:46:07.081  INFO   57 --- [ 161.0 (TID 82)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 161.0 (TID 82)
2022-07-30 11:46:07.083  INFO   57 --- [ 161.0 (TID 82)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:46:07.083  INFO   57 --- [ 161.0 (TID 82)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-30 11:46:07.084  INFO   57 --- [ 161.0 (TID 82)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 161.0 (TID 82). 2555 bytes result sent to driver
2022-07-30 11:46:07.085  INFO   57 --- [result-getter-1] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 161.0 (TID 82) in 5 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:46:07.085  INFO   57 --- [result-getter-1] org.apache.spark.internal.Logging        : Removed TaskSet 161.0, whose tasks have all completed, from pool 
2022-07-30 11:46:07.086  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 161 (count at Application.java:147) finished in 0.011 s
2022-07-30 11:46:07.086  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 82 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:46:07.086  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 161: Stage finished
2022-07-30 11:46:07.086  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 82 finished: count at Application.java:147, took 0.013644 s
2022-07-30 11:46:07.087  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177967000 ms.0 from job set of time 1659177967000 ms
2022-07-30 11:46:07.087  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 0.087 s for time 1659177967000 ms (execution: 0.083 s)
2022-07-30 11:46:07.087  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 850 from persistence list
2022-07-30 11:46:07.088  INFO   57 --- [-thread-pool-11] org.apache.spark.internal.Logging        : Removing RDD 850
2022-07-30 11:46:07.088  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 849 from persistence list
2022-07-30 11:46:07.088  INFO   57 --- [-thread-pool-14] org.apache.spark.internal.Logging        : Removing RDD 849
2022-07-30 11:46:07.088  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[849] at receiverStream at Application.java:122 of time 1659177967000 ms
2022-07-30 11:46:07.089  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177965000 ms
2022-07-30 11:46:07.089  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177965000 ms
2022-07-30 11:46:08.005  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177968000 ms
2022-07-30 11:46:08.007  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177968000 ms.0 from job set of time 1659177968000 ms
2022-07-30 11:46:08.008  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:46:08.008  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:46:08.088  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:46:08.088  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 878 (count at Application.java:147) as input to shuffle 79
2022-07-30 11:46:08.089  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 83 (count at Application.java:147) with 1 output partitions
2022-07-30 11:46:08.089  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 163 (count at Application.java:147)
2022-07-30 11:46:08.089  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 162)
2022-07-30 11:46:08.089  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:46:08.089  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 163 (MapPartitionsRDD[881] at count at Application.java:147), which has no missing parents
2022-07-30 11:46:08.091  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_83 stored as values in memory (estimated size 11.0 KiB, free 896.8 MiB)
2022-07-30 11:46:08.093  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_83_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 896.8 MiB)
2022-07-30 11:46:08.094  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_83_piece0 in memory on host.docker.internal:58598 (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:46:08.094  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 83 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:46:08.095  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 163 (MapPartitionsRDD[881] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:46:08.095  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 163.0 with 1 tasks resource profile 0
2022-07-30 11:46:08.096  INFO   57 --- [er-event-loop-2] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 163.0 (TID 83) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:46:08.097  INFO   57 --- [ 163.0 (TID 83)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 163.0 (TID 83)
2022-07-30 11:46:08.100  INFO   57 --- [ 163.0 (TID 83)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:46:08.101  INFO   57 --- [ 163.0 (TID 83)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 1 ms
2022-07-30 11:46:08.102  INFO   57 --- [ 163.0 (TID 83)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 163.0 (TID 83). 2555 bytes result sent to driver
2022-07-30 11:46:08.103  INFO   57 --- [result-getter-2] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 163.0 (TID 83) in 7 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:46:08.103  INFO   57 --- [result-getter-2] org.apache.spark.internal.Logging        : Removed TaskSet 163.0, whose tasks have all completed, from pool 
2022-07-30 11:46:08.104  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 163 (count at Application.java:147) finished in 0.013 s
2022-07-30 11:46:08.104  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 83 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:46:08.104  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 163: Stage finished
2022-07-30 11:46:08.104  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 83 finished: count at Application.java:147, took 0.016201 s
2022-07-30 11:46:08.105  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177968000 ms.0 from job set of time 1659177968000 ms
2022-07-30 11:46:08.105  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 0.105 s for time 1659177968000 ms (execution: 0.099 s)
2022-07-30 11:46:08.105  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 861 from persistence list
2022-07-30 11:46:08.106  INFO   57 --- [-thread-pool-17] org.apache.spark.internal.Logging        : Removing RDD 861
2022-07-30 11:46:08.106  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 860 from persistence list
2022-07-30 11:46:08.107  INFO   57 --- [-thread-pool-21] org.apache.spark.internal.Logging        : Removing RDD 860
2022-07-30 11:46:08.107  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[860] at receiverStream at Application.java:122 of time 1659177968000 ms
2022-07-30 11:46:08.107  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177966000 ms
2022-07-30 11:46:08.107  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177966000 ms
2022-07-30 11:46:09.157  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177969000 ms
2022-07-30 11:46:09.160  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:46:09.161  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:46:09.175  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177969000 ms.0 from job set of time 1659177969000 ms
2022-07-30 11:46:09.273  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:46:09.273  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 889 (count at Application.java:147) as input to shuffle 80
2022-07-30 11:46:09.274  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 84 (count at Application.java:147) with 1 output partitions
2022-07-30 11:46:09.274  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 165 (count at Application.java:147)
2022-07-30 11:46:09.274  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 164)
2022-07-30 11:46:09.274  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:46:09.275  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 165 (MapPartitionsRDD[892] at count at Application.java:147), which has no missing parents
2022-07-30 11:46:09.277  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_84 stored as values in memory (estimated size 11.0 KiB, free 896.8 MiB)
2022-07-30 11:46:09.279  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_84_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 896.8 MiB)
2022-07-30 11:46:09.280  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_84_piece0 in memory on host.docker.internal:58598 (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:46:09.281  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 84 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:46:09.282  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 165 (MapPartitionsRDD[892] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:46:09.282  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 165.0 with 1 tasks resource profile 0
2022-07-30 11:46:09.283  INFO   57 --- [er-event-loop-1] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 165.0 (TID 84) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:46:09.285  INFO   57 --- [ 165.0 (TID 84)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 165.0 (TID 84)
2022-07-30 11:46:09.296  INFO   57 --- [ 165.0 (TID 84)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:46:09.296  INFO   57 --- [ 165.0 (TID 84)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-30 11:46:09.299  INFO   57 --- [ 165.0 (TID 84)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 165.0 (TID 84). 2598 bytes result sent to driver
2022-07-30 11:46:09.300  INFO   57 --- [result-getter-3] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 165.0 (TID 84) in 17 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:46:09.305  INFO   57 --- [result-getter-3] org.apache.spark.internal.Logging        : Removed TaskSet 165.0, whose tasks have all completed, from pool 
2022-07-30 11:46:09.306  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 165 (count at Application.java:147) finished in 0.029 s
2022-07-30 11:46:09.306  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 84 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:46:09.309  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 165: Stage finished
2022-07-30 11:46:09.310  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 84 finished: count at Application.java:147, took 0.036838 s
2022-07-30 11:46:09.311  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177969000 ms.0 from job set of time 1659177969000 ms
2022-07-30 11:46:09.311  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 0.311 s for time 1659177969000 ms (execution: 0.136 s)
2022-07-30 11:46:09.312  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 872 from persistence list
2022-07-30 11:46:09.313  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 871 from persistence list
2022-07-30 11:46:09.314  INFO   57 --- [-thread-pool-20] org.apache.spark.internal.Logging        : Removing RDD 872
2022-07-30 11:46:09.315  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[871] at receiverStream at Application.java:122 of time 1659177969000 ms
2022-07-30 11:46:09.316  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177967000 ms
2022-07-30 11:46:09.316  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177967000 ms
2022-07-30 11:46:09.316  INFO   57 --- [-thread-pool-26] org.apache.spark.internal.Logging        : Removing RDD 871
2022-07-30 11:46:09.396  INFO   57 --- [shutdown-hook-0] org.apache.spark.internal.Logging        : Invoking stop(stopGracefully=false) from shutdown hook
2022-07-30 11:46:09.476  INFO   57 --- [er-event-loop-0] org.apache.spark.internal.Logging        : Sent stop signal to all 1 receivers
2022-07-30 11:46:09.478  INFO   57 --- [er-event-loop-0] org.apache.spark.internal.Logging        : Received stop signal
2022-07-30 11:46:09.481  INFO   57 --- [er-event-loop-0] org.apache.spark.internal.Logging        : Stopping receiver with message: Stopped by driver: 
2022-07-30 11:46:09.482  INFO   57 --- [er-event-loop-0] org.apache.spark.internal.Logging        : Called receiver onStop
2022-07-30 11:46:09.485  INFO   57 --- [er-event-loop-0] org.apache.spark.internal.Logging        : Deregistering receiver 0
2022-07-30 11:46:09.488  ERROR   73 --- [er-event-loop-2] org.apache.spark.internal.Logging        : Deregistered receiver for stream 0: Stopped by driver
2022-07-30 11:46:09.489  INFO   57 --- [er-event-loop-0] org.apache.spark.internal.Logging        : Stopped receiver 0
2022-07-30 11:46:09.523  INFO   57 --- [er-event-loop-0] org.apache.spark.internal.Logging        : Stopping BlockGenerator
2022-07-30 11:46:09.811  INFO   57 --- [er-event-loop-0] org.apache.spark.internal.Logging        : Stopped timer for BlockGenerator after time 1659177969800
2022-07-30 11:46:09.812  INFO   57 --- [er-event-loop-0] org.apache.spark.internal.Logging        : Waiting for block pushing thread to terminate
2022-07-30 11:46:09.818  INFO   57 --- [      Thread-14] org.apache.spark.internal.Logging        : Pushing out the last 0 blocks
2022-07-30 11:46:09.820  INFO   57 --- [      Thread-14] org.apache.spark.internal.Logging        : Stopped block pushing thread
2022-07-30 11:46:09.820  INFO   57 --- [er-event-loop-0] org.apache.spark.internal.Logging        : Stopped BlockGenerator
2022-07-30 11:46:09.941  INFO   57 --- [age 0.0 (TID 0)] org.apache.spark.internal.Logging        : Stopped receiver without error
2022-07-30 11:46:09.944  INFO   57 --- [age 0.0 (TID 0)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 0.0 (TID 0). 923 bytes result sent to driver
2022-07-30 11:46:09.947  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 0.0 (TID 0) in 80830 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:46:09.948  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Removed TaskSet 0.0, whose tasks have all completed, from pool 
2022-07-30 11:46:09.950  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 0 (start at Application.java:156) finished in 81.559 s
2022-07-30 11:46:09.951  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:46:09.951  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 0: Stage finished
2022-07-30 11:46:09.957  INFO   57 --- [shutdown-hook-0] org.apache.spark.internal.Logging        : All of the receivers have deregistered successfully
2022-07-30 11:46:09.959  INFO   57 --- [shutdown-hook-0] org.apache.spark.internal.Logging        : ReceiverTracker stopped
2022-07-30 11:46:09.961  INFO   57 --- [shutdown-hook-0] org.apache.spark.internal.Logging        : Stopping JobGenerator immediately
2022-07-30 11:46:09.965  INFO   57 --- [shutdown-hook-0] org.apache.spark.internal.Logging        : Stopped timer for JobGenerator after time 1659177969000
2022-07-30 11:46:09.970  INFO   57 --- [shutdown-hook-0] org.apache.spark.internal.Logging        : Stopped JobGenerator
2022-07-30 11:46:09.980  INFO   57 --- [shutdown-hook-0] org.apache.spark.internal.Logging        : Stopped JobScheduler
2022-07-30 11:46:10.088  INFO 1153 --- [shutdown-hook-0] ject.jetty.server.handler.ContextHandler : Stopped o.s.j.s.ServletContextHandler@6972c30a{/streaming,null,STOPPED,@Spark}
2022-07-30 11:46:10.090  INFO 1153 --- [shutdown-hook-0] ject.jetty.server.handler.ContextHandler : Stopped o.s.j.s.ServletContextHandler@1ab6718{/streaming/json,null,STOPPED,@Spark}
2022-07-30 11:46:10.091  INFO 1153 --- [shutdown-hook-0] ject.jetty.server.handler.ContextHandler : Stopped o.s.j.s.ServletContextHandler@5109e8cf{/streaming/batch,null,STOPPED,@Spark}
2022-07-30 11:46:10.092  INFO 1153 --- [shutdown-hook-0] ject.jetty.server.handler.ContextHandler : Stopped o.s.j.s.ServletContextHandler@78b41097{/streaming/batch/json,null,STOPPED,@Spark}
2022-07-30 11:46:10.095  INFO 1153 --- [shutdown-hook-0] ject.jetty.server.handler.ContextHandler : Stopped o.s.j.s.ServletContextHandler@6c65860d{/static/streaming,null,STOPPED,@Spark}
2022-07-30 11:46:10.098  INFO  167 --- [           main] com.elite.cdr.validator.Application      : ****************************************************
2022-07-30 11:46:10.098  INFO   57 --- [shutdown-hook-0] org.apache.spark.internal.Logging        : StreamingContext stopped successfully
2022-07-30 11:46:10.098  INFO  168 --- [           main] com.elite.cdr.validator.Application      : Duration: 0.0 seconds
2022-07-30 11:46:10.098  INFO  169 --- [           main] com.elite.cdr.validator.Application      : Batch executed with success
2022-07-30 11:46:10.098  INFO  170 --- [           main] com.elite.cdr.validator.Application      : ****************************************************
2022-07-30 11:46:10.098  INFO   57 --- [shutdown-hook-0] org.apache.spark.internal.Logging        : Invoking stop() from shutdown hook
2022-07-30 11:46:10.248  INFO  381 --- [shutdown-hook-0] rkproject.jetty.server.AbstractConnector : Stopped Spark@2c715e84{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2022-07-30 11:46:10.281  INFO   57 --- [shutdown-hook-0] org.apache.spark.internal.Logging        : Stopped Spark web UI at http://host.docker.internal:4040
2022-07-30 11:46:10.415  INFO   57 --- [er-event-loop-2] org.apache.spark.internal.Logging        : MapOutputTrackerMasterEndpoint stopped!
2022-07-30 11:46:11.201  INFO   57 --- [shutdown-hook-0] org.apache.spark.internal.Logging        : MemoryStore cleared
2022-07-30 11:46:11.204  INFO   57 --- [shutdown-hook-0] org.apache.spark.internal.Logging        : BlockManager stopped
2022-07-30 11:46:11.265  INFO   57 --- [shutdown-hook-0] org.apache.spark.internal.Logging        : BlockManagerMaster stopped
2022-07-30 11:46:11.303  INFO   57 --- [er-event-loop-2] org.apache.spark.internal.Logging        : OutputCommitCoordinator stopped!
2022-07-30 11:46:11.321  INFO   57 --- [shutdown-hook-0] org.apache.spark.internal.Logging        : Successfully stopped SparkContext
2022-07-30 11:46:11.322  INFO   57 --- [shutdown-hook-0] org.apache.spark.internal.Logging        : Shutdown hook called
2022-07-30 11:46:11.323  INFO   57 --- [shutdown-hook-0] org.apache.spark.internal.Logging        : Deleting directory C:\Users\Wael Hamdi\AppData\Local\Temp\spark-384afd6e-5581-401d-ac74-60bbe2b5e655
