2022-07-30 11:41:28.057  INFO   48 --- [           main] com.elite.cdr.validator.Application      : Starting ASN1 Reader 
2022-07-30 11:41:28.062  INFO   50 --- [           main] com.elite.cdr.validator.Application      : ############### Run with the args [--env, local, --file, src/main/resources/data/simpleTypes.ber, --prop, src/main/resources/myapp.properties]
2022-07-30 11:41:28.170  INFO   56 --- [           main] com.elite.cdr.validator.Application      : ############### Run in local mode
2022-07-30 11:41:33.618  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Running Spark version 3.2.1
2022-07-30 11:41:34.278  INFO   57 --- [           main] org.apache.spark.internal.Logging        : ==============================================================
2022-07-30 11:41:34.285  INFO   57 --- [           main] org.apache.spark.internal.Logging        : No custom resources configured for spark.driver.
2022-07-30 11:41:34.286  INFO   57 --- [           main] org.apache.spark.internal.Logging        : ==============================================================
2022-07-30 11:41:34.288  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Submitted application: NiFi Spark Streaming example
2022-07-30 11:41:34.601  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2022-07-30 11:41:34.629  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Limiting resource is cpu
2022-07-30 11:41:34.636  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Added ResourceProfile id: 0
2022-07-30 11:41:35.134  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Changing view acls to: Wael Hamdi
2022-07-30 11:41:35.135  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Changing modify acls to: Wael Hamdi
2022-07-30 11:41:35.136  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Changing view acls groups to: 
2022-07-30 11:41:35.137  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Changing modify acls groups to: 
2022-07-30 11:41:35.140  INFO   57 --- [           main] org.apache.spark.internal.Logging        : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Wael Hamdi); groups with view permissions: Set(); users  with modify permissions: Set(Wael Hamdi); groups with modify permissions: Set()
2022-07-30 11:41:41.886  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Successfully started service 'sparkDriver' on port 58140.
2022-07-30 11:41:42.214  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Registering MapOutputTracker
2022-07-30 11:41:42.652  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Registering BlockManagerMaster
2022-07-30 11:41:42.769  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2022-07-30 11:41:42.771  INFO   57 --- [           main] org.apache.spark.internal.Logging        : BlockManagerMasterEndpoint up
2022-07-30 11:41:42.779  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Registering BlockManagerMasterHeartbeat
2022-07-30 11:41:43.094  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Created local directory at C:\Users\Wael Hamdi\AppData\Local\Temp\blockmgr-eccab35a-e88a-49d3-8628-14850dfe14da
2022-07-30 11:41:43.172  INFO   57 --- [           main] org.apache.spark.internal.Logging        : MemoryStore started with capacity 897.6 MiB
2022-07-30 11:41:43.297  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Registering OutputCommitCoordinator
2022-07-30 11:41:43.809  INFO  170 --- [           main] org.sparkproject.jetty.util.log.Log      : Logging initialized @17916ms to org.sparkproject.jetty.util.log.Slf4jLog
2022-07-30 11:41:44.226  INFO  375 --- [           main] org.sparkproject.jetty.server.Server     : jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_301-b09
2022-07-30 11:41:44.297  INFO  415 --- [           main] org.sparkproject.jetty.server.Server     : Started @18406ms
2022-07-30 11:41:44.368  INFO  331 --- [           main] rkproject.jetty.server.AbstractConnector : Started ServerConnector@3b9d6699{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2022-07-30 11:41:44.369  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Successfully started service 'SparkUI' on port 4040.
2022-07-30 11:41:44.408  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@e6516e{/jobs,null,AVAILABLE,@Spark}
2022-07-30 11:41:44.411  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@db44aa2{/jobs/json,null,AVAILABLE,@Spark}
2022-07-30 11:41:44.413  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3f093abe{/jobs/job,null,AVAILABLE,@Spark}
2022-07-30 11:41:44.415  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@780ec4a5{/jobs/job/json,null,AVAILABLE,@Spark}
2022-07-30 11:41:44.417  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6f70f32f{/stages,null,AVAILABLE,@Spark}
2022-07-30 11:41:44.418  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5aabbb29{/stages/json,null,AVAILABLE,@Spark}
2022-07-30 11:41:44.420  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1ac85b0c{/stages/stage,null,AVAILABLE,@Spark}
2022-07-30 11:41:44.422  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@59a67c3a{/stages/stage/json,null,AVAILABLE,@Spark}
2022-07-30 11:41:44.423  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@724bade8{/stages/pool,null,AVAILABLE,@Spark}
2022-07-30 11:41:44.425  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6bc248ed{/stages/pool/json,null,AVAILABLE,@Spark}
2022-07-30 11:41:44.426  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@ca27722{/storage,null,AVAILABLE,@Spark}
2022-07-30 11:41:44.427  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@9573b3b{/storage/json,null,AVAILABLE,@Spark}
2022-07-30 11:41:44.429  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@78461bc4{/storage/rdd,null,AVAILABLE,@Spark}
2022-07-30 11:41:44.432  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@64f857e7{/storage/rdd/json,null,AVAILABLE,@Spark}
2022-07-30 11:41:44.434  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@58c540cf{/environment,null,AVAILABLE,@Spark}
2022-07-30 11:41:44.436  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1b822fcc{/environment/json,null,AVAILABLE,@Spark}
2022-07-30 11:41:44.437  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@56102e1c{/executors,null,AVAILABLE,@Spark}
2022-07-30 11:41:44.439  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7927bd9f{/executors/json,null,AVAILABLE,@Spark}
2022-07-30 11:41:44.441  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@410954b{/executors/threadDump,null,AVAILABLE,@Spark}
2022-07-30 11:41:44.443  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3b366632{/executors/threadDump/json,null,AVAILABLE,@Spark}
2022-07-30 11:41:44.458  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@514eedd8{/static,null,AVAILABLE,@Spark}
2022-07-30 11:41:44.460  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@687a762c{/,null,AVAILABLE,@Spark}
2022-07-30 11:41:44.464  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@733c423e{/api,null,AVAILABLE,@Spark}
2022-07-30 11:41:44.467  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@55e7a35c{/jobs/job/kill,null,AVAILABLE,@Spark}
2022-07-30 11:41:44.469  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5922ae77{/stages/stage/kill,null,AVAILABLE,@Spark}
2022-07-30 11:41:44.472  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Bound SparkUI to 0.0.0.0, and started at http://host.docker.internal:4040
2022-07-30 11:41:44.966  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Starting executor ID driver on host host.docker.internal
2022-07-30 11:41:45.211  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 58170.
2022-07-30 11:41:45.211  INFO   82 --- [           main] .network.netty.NettyBlockTransferService : Server created on host.docker.internal:58170
2022-07-30 11:41:45.220  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2022-07-30 11:41:45.252  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Registering BlockManager BlockManagerId(driver, host.docker.internal, 58170, None)
2022-07-30 11:41:45.258  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Registering block manager host.docker.internal:58170 with 897.6 MiB RAM, BlockManagerId(driver, host.docker.internal, 58170, None)
2022-07-30 11:41:45.268  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Registered BlockManager BlockManagerId(driver, host.docker.internal, 58170, None)
2022-07-30 11:41:45.270  INFO   57 --- [           main] org.apache.spark.internal.Logging        : Initialized BlockManager: BlockManagerId(driver, host.docker.internal, 58170, None)
2022-07-30 11:41:45.732  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@56781d96{/metrics/json,null,AVAILABLE,@Spark}
2022-07-30 11:41:48.333  INFO   57 --- [streaming-start] org.apache.spark.internal.Logging        : Starting 1 receivers
2022-07-30 11:41:48.338  INFO   57 --- [streaming-start] org.apache.spark.internal.Logging        : ReceiverTracker started
2022-07-30 11:41:48.349  INFO   57 --- [streaming-start] org.apache.spark.internal.Logging        : Slide time = 1000 ms
2022-07-30 11:41:48.350  INFO   57 --- [streaming-start] org.apache.spark.internal.Logging        : Storage level = Serialized 1x Replicated
2022-07-30 11:41:48.351  INFO   57 --- [streaming-start] org.apache.spark.internal.Logging        : Checkpoint interval = null
2022-07-30 11:41:48.352  INFO   57 --- [streaming-start] org.apache.spark.internal.Logging        : Remember interval = 1000 ms
2022-07-30 11:41:48.353  INFO   57 --- [streaming-start] org.apache.spark.internal.Logging        : Initialized and validated org.apache.spark.streaming.dstream.PluggableInputDStream@3adbc19e
2022-07-30 11:41:48.354  INFO   57 --- [streaming-start] org.apache.spark.internal.Logging        : Slide time = 1000 ms
2022-07-30 11:41:48.354  INFO   57 --- [streaming-start] org.apache.spark.internal.Logging        : Storage level = Serialized 1x Replicated
2022-07-30 11:41:48.354  INFO   57 --- [streaming-start] org.apache.spark.internal.Logging        : Checkpoint interval = null
2022-07-30 11:41:48.355  INFO   57 --- [streaming-start] org.apache.spark.internal.Logging        : Remember interval = 1000 ms
2022-07-30 11:41:48.355  INFO   57 --- [streaming-start] org.apache.spark.internal.Logging        : Initialized and validated org.apache.spark.streaming.dstream.MappedDStream@4d1336a1
2022-07-30 11:41:48.355  INFO   57 --- [streaming-start] org.apache.spark.internal.Logging        : Slide time = 1000 ms
2022-07-30 11:41:48.356  INFO   57 --- [streaming-start] org.apache.spark.internal.Logging        : Storage level = Serialized 1x Replicated
2022-07-30 11:41:48.356  INFO   57 --- [streaming-start] org.apache.spark.internal.Logging        : Checkpoint interval = null
2022-07-30 11:41:48.356  INFO   57 --- [streaming-start] org.apache.spark.internal.Logging        : Remember interval = 1000 ms
2022-07-30 11:41:48.357  INFO   57 --- [streaming-start] org.apache.spark.internal.Logging        : Initialized and validated org.apache.spark.streaming.dstream.ForEachDStream@275734be
2022-07-30 11:41:48.763  INFO   57 --- [er-event-loop-3] org.apache.spark.internal.Logging        : Receiver 0 started
2022-07-30 11:41:48.775  INFO   57 --- [streaming-start] org.apache.spark.internal.Logging        : Started timer for JobGenerator at time 1659177709000
2022-07-30 11:41:48.777  INFO   57 --- [streaming-start] org.apache.spark.internal.Logging        : Started JobGenerator at 1659177709000 ms
2022-07-30 11:41:48.781  INFO   57 --- [streaming-start] org.apache.spark.internal.Logging        : Started JobScheduler
2022-07-30 11:41:48.784  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 0 (start at Application.java:156) with 1 output partitions
2022-07-30 11:41:48.786  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 0 (start at Application.java:156)
2022-07-30 11:41:48.787  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List()
2022-07-30 11:41:48.788  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3910fe11{/streaming,null,AVAILABLE,@Spark}
2022-07-30 11:41:48.789  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@351e414e{/streaming/json,null,AVAILABLE,@Spark}
2022-07-30 11:41:48.791  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2c2db130{/streaming/batch,null,AVAILABLE,@Spark}
2022-07-30 11:41:48.793  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@348d18a3{/streaming/batch/json,null,AVAILABLE,@Spark}
2022-07-30 11:41:48.796  INFO  915 --- [           main] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@20e6c4dc{/static/streaming,null,AVAILABLE,@Spark}
2022-07-30 11:41:48.797  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:41:48.797  INFO   57 --- [           main] org.apache.spark.internal.Logging        : StreamingContext started
2022-07-30 11:41:48.803  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 0 (Receiver 0 ParallelCollectionRDD[0] at makeRDD at ReceiverTracker.scala:609), which has no missing parents
2022-07-30 11:41:49.254  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177709000 ms
2022-07-30 11:41:49.258  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177709000 ms.0 from job set of time 1659177709000 ms
2022-07-30 11:41:49.684  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_0 stored as values in memory (estimated size 97.5 KiB, free 897.5 MiB)
2022-07-30 11:41:49.741  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkContext; some configuration may not take effect.
2022-07-30 11:41:50.006  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177710000 ms
2022-07-30 11:41:50.748  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_0_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 897.5 MiB)
2022-07-30 11:41:50.754  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_0_piece0 in memory on host.docker.internal:58170 (size: 34.2 KiB, free: 897.6 MiB)
2022-07-30 11:41:50.779  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 0 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:41:50.834  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 0 (Receiver 0 ParallelCollectionRDD[0] at makeRDD at ReceiverTracker.scala:609) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:41:50.836  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 0.0 with 1 tasks resource profile 0
2022-07-30 11:41:51.010  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177711000 ms
2022-07-30 11:41:51.353  INFO   57 --- [er-event-loop-0] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 0.0 (TID 0) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 5950 bytes) taskResourceAssignments Map()
2022-07-30 11:41:51.552  INFO   57 --- [age 0.0 (TID 0)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 0.0 (TID 0)
2022-07-30 11:41:52.004  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177712000 ms
2022-07-30 11:41:52.123  INFO   57 --- [age 0.0 (TID 0)] org.apache.spark.internal.Logging        : Started timer for BlockGenerator at time 1659177712200
2022-07-30 11:41:52.126  INFO   57 --- [age 0.0 (TID 0)] org.apache.spark.internal.Logging        : Started BlockGenerator
2022-07-30 11:41:52.126  INFO   57 --- [      Thread-14] org.apache.spark.internal.Logging        : Started block pushing thread
2022-07-30 11:41:52.180  INFO   57 --- [er-event-loop-0] org.apache.spark.internal.Logging        : Registered receiver for stream 0 from host.docker.internal:58140
2022-07-30 11:41:52.183  INFO   57 --- [age 0.0 (TID 0)] org.apache.spark.internal.Logging        : Starting receiver 0
2022-07-30 11:41:52.202  INFO   57 --- [age 0.0 (TID 0)] org.apache.spark.internal.Logging        : Called receiver 0 onStart
2022-07-30 11:41:52.204  INFO   57 --- [age 0.0 (TID 0)] org.apache.spark.internal.Logging        : Waiting for receiver to be stopped
2022-07-30 11:41:52.789  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2022-07-30 11:41:53.004  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177713000 ms
2022-07-30 11:41:53.730  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Warehouse path is 'file:/C:/IntelliJProjects/NifiSparkStreaming/spark-warehouse'.
2022-07-30 11:41:53.817  INFO  915 --- [-job-executor-0] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7ab35b31{/SQL,null,AVAILABLE,@Spark}
2022-07-30 11:41:53.819  INFO  915 --- [-job-executor-0] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@329be101{/SQL/json,null,AVAILABLE,@Spark}
2022-07-30 11:41:53.822  INFO  915 --- [-job-executor-0] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@65451262{/SQL/execution,null,AVAILABLE,@Spark}
2022-07-30 11:41:53.824  INFO  915 --- [-job-executor-0] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7b45f1a4{/SQL/execution/json,null,AVAILABLE,@Spark}
2022-07-30 11:41:53.827  INFO  915 --- [-job-executor-0] ject.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7b002bfe{/static/sql,null,AVAILABLE,@Spark}
2022-07-30 11:41:54.003  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177714000 ms
2022-07-30 11:41:55.004  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177715000 ms
2022-07-30 11:41:55.995  INFO  571 --- [ool Maintenance] g.apache.nifi.remote.client.PeerSelector : Successfully refreshed peer status cache; remote group consists of 1 peers
2022-07-30 11:41:55.995  INFO  571 --- [  NiFi Receiver] g.apache.nifi.remote.client.PeerSelector : Successfully refreshed peer status cache; remote group consists of 1 peers
2022-07-30 11:41:56.038  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177716000 ms
2022-07-30 11:41:57.004  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177717000 ms
2022-07-30 11:41:57.573  INFO   57 --- [  NiFi Receiver] org.apache.spark.internal.Logging        : Block input-0-1659177712094 stored as values in memory (estimated size 55.9 MiB, free 841.6 MiB)
2022-07-30 11:41:57.575  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added input-0-1659177712094 in memory on host.docker.internal:58170 (size: 55.9 MiB, free: 841.7 MiB)
2022-07-30 11:41:58.041  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177718000 ms
2022-07-30 11:41:59.002  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177719000 ms
2022-07-30 11:42:00.003  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177720000 ms
2022-07-30 11:42:01.003  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177721000 ms
2022-07-30 11:42:02.005  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177722000 ms
2022-07-30 11:42:03.004  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177723000 ms
2022-07-30 11:42:03.163  WARN   69 --- [ver-heartbeater] org.apache.spark.internal.Logging        : Exception when trying to compute pagesize, as a result reporting of ProcessTree metrics is stopped
2022-07-30 11:42:04.002  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177724000 ms
2022-07-30 11:42:05.012  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177725000 ms
2022-07-30 11:42:05.837  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Code generated in 459.1886 ms
2022-07-30 11:42:06.004  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177726000 ms
2022-07-30 11:42:06.316  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Code generated in 22.5211 ms
2022-07-30 11:42:06.376  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Code generated in 17.4648 ms
2022-07-30 11:42:06.539  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:42:06.546  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 42 (count at Application.java:147) as input to shuffle 0
2022-07-30 11:42:06.552  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 1 (count at Application.java:147) with 1 output partitions
2022-07-30 11:42:06.552  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 2 (count at Application.java:147)
2022-07-30 11:42:06.552  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 1)
2022-07-30 11:42:06.554  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:42:06.555  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 2 (MapPartitionsRDD[45] at count at Application.java:147), which has no missing parents
2022-07-30 11:42:06.566  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_1 stored as values in memory (estimated size 11.0 KiB, free 841.6 MiB)
2022-07-30 11:42:06.570  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 841.6 MiB)
2022-07-30 11:42:06.571  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_1_piece0 in memory on host.docker.internal:58170 (size: 5.4 KiB, free: 841.7 MiB)
2022-07-30 11:42:06.572  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 1 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:42:06.573  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[45] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:42:06.573  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 2.0 with 1 tasks resource profile 0
2022-07-30 11:42:06.575  INFO   57 --- [er-event-loop-0] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 2.0 (TID 1) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:42:06.577  INFO   57 --- [age 2.0 (TID 1)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 2.0 (TID 1)
2022-07-30 11:42:06.874  INFO   57 --- [age 2.0 (TID 1)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:42:06.883  INFO   57 --- [age 2.0 (TID 1)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 26 ms
2022-07-30 11:42:06.935  INFO   57 --- [age 2.0 (TID 1)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 2.0 (TID 1). 2684 bytes result sent to driver
2022-07-30 11:42:06.948  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 2.0 (TID 1) in 373 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:42:06.951  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Removed TaskSet 2.0, whose tasks have all completed, from pool 
2022-07-30 11:42:06.972  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 2 (count at Application.java:147) finished in 0.407 s
2022-07-30 11:42:06.980  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:42:06.981  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 2: Stage finished
2022-07-30 11:42:06.984  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 1 finished: count at Application.java:147, took 0.444298 s
2022-07-30 11:42:06.996  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177709000 ms.0 from job set of time 1659177709000 ms
2022-07-30 11:42:06.998  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 17.995 s for time 1659177709000 ms (execution: 17.738 s)
2022-07-30 11:42:07.010  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177710000 ms.0 from job set of time 1659177710000 ms
2022-07-30 11:42:07.016  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:42:07.017  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:42:07.026  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 
2022-07-30 11:42:07.030  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 
2022-07-30 11:42:07.036  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177727000 ms
2022-07-30 11:42:07.096  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_1_piece0 on host.docker.internal:58170 in memory (size: 5.4 KiB, free: 841.7 MiB)
2022-07-30 11:42:07.221  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:42:07.223  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 53 (count at Application.java:147) as input to shuffle 1
2022-07-30 11:42:07.224  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 2 (count at Application.java:147) with 1 output partitions
2022-07-30 11:42:07.224  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 4 (count at Application.java:147)
2022-07-30 11:42:07.224  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 3)
2022-07-30 11:42:07.225  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:42:07.226  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 4 (MapPartitionsRDD[56] at count at Application.java:147), which has no missing parents
2022-07-30 11:42:07.230  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_2 stored as values in memory (estimated size 11.0 KiB, free 841.6 MiB)
2022-07-30 11:42:07.234  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 841.6 MiB)
2022-07-30 11:42:07.235  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_2_piece0 in memory on host.docker.internal:58170 (size: 5.4 KiB, free: 841.7 MiB)
2022-07-30 11:42:07.236  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 2 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:42:07.238  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[56] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:42:07.238  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 4.0 with 1 tasks resource profile 0
2022-07-30 11:42:07.240  INFO   57 --- [er-event-loop-3] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 4.0 (TID 2) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:42:07.241  INFO   57 --- [age 4.0 (TID 2)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 4.0 (TID 2)
2022-07-30 11:42:07.247  INFO   57 --- [age 4.0 (TID 2)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:42:07.248  INFO   57 --- [age 4.0 (TID 2)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-30 11:42:07.250  INFO   57 --- [age 4.0 (TID 2)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 4.0 (TID 2). 2598 bytes result sent to driver
2022-07-30 11:42:07.254  INFO   57 --- [result-getter-1] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 4.0 (TID 2) in 15 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:42:07.255  INFO   57 --- [result-getter-1] org.apache.spark.internal.Logging        : Removed TaskSet 4.0, whose tasks have all completed, from pool 
2022-07-30 11:42:07.256  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 4 (count at Application.java:147) finished in 0.029 s
2022-07-30 11:42:07.256  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:42:07.257  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 4: Stage finished
2022-07-30 11:42:07.257  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 2 finished: count at Application.java:147, took 0.035331 s
2022-07-30 11:42:07.259  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177710000 ms.0 from job set of time 1659177710000 ms
2022-07-30 11:42:07.259  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 17.259 s for time 1659177710000 ms (execution: 0.249 s)
2022-07-30 11:42:07.260  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177711000 ms.0 from job set of time 1659177711000 ms
2022-07-30 11:42:07.263  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 2 from persistence list
2022-07-30 11:42:07.264  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:42:07.264  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:42:07.271  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 1 from persistence list
2022-07-30 11:42:07.274  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[1] at receiverStream at Application.java:122 of time 1659177710000 ms
2022-07-30 11:42:07.276  INFO   57 --- [c-thread-pool-3] org.apache.spark.internal.Logging        : Removing RDD 2
2022-07-30 11:42:07.277  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 
2022-07-30 11:42:07.277  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 
2022-07-30 11:42:07.276  INFO   57 --- [c-thread-pool-4] org.apache.spark.internal.Logging        : Removing RDD 1
2022-07-30 11:42:07.471  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:42:07.476  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 62 (count at Application.java:147) as input to shuffle 2
2022-07-30 11:42:07.477  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 3 (count at Application.java:147) with 1 output partitions
2022-07-30 11:42:07.477  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 6 (count at Application.java:147)
2022-07-30 11:42:07.478  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 5)
2022-07-30 11:42:07.478  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:42:07.481  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 6 (MapPartitionsRDD[65] at count at Application.java:147), which has no missing parents
2022-07-30 11:42:07.491  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_3 stored as values in memory (estimated size 11.0 KiB, free 841.6 MiB)
2022-07-30 11:42:07.529  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_3_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 841.5 MiB)
2022-07-30 11:42:07.530  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_3_piece0 in memory on host.docker.internal:58170 (size: 5.4 KiB, free: 841.7 MiB)
2022-07-30 11:42:07.531  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 3 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:42:07.532  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[65] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:42:07.533  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 6.0 with 1 tasks resource profile 0
2022-07-30 11:42:07.537  INFO   57 --- [er-event-loop-2] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 6.0 (TID 3) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:42:07.538  INFO   57 --- [age 6.0 (TID 3)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 6.0 (TID 3)
2022-07-30 11:42:07.553  INFO   57 --- [age 6.0 (TID 3)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:42:07.554  INFO   57 --- [age 6.0 (TID 3)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 1 ms
2022-07-30 11:42:07.557  INFO   57 --- [age 6.0 (TID 3)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 6.0 (TID 3). 2598 bytes result sent to driver
2022-07-30 11:42:07.560  INFO   57 --- [result-getter-2] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 6.0 (TID 3) in 24 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:42:07.560  INFO   57 --- [result-getter-2] org.apache.spark.internal.Logging        : Removed TaskSet 6.0, whose tasks have all completed, from pool 
2022-07-30 11:42:07.564  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 6 (count at Application.java:147) finished in 0.080 s
2022-07-30 11:42:07.565  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:42:07.566  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 6: Stage finished
2022-07-30 11:42:07.572  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 3 finished: count at Application.java:147, took 0.100365 s
2022-07-30 11:42:07.580  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177711000 ms.0 from job set of time 1659177711000 ms
2022-07-30 11:42:07.581  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 16.580 s for time 1659177711000 ms (execution: 0.320 s)
2022-07-30 11:42:07.581  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177712000 ms.0 from job set of time 1659177712000 ms
2022-07-30 11:42:07.582  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 5 from persistence list
2022-07-30 11:42:07.584  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:42:07.585  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:42:07.589  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 4 from persistence list
2022-07-30 11:42:07.593  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[4] at receiverStream at Application.java:122 of time 1659177711000 ms
2022-07-30 11:42:07.593  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177709000 ms
2022-07-30 11:42:07.597  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177709000 ms
2022-07-30 11:42:07.605  INFO   57 --- [-thread-pool-10] org.apache.spark.internal.Logging        : Removing RDD 4
2022-07-30 11:42:07.605  INFO   57 --- [c-thread-pool-9] org.apache.spark.internal.Logging        : Removing RDD 5
2022-07-30 11:42:07.832  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:42:07.834  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 71 (count at Application.java:147) as input to shuffle 3
2022-07-30 11:42:07.835  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 4 (count at Application.java:147) with 1 output partitions
2022-07-30 11:42:07.835  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 8 (count at Application.java:147)
2022-07-30 11:42:07.835  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 7)
2022-07-30 11:42:07.836  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:42:07.838  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 8 (MapPartitionsRDD[74] at count at Application.java:147), which has no missing parents
2022-07-30 11:42:07.843  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_4 stored as values in memory (estimated size 11.0 KiB, free 841.5 MiB)
2022-07-30 11:42:07.851  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_4_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 841.5 MiB)
2022-07-30 11:42:07.853  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_4_piece0 in memory on host.docker.internal:58170 (size: 5.4 KiB, free: 841.7 MiB)
2022-07-30 11:42:07.854  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 4 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:42:07.855  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[74] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:42:07.855  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 8.0 with 1 tasks resource profile 0
2022-07-30 11:42:07.856  INFO   57 --- [er-event-loop-1] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 8.0 (TID 4) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:42:07.857  INFO   57 --- [age 8.0 (TID 4)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 8.0 (TID 4)
2022-07-30 11:42:07.873  INFO   57 --- [age 8.0 (TID 4)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:42:07.874  INFO   57 --- [age 8.0 (TID 4)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-30 11:42:07.876  INFO   57 --- [age 8.0 (TID 4)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 8.0 (TID 4). 2598 bytes result sent to driver
2022-07-30 11:42:07.881  INFO   57 --- [result-getter-3] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 8.0 (TID 4) in 25 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:42:07.882  INFO   57 --- [result-getter-3] org.apache.spark.internal.Logging        : Removed TaskSet 8.0, whose tasks have all completed, from pool 
2022-07-30 11:42:07.882  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 8 (count at Application.java:147) finished in 0.042 s
2022-07-30 11:42:07.883  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:42:07.883  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 8: Stage finished
2022-07-30 11:42:07.884  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 4 finished: count at Application.java:147, took 0.050808 s
2022-07-30 11:42:07.885  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177712000 ms.0 from job set of time 1659177712000 ms
2022-07-30 11:42:07.886  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 15.885 s for time 1659177712000 ms (execution: 0.304 s)
2022-07-30 11:42:07.886  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177713000 ms.0 from job set of time 1659177713000 ms
2022-07-30 11:42:07.887  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 7 from persistence list
2022-07-30 11:42:07.889  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 6 from persistence list
2022-07-30 11:42:07.890  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:42:07.890  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:42:07.893  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[6] at receiverStream at Application.java:122 of time 1659177712000 ms
2022-07-30 11:42:07.893  INFO   57 --- [-thread-pool-16] org.apache.spark.internal.Logging        : Removing RDD 6
2022-07-30 11:42:07.893  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177710000 ms
2022-07-30 11:42:07.897  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177710000 ms
2022-07-30 11:42:07.893  INFO   57 --- [-thread-pool-15] org.apache.spark.internal.Logging        : Removing RDD 7
2022-07-30 11:42:08.000  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:42:08.003  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177728000 ms
2022-07-30 11:42:08.003  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 80 (count at Application.java:147) as input to shuffle 4
2022-07-30 11:42:08.004  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 5 (count at Application.java:147) with 1 output partitions
2022-07-30 11:42:08.004  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 10 (count at Application.java:147)
2022-07-30 11:42:08.004  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 9)
2022-07-30 11:42:08.005  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:42:08.006  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 10 (MapPartitionsRDD[83] at count at Application.java:147), which has no missing parents
2022-07-30 11:42:08.009  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_5 stored as values in memory (estimated size 11.0 KiB, free 841.5 MiB)
2022-07-30 11:42:08.013  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_5_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 841.5 MiB)
2022-07-30 11:42:08.016  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_5_piece0 in memory on host.docker.internal:58170 (size: 5.4 KiB, free: 841.7 MiB)
2022-07-30 11:42:08.016  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 5 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:42:08.017  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[83] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:42:08.018  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 10.0 with 1 tasks resource profile 0
2022-07-30 11:42:08.019  INFO   57 --- [er-event-loop-0] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 10.0 (TID 5) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:42:08.020  INFO   57 --- [ge 10.0 (TID 5)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 10.0 (TID 5)
2022-07-30 11:42:08.026  INFO   57 --- [ge 10.0 (TID 5)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:42:08.026  INFO   57 --- [ge 10.0 (TID 5)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 1 ms
2022-07-30 11:42:08.029  INFO   57 --- [ge 10.0 (TID 5)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 10.0 (TID 5). 2555 bytes result sent to driver
2022-07-30 11:42:08.030  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 10.0 (TID 5) in 11 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:42:08.030  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Removed TaskSet 10.0, whose tasks have all completed, from pool 
2022-07-30 11:42:08.032  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 10 (count at Application.java:147) finished in 0.025 s
2022-07-30 11:42:08.033  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:42:08.033  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 10: Stage finished
2022-07-30 11:42:08.034  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 5 finished: count at Application.java:147, took 0.033611 s
2022-07-30 11:42:08.039  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:42:08.039  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:42:08.042  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177713000 ms.0 from job set of time 1659177713000 ms
2022-07-30 11:42:08.043  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 15.042 s for time 1659177713000 ms (execution: 0.156 s)
2022-07-30 11:42:08.043  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177714000 ms.0 from job set of time 1659177714000 ms
2022-07-30 11:42:08.056  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 9 from persistence list
2022-07-30 11:42:08.086  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 8 from persistence list
2022-07-30 11:42:08.105  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[8] at receiverStream at Application.java:122 of time 1659177713000 ms
2022-07-30 11:42:08.106  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177711000 ms
2022-07-30 11:42:08.106  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177711000 ms
2022-07-30 11:42:08.134  INFO   57 --- [-thread-pool-21] org.apache.spark.internal.Logging        : Removing RDD 9
2022-07-30 11:42:08.140  INFO   57 --- [-thread-pool-22] org.apache.spark.internal.Logging        : Removing RDD 8
2022-07-30 11:42:08.196  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_2_piece0 on host.docker.internal:58170 in memory (size: 5.4 KiB, free: 841.7 MiB)
2022-07-30 11:42:08.227  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_4_piece0 on host.docker.internal:58170 in memory (size: 5.4 KiB, free: 841.7 MiB)
2022-07-30 11:42:08.248  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_5_piece0 on host.docker.internal:58170 in memory (size: 5.4 KiB, free: 841.7 MiB)
2022-07-30 11:42:08.256  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_3_piece0 on host.docker.internal:58170 in memory (size: 5.4 KiB, free: 841.7 MiB)
2022-07-30 11:42:08.300  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:42:08.301  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 91 (count at Application.java:147) as input to shuffle 5
2022-07-30 11:42:08.302  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 6 (count at Application.java:147) with 1 output partitions
2022-07-30 11:42:08.302  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 12 (count at Application.java:147)
2022-07-30 11:42:08.302  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 11)
2022-07-30 11:42:08.303  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:42:08.304  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 12 (MapPartitionsRDD[94] at count at Application.java:147), which has no missing parents
2022-07-30 11:42:08.308  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_6 stored as values in memory (estimated size 11.0 KiB, free 841.6 MiB)
2022-07-30 11:42:08.315  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_6_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 841.6 MiB)
2022-07-30 11:42:08.319  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_6_piece0 in memory on host.docker.internal:58170 (size: 5.4 KiB, free: 841.7 MiB)
2022-07-30 11:42:08.321  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 6 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:42:08.322  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[94] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:42:08.322  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 12.0 with 1 tasks resource profile 0
2022-07-30 11:42:08.324  INFO   57 --- [er-event-loop-3] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 12.0 (TID 6) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:42:08.324  INFO   57 --- [ge 12.0 (TID 6)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 12.0 (TID 6)
2022-07-30 11:42:08.331  INFO   57 --- [ge 12.0 (TID 6)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:42:08.332  INFO   57 --- [ge 12.0 (TID 6)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 1 ms
2022-07-30 11:42:08.337  INFO   57 --- [ge 12.0 (TID 6)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 12.0 (TID 6). 2641 bytes result sent to driver
2022-07-30 11:42:08.339  INFO   57 --- [result-getter-1] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 12.0 (TID 6) in 16 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:42:08.339  INFO   57 --- [result-getter-1] org.apache.spark.internal.Logging        : Removed TaskSet 12.0, whose tasks have all completed, from pool 
2022-07-30 11:42:08.340  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 12 (count at Application.java:147) finished in 0.033 s
2022-07-30 11:42:08.341  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:42:08.341  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 12: Stage finished
2022-07-30 11:42:08.342  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 6 finished: count at Application.java:147, took 0.041227 s
2022-07-30 11:42:08.343  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177714000 ms.0 from job set of time 1659177714000 ms
2022-07-30 11:42:08.344  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 14.343 s for time 1659177714000 ms (execution: 0.300 s)
2022-07-30 11:42:08.344  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177715000 ms.0 from job set of time 1659177715000 ms
2022-07-30 11:42:08.351  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:42:08.352  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:42:08.369  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 12 from persistence list
2022-07-30 11:42:08.379  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 11 from persistence list
2022-07-30 11:42:08.382  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[11] at receiverStream at Application.java:122 of time 1659177714000 ms
2022-07-30 11:42:08.383  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177712000 ms
2022-07-30 11:42:08.384  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177712000 ms
2022-07-30 11:42:08.392  INFO   57 --- [-thread-pool-54] org.apache.spark.internal.Logging        : Removing RDD 12
2022-07-30 11:42:08.394  INFO   57 --- [-thread-pool-55] org.apache.spark.internal.Logging        : Removing RDD 11
2022-07-30 11:42:08.497  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:42:08.499  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 100 (count at Application.java:147) as input to shuffle 6
2022-07-30 11:42:08.499  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 7 (count at Application.java:147) with 1 output partitions
2022-07-30 11:42:08.500  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 14 (count at Application.java:147)
2022-07-30 11:42:08.500  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 13)
2022-07-30 11:42:08.500  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:42:08.501  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 14 (MapPartitionsRDD[103] at count at Application.java:147), which has no missing parents
2022-07-30 11:42:08.507  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_7 stored as values in memory (estimated size 11.0 KiB, free 841.6 MiB)
2022-07-30 11:42:08.510  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_7_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 841.5 MiB)
2022-07-30 11:42:08.512  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_7_piece0 in memory on host.docker.internal:58170 (size: 5.4 KiB, free: 841.7 MiB)
2022-07-30 11:42:08.513  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 7 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:42:08.514  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[103] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:42:08.514  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 14.0 with 1 tasks resource profile 0
2022-07-30 11:42:08.518  INFO   57 --- [er-event-loop-2] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 14.0 (TID 7) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:42:08.519  INFO   57 --- [ge 14.0 (TID 7)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 14.0 (TID 7)
2022-07-30 11:42:08.527  INFO   57 --- [ge 14.0 (TID 7)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:42:08.527  INFO   57 --- [ge 14.0 (TID 7)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 4 ms
2022-07-30 11:42:08.531  INFO   57 --- [ge 14.0 (TID 7)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 14.0 (TID 7). 2555 bytes result sent to driver
2022-07-30 11:42:08.535  INFO   57 --- [result-getter-2] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 14.0 (TID 7) in 16 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:42:08.537  INFO   57 --- [result-getter-2] org.apache.spark.internal.Logging        : Removed TaskSet 14.0, whose tasks have all completed, from pool 
2022-07-30 11:42:08.548  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 14 (count at Application.java:147) finished in 0.045 s
2022-07-30 11:42:08.548  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:42:08.549  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 14: Stage finished
2022-07-30 11:42:08.560  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 7 finished: count at Application.java:147, took 0.061514 s
2022-07-30 11:42:08.618  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:42:08.619  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:42:08.623  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177715000 ms.0 from job set of time 1659177715000 ms
2022-07-30 11:42:08.624  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 13.623 s for time 1659177715000 ms (execution: 0.279 s)
2022-07-30 11:42:08.624  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177716000 ms.0 from job set of time 1659177716000 ms
2022-07-30 11:42:08.647  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 14 from persistence list
2022-07-30 11:42:08.651  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 13 from persistence list
2022-07-30 11:42:08.653  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[13] at receiverStream at Application.java:122 of time 1659177715000 ms
2022-07-30 11:42:08.653  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177713000 ms
2022-07-30 11:42:08.653  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177713000 ms
2022-07-30 11:42:08.659  INFO   57 --- [-thread-pool-60] org.apache.spark.internal.Logging        : Removing RDD 14
2022-07-30 11:42:08.666  INFO   57 --- [-thread-pool-61] org.apache.spark.internal.Logging        : Removing RDD 13
2022-07-30 11:42:08.752  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:42:08.753  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 109 (count at Application.java:147) as input to shuffle 7
2022-07-30 11:42:08.754  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 8 (count at Application.java:147) with 1 output partitions
2022-07-30 11:42:08.758  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 16 (count at Application.java:147)
2022-07-30 11:42:08.758  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 15)
2022-07-30 11:42:08.759  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:42:08.760  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 16 (MapPartitionsRDD[112] at count at Application.java:147), which has no missing parents
2022-07-30 11:42:08.768  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_8 stored as values in memory (estimated size 11.0 KiB, free 841.5 MiB)
2022-07-30 11:42:08.773  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_8_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 841.5 MiB)
2022-07-30 11:42:08.781  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_8_piece0 in memory on host.docker.internal:58170 (size: 5.4 KiB, free: 841.7 MiB)
2022-07-30 11:42:08.782  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 8 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:42:08.783  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[112] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:42:08.783  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 16.0 with 1 tasks resource profile 0
2022-07-30 11:42:08.784  INFO   57 --- [er-event-loop-1] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 16.0 (TID 8) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:42:08.785  INFO   57 --- [ge 16.0 (TID 8)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 16.0 (TID 8)
2022-07-30 11:42:08.792  INFO   57 --- [ge 16.0 (TID 8)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:42:08.793  INFO   57 --- [ge 16.0 (TID 8)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 1 ms
2022-07-30 11:42:08.798  INFO   57 --- [ge 16.0 (TID 8)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 16.0 (TID 8). 2598 bytes result sent to driver
2022-07-30 11:42:08.799  INFO   57 --- [result-getter-3] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 16.0 (TID 8) in 15 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:42:08.800  INFO   57 --- [result-getter-3] org.apache.spark.internal.Logging        : Removed TaskSet 16.0, whose tasks have all completed, from pool 
2022-07-30 11:42:08.802  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 16 (count at Application.java:147) finished in 0.038 s
2022-07-30 11:42:08.803  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:42:08.803  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 16: Stage finished
2022-07-30 11:42:08.805  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 8 finished: count at Application.java:147, took 0.052474 s
2022-07-30 11:42:08.814  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177716000 ms.0 from job set of time 1659177716000 ms
2022-07-30 11:42:08.815  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 12.814 s for time 1659177716000 ms (execution: 0.190 s)
2022-07-30 11:42:08.815  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177717000 ms.0 from job set of time 1659177717000 ms
2022-07-30 11:42:08.816  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:42:08.816  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:42:08.825  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 16 from persistence list
2022-07-30 11:42:08.830  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 15 from persistence list
2022-07-30 11:42:08.855  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[15] at receiverStream at Application.java:122 of time 1659177716000 ms
2022-07-30 11:42:08.856  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177714000 ms
2022-07-30 11:42:08.856  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177714000 ms
2022-07-30 11:42:08.865  INFO   57 --- [-thread-pool-66] org.apache.spark.internal.Logging        : Removing RDD 16
2022-07-30 11:42:08.866  INFO   57 --- [-thread-pool-67] org.apache.spark.internal.Logging        : Removing RDD 15
2022-07-30 11:42:08.941  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:42:08.943  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 118 (count at Application.java:147) as input to shuffle 8
2022-07-30 11:42:08.943  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 9 (count at Application.java:147) with 1 output partitions
2022-07-30 11:42:08.944  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 18 (count at Application.java:147)
2022-07-30 11:42:08.944  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 17)
2022-07-30 11:42:08.944  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:42:08.946  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 18 (MapPartitionsRDD[121] at count at Application.java:147), which has no missing parents
2022-07-30 11:42:08.949  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_9 stored as values in memory (estimated size 11.0 KiB, free 841.5 MiB)
2022-07-30 11:42:08.954  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_9_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 841.5 MiB)
2022-07-30 11:42:08.955  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_9_piece0 in memory on host.docker.internal:58170 (size: 5.4 KiB, free: 841.7 MiB)
2022-07-30 11:42:08.956  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 9 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:42:08.956  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[121] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:42:08.956  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 18.0 with 1 tasks resource profile 0
2022-07-30 11:42:08.958  INFO   57 --- [er-event-loop-0] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 18.0 (TID 9) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:42:08.960  INFO   57 --- [ge 18.0 (TID 9)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 18.0 (TID 9)
2022-07-30 11:42:08.969  INFO   57 --- [ge 18.0 (TID 9)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:42:08.970  INFO   57 --- [ge 18.0 (TID 9)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 1 ms
2022-07-30 11:42:08.973  INFO   57 --- [ge 18.0 (TID 9)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 18.0 (TID 9). 2598 bytes result sent to driver
2022-07-30 11:42:08.975  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 18.0 (TID 9) in 17 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:42:08.975  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Removed TaskSet 18.0, whose tasks have all completed, from pool 
2022-07-30 11:42:08.976  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 18 (count at Application.java:147) finished in 0.029 s
2022-07-30 11:42:08.977  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 9 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:42:08.977  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 18: Stage finished
2022-07-30 11:42:08.979  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 9 finished: count at Application.java:147, took 0.037515 s
2022-07-30 11:42:08.981  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177717000 ms.0 from job set of time 1659177717000 ms
2022-07-30 11:42:08.982  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 11.981 s for time 1659177717000 ms (execution: 0.166 s)
2022-07-30 11:42:08.982  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177718000 ms.0 from job set of time 1659177718000 ms
2022-07-30 11:42:08.985  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 18 from persistence list
2022-07-30 11:42:08.986  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:42:08.986  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:42:08.998  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 17 from persistence list
2022-07-30 11:42:09.006  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[17] at receiverStream at Application.java:122 of time 1659177717000 ms
2022-07-30 11:42:09.007  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177715000 ms
2022-07-30 11:42:09.008  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177715000 ms
2022-07-30 11:42:09.016  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177729000 ms
2022-07-30 11:42:09.017  INFO   57 --- [-thread-pool-72] org.apache.spark.internal.Logging        : Removing RDD 18
2022-07-30 11:42:09.018  INFO   57 --- [-thread-pool-73] org.apache.spark.internal.Logging        : Removing RDD 17
2022-07-30 11:42:09.091  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: show at Application.java:146
2022-07-30 11:42:09.092  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 10 (show at Application.java:146) with 1 output partitions
2022-07-30 11:42:09.092  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 19 (show at Application.java:146)
2022-07-30 11:42:09.093  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List()
2022-07-30 11:42:09.093  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:42:09.094  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 19 (MapPartitionsRDD[127] at show at Application.java:146), which has no missing parents
2022-07-30 11:42:09.116  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_10 stored as values in memory (estimated size 12.9 KiB, free 841.5 MiB)
2022-07-30 11:42:09.122  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_10_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 841.5 MiB)
2022-07-30 11:42:09.123  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_10_piece0 in memory on host.docker.internal:58170 (size: 5.8 KiB, free: 841.7 MiB)
2022-07-30 11:42:09.124  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 10 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:42:09.125  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[127] at show at Application.java:146) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:42:09.125  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 19.0 with 1 tasks resource profile 0
2022-07-30 11:42:09.129  INFO   57 --- [er-event-loop-3] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 19.0 (TID 10) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
2022-07-30 11:42:09.130  INFO   57 --- [e 19.0 (TID 10)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 19.0 (TID 10)
2022-07-30 11:42:09.156  INFO   57 --- [e 19.0 (TID 10)] org.apache.spark.internal.Logging        : Found block input-0-1659177712094 locally
2022-07-30 11:42:09.348  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_9_piece0 on host.docker.internal:58170 in memory (size: 5.4 KiB, free: 841.7 MiB)
2022-07-30 11:42:09.357  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_6_piece0 on host.docker.internal:58170 in memory (size: 5.4 KiB, free: 841.7 MiB)
2022-07-30 11:42:09.366  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_8_piece0 on host.docker.internal:58170 in memory (size: 5.4 KiB, free: 841.7 MiB)
2022-07-30 11:42:09.374  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_7_piece0 on host.docker.internal:58170 in memory (size: 5.4 KiB, free: 841.7 MiB)
2022-07-30 11:42:10.003  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177730000 ms
2022-07-30 11:42:10.230  INFO   57 --- [e 19.0 (TID 10)] org.apache.spark.internal.Logging        : 1 block locks were not released by task 0.0 in stage 19.0 (TID 10)
[input-0-1659177712094]
2022-07-30 11:42:10.231  INFO   57 --- [e 19.0 (TID 10)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 19.0 (TID 10). 2167 bytes result sent to driver
2022-07-30 11:42:10.232  INFO   57 --- [result-getter-1] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 19.0 (TID 10) in 1106 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:42:10.233  INFO   57 --- [result-getter-1] org.apache.spark.internal.Logging        : Removed TaskSet 19.0, whose tasks have all completed, from pool 
2022-07-30 11:42:10.234  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 19 (show at Application.java:146) finished in 1.132 s
2022-07-30 11:42:10.234  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 10 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:42:10.234  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 19: Stage finished
2022-07-30 11:42:10.235  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 10 finished: show at Application.java:146, took 1.142789 s
2022-07-30 11:42:10.329  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Code generated in 57.2893 ms
2022-07-30 11:42:10.415  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 131 (count at Application.java:147) as input to shuffle 9
2022-07-30 11:42:10.416  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got map stage job 11 (count at Application.java:147) with 1 output partitions
2022-07-30 11:42:10.417  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ShuffleMapStage 20 (count at Application.java:147)
2022-07-30 11:42:10.418  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List()
2022-07-30 11:42:10.419  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:42:10.421  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ShuffleMapStage 20 (MapPartitionsRDD[131] at count at Application.java:147), which has no missing parents
2022-07-30 11:42:10.438  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_11 stored as values in memory (estimated size 13.6 KiB, free 841.6 MiB)
2022-07-30 11:42:10.455  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_11_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 841.5 MiB)
2022-07-30 11:42:10.456  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_11_piece0 in memory on host.docker.internal:58170 (size: 6.7 KiB, free: 841.7 MiB)
2022-07-30 11:42:10.457  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 11 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:42:10.459  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[131] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:42:10.459  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 20.0 with 1 tasks resource profile 0
2022-07-30 11:42:10.463  INFO   57 --- [er-event-loop-2] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 20.0 (TID 11) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4383 bytes) taskResourceAssignments Map()
2022-07-30 11:42:10.465  INFO   57 --- [e 20.0 (TID 11)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 20.0 (TID 11)
2022-07-30 11:42:10.566  INFO   57 --- [e 20.0 (TID 11)] org.apache.spark.internal.Logging        : Found block input-0-1659177712094 locally
2022-07-30 11:42:10.610  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_10_piece0 on host.docker.internal:58170 in memory (size: 5.8 KiB, free: 841.7 MiB)
2022-07-30 11:42:11.002  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177731000 ms
2022-07-30 11:42:12.021  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177732000 ms
2022-07-30 11:42:12.040  INFO   57 --- [e 20.0 (TID 11)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 20.0 (TID 11). 1924 bytes result sent to driver
2022-07-30 11:42:12.049  INFO   57 --- [result-getter-2] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 20.0 (TID 11) in 1587 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:42:12.049  INFO   57 --- [result-getter-2] org.apache.spark.internal.Logging        : Removed TaskSet 20.0, whose tasks have all completed, from pool 
2022-07-30 11:42:12.052  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ShuffleMapStage 20 (count at Application.java:147) finished in 1.626 s
2022-07-30 11:42:12.052  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : looking for newly runnable stages
2022-07-30 11:42:12.053  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : running: Set(ResultStage 0)
2022-07-30 11:42:12.054  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : waiting: Set()
2022-07-30 11:42:12.054  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : failed: Set()
2022-07-30 11:42:12.119  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:42:12.120  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 12 (count at Application.java:147) with 1 output partitions
2022-07-30 11:42:12.120  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 22 (count at Application.java:147)
2022-07-30 11:42:12.121  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 21)
2022-07-30 11:42:12.121  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:42:12.121  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 22 (MapPartitionsRDD[138] at count at Application.java:147), which has no missing parents
2022-07-30 11:42:12.129  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_12 stored as values in memory (estimated size 11.0 KiB, free 841.6 MiB)
2022-07-30 11:42:12.131  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_12_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 841.5 MiB)
2022-07-30 11:42:12.132  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_12_piece0 in memory on host.docker.internal:58170 (size: 5.5 KiB, free: 841.7 MiB)
2022-07-30 11:42:12.134  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 12 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:42:12.135  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 22 (MapPartitionsRDD[138] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:42:12.135  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 22.0 with 1 tasks resource profile 0
2022-07-30 11:42:12.136  INFO   57 --- [er-event-loop-1] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 22.0 (TID 12) (host.docker.internal, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:42:12.137  INFO   57 --- [e 22.0 (TID 12)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 22.0 (TID 12)
2022-07-30 11:42:12.156  INFO   57 --- [e 22.0 (TID 12)] org.apache.spark.internal.Logging        : Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:42:12.157  INFO   57 --- [e 22.0 (TID 12)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 3 ms
2022-07-30 11:42:12.249  INFO   57 --- [e 22.0 (TID 12)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 22.0 (TID 12). 2605 bytes result sent to driver
2022-07-30 11:42:12.250  INFO   57 --- [result-getter-3] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 22.0 (TID 12) in 114 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:42:12.251  INFO   57 --- [result-getter-3] org.apache.spark.internal.Logging        : Removed TaskSet 22.0, whose tasks have all completed, from pool 
2022-07-30 11:42:12.253  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 22 (count at Application.java:147) finished in 0.124 s
2022-07-30 11:42:12.254  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 12 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:42:12.255  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 22: Stage finished
2022-07-30 11:42:12.255  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 12 finished: count at Application.java:147, took 0.135057 s
2022-07-30 11:42:13.001  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177733000 ms
2022-07-30 11:42:13.755  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_12_piece0 on host.docker.internal:58170 in memory (size: 5.5 KiB, free: 841.7 MiB)
2022-07-30 11:42:13.759  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_11_piece0 on host.docker.internal:58170 in memory (size: 6.7 KiB, free: 841.7 MiB)
2022-07-30 11:42:14.005  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177734000 ms
2022-07-30 11:42:15.002  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177735000 ms
2022-07-30 11:42:16.003  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177736000 ms
2022-07-30 11:42:16.277  INFO  142 --- [-job-executor-0] mapreduce.lib.output.FileOutputCommitter : File Output Committer Algorithm version is 1
2022-07-30 11:42:16.277  INFO  157 --- [-job-executor-0] mapreduce.lib.output.FileOutputCommitter : FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2022-07-30 11:42:16.279  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2022-07-30 11:42:17.001  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177737000 ms
2022-07-30 11:42:17.015  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: csv at Application.java:148
2022-07-30 11:42:17.016  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 13 (csv at Application.java:148) with 1 output partitions
2022-07-30 11:42:17.017  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 23 (csv at Application.java:148)
2022-07-30 11:42:17.017  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List()
2022-07-30 11:42:17.017  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:42:17.017  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 23 (MapPartitionsRDD[147] at csv at Application.java:148), which has no missing parents
2022-07-30 11:42:17.051  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_13 stored as values in memory (estimated size 206.8 KiB, free 841.4 MiB)
2022-07-30 11:42:17.054  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_13_piece0 stored as bytes in memory (estimated size 74.0 KiB, free 841.3 MiB)
2022-07-30 11:42:17.055  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_13_piece0 in memory on host.docker.internal:58170 (size: 74.0 KiB, free: 841.6 MiB)
2022-07-30 11:42:17.056  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 13 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:42:17.056  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 23 (MapPartitionsRDD[147] at csv at Application.java:148) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:42:17.056  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 23.0 with 1 tasks resource profile 0
2022-07-30 11:42:17.058  INFO   57 --- [er-event-loop-2] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 23.0 (TID 13) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
2022-07-30 11:42:17.059  INFO   57 --- [e 23.0 (TID 13)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 23.0 (TID 13)
2022-07-30 11:42:17.088  INFO   57 --- [e 23.0 (TID 13)] org.apache.spark.internal.Logging        : Found block input-0-1659177712094 locally
2022-07-30 11:42:17.090  INFO  142 --- [e 23.0 (TID 13)] mapreduce.lib.output.FileOutputCommitter : File Output Committer Algorithm version is 1
2022-07-30 11:42:17.091  INFO  157 --- [e 23.0 (TID 13)] mapreduce.lib.output.FileOutputCommitter : FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2022-07-30 11:42:17.092  INFO   57 --- [e 23.0 (TID 13)] org.apache.spark.internal.Logging        : Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2022-07-30 11:42:18.004  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177738000 ms
2022-07-30 11:42:19.002  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177739000 ms
2022-07-30 11:42:20.010  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177740000 ms
2022-07-30 11:42:21.003  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177741000 ms
2022-07-30 11:42:22.007  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177742000 ms
2022-07-30 11:42:22.462  INFO  604 --- [e 23.0 (TID 13)] mapreduce.lib.output.FileOutputCommitter : Saved output of task 'attempt_202207301142163704969840871551062_0023_m_000000_13' to hdfs://localhost:9000/user/dataFromSpark/file1/_temporary/0/task_202207301142163704969840871551062_0023_m_000000
2022-07-30 11:42:22.463  INFO   57 --- [e 23.0 (TID 13)] org.apache.spark.internal.Logging        : attempt_202207301142163704969840871551062_0023_m_000000_13: Committed
2022-07-30 11:42:22.496  INFO   57 --- [e 23.0 (TID 13)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 23.0 (TID 13). 2515 bytes result sent to driver
2022-07-30 11:42:22.499  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 23.0 (TID 13) in 5441 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:42:22.500  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Removed TaskSet 23.0, whose tasks have all completed, from pool 
2022-07-30 11:42:22.502  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 23 (csv at Application.java:148) finished in 5.483 s
2022-07-30 11:42:22.503  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 13 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:42:22.503  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 23: Stage finished
2022-07-30 11:42:22.505  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 13 finished: csv at Application.java:148, took 5.489321 s
2022-07-30 11:42:22.508  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Start to commit write Job 5f842b92-f347-442f-a646-4d7539cf790e.
2022-07-30 11:42:22.830  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Write Job 5f842b92-f347-442f-a646-4d7539cf790e committed. Elapsed time: 320 ms.
2022-07-30 11:42:22.834  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Finished processing stats for write job 5f842b92-f347-442f-a646-4d7539cf790e.
2022-07-30 11:42:22.839  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177718000 ms.0 from job set of time 1659177718000 ms
2022-07-30 11:42:22.839  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 24.839 s for time 1659177718000 ms (execution: 13.857 s)
2022-07-30 11:42:22.840  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177719000 ms.0 from job set of time 1659177719000 ms
2022-07-30 11:42:22.840  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 20 from persistence list
2022-07-30 11:42:22.841  INFO   57 --- [-thread-pool-14] org.apache.spark.internal.Logging        : Removing RDD 20
2022-07-30 11:42:22.842  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 19 from persistence list
2022-07-30 11:42:22.843  INFO   57 --- [-thread-pool-18] org.apache.spark.internal.Logging        : Removing RDD 19
2022-07-30 11:42:22.843  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[19] at receiverStream at Application.java:122 of time 1659177718000 ms
2022-07-30 11:42:22.845  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177716000 ms
2022-07-30 11:42:22.845  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177716000 ms
2022-07-30 11:42:22.851  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:42:22.851  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:42:22.976  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:42:22.978  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 165 (count at Application.java:147) as input to shuffle 10
2022-07-30 11:42:22.979  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 14 (count at Application.java:147) with 1 output partitions
2022-07-30 11:42:22.979  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 25 (count at Application.java:147)
2022-07-30 11:42:22.979  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 24)
2022-07-30 11:42:22.979  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:42:22.980  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 25 (MapPartitionsRDD[168] at count at Application.java:147), which has no missing parents
2022-07-30 11:42:22.984  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_14 stored as values in memory (estimated size 11.0 KiB, free 841.3 MiB)
2022-07-30 11:42:22.996  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_14_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 841.3 MiB)
2022-07-30 11:42:22.997  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_14_piece0 in memory on host.docker.internal:58170 (size: 5.4 KiB, free: 841.6 MiB)
2022-07-30 11:42:22.998  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 14 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:42:22.999  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 25 (MapPartitionsRDD[168] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:42:22.999  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 25.0 with 1 tasks resource profile 0
2022-07-30 11:42:23.000  INFO   57 --- [er-event-loop-2] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 25.0 (TID 14) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:42:23.001  INFO   57 --- [e 25.0 (TID 14)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 25.0 (TID 14)
2022-07-30 11:42:23.004  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177743000 ms
2022-07-30 11:42:23.008  INFO   57 --- [e 25.0 (TID 14)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:42:23.009  INFO   57 --- [e 25.0 (TID 14)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-30 11:42:23.011  INFO   57 --- [e 25.0 (TID 14)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 25.0 (TID 14). 2555 bytes result sent to driver
2022-07-30 11:42:23.013  INFO   57 --- [result-getter-1] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 25.0 (TID 14) in 12 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:42:23.013  INFO   57 --- [result-getter-1] org.apache.spark.internal.Logging        : Removed TaskSet 25.0, whose tasks have all completed, from pool 
2022-07-30 11:42:23.014  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 25 (count at Application.java:147) finished in 0.031 s
2022-07-30 11:42:23.014  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 14 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:42:23.014  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 25: Stage finished
2022-07-30 11:42:23.015  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 14 finished: count at Application.java:147, took 0.038674 s
2022-07-30 11:42:23.017  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177719000 ms.0 from job set of time 1659177719000 ms
2022-07-30 11:42:23.020  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 24.017 s for time 1659177719000 ms (execution: 0.178 s)
2022-07-30 11:42:23.021  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177720000 ms.0 from job set of time 1659177720000 ms
2022-07-30 11:42:23.022  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:42:23.023  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:42:23.026  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 22 from persistence list
2022-07-30 11:42:23.029  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 21 from persistence list
2022-07-30 11:42:23.030  INFO   57 --- [-thread-pool-20] org.apache.spark.internal.Logging        : Removing RDD 22
2022-07-30 11:42:23.032  INFO   57 --- [-thread-pool-21] org.apache.spark.internal.Logging        : Removing RDD 21
2022-07-30 11:42:23.033  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[21] at receiverStream at Application.java:122 of time 1659177719000 ms
2022-07-30 11:42:23.063  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177717000 ms
2022-07-30 11:42:23.064  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177717000 ms
2022-07-30 11:42:23.068  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed input-0-1659177712094 on host.docker.internal:58170 in memory (size: 55.9 MiB, free: 897.5 MiB)
2022-07-30 11:42:23.204  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:42:23.205  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 176 (count at Application.java:147) as input to shuffle 11
2022-07-30 11:42:23.205  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 15 (count at Application.java:147) with 1 output partitions
2022-07-30 11:42:23.205  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 27 (count at Application.java:147)
2022-07-30 11:42:23.205  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 26)
2022-07-30 11:42:23.206  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:42:23.206  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 27 (MapPartitionsRDD[179] at count at Application.java:147), which has no missing parents
2022-07-30 11:42:23.208  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_15 stored as values in memory (estimated size 11.0 KiB, free 897.2 MiB)
2022-07-30 11:42:23.217  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_15_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.2 MiB)
2022-07-30 11:42:23.218  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_15_piece0 in memory on host.docker.internal:58170 (size: 5.4 KiB, free: 897.5 MiB)
2022-07-30 11:42:23.218  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 15 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:42:23.219  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 27 (MapPartitionsRDD[179] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:42:23.220  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 27.0 with 1 tasks resource profile 0
2022-07-30 11:42:23.221  INFO   57 --- [er-event-loop-1] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 27.0 (TID 15) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:42:23.223  INFO   57 --- [e 27.0 (TID 15)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 27.0 (TID 15)
2022-07-30 11:42:23.228  INFO   57 --- [e 27.0 (TID 15)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:42:23.228  INFO   57 --- [e 27.0 (TID 15)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-30 11:42:23.229  INFO   57 --- [e 27.0 (TID 15)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 27.0 (TID 15). 2555 bytes result sent to driver
2022-07-30 11:42:23.230  INFO   57 --- [result-getter-2] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 27.0 (TID 15) in 9 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:42:23.230  INFO   57 --- [result-getter-2] org.apache.spark.internal.Logging        : Removed TaskSet 27.0, whose tasks have all completed, from pool 
2022-07-30 11:42:23.231  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 27 (count at Application.java:147) finished in 0.024 s
2022-07-30 11:42:23.232  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 15 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:42:23.232  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 27: Stage finished
2022-07-30 11:42:23.233  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 15 finished: count at Application.java:147, took 0.028315 s
2022-07-30 11:42:23.234  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177720000 ms.0 from job set of time 1659177720000 ms
2022-07-30 11:42:23.235  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 23.234 s for time 1659177720000 ms (execution: 0.214 s)
2022-07-30 11:42:23.235  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177721000 ms.0 from job set of time 1659177721000 ms
2022-07-30 11:42:23.240  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:42:23.241  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:42:23.240  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 24 from persistence list
2022-07-30 11:42:23.247  INFO   57 --- [-thread-pool-29] org.apache.spark.internal.Logging        : Removing RDD 24
2022-07-30 11:42:23.248  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 23 from persistence list
2022-07-30 11:42:23.250  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[23] at receiverStream at Application.java:122 of time 1659177720000 ms
2022-07-30 11:42:23.251  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177718000 ms
2022-07-30 11:42:23.251  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177718000 ms
2022-07-30 11:42:23.250  INFO   57 --- [-thread-pool-32] org.apache.spark.internal.Logging        : Removing RDD 23
2022-07-30 11:42:23.401  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:42:23.402  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 185 (count at Application.java:147) as input to shuffle 12
2022-07-30 11:42:23.403  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 16 (count at Application.java:147) with 1 output partitions
2022-07-30 11:42:23.403  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 29 (count at Application.java:147)
2022-07-30 11:42:23.403  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 28)
2022-07-30 11:42:23.403  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:42:23.404  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 29 (MapPartitionsRDD[188] at count at Application.java:147), which has no missing parents
2022-07-30 11:42:23.407  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_16 stored as values in memory (estimated size 11.0 KiB, free 897.2 MiB)
2022-07-30 11:42:23.417  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_16_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.1 MiB)
2022-07-30 11:42:23.418  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_16_piece0 in memory on host.docker.internal:58170 (size: 5.4 KiB, free: 897.5 MiB)
2022-07-30 11:42:23.418  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 16 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:42:23.419  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 29 (MapPartitionsRDD[188] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:42:23.419  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 29.0 with 1 tasks resource profile 0
2022-07-30 11:42:23.420  INFO   57 --- [er-event-loop-0] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 29.0 (TID 16) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:42:23.421  INFO   57 --- [e 29.0 (TID 16)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 29.0 (TID 16)
2022-07-30 11:42:23.426  INFO   57 --- [e 29.0 (TID 16)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:42:23.428  INFO   57 --- [e 29.0 (TID 16)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 2 ms
2022-07-30 11:42:23.430  INFO   57 --- [e 29.0 (TID 16)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 29.0 (TID 16). 2555 bytes result sent to driver
2022-07-30 11:42:23.432  INFO   57 --- [result-getter-3] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 29.0 (TID 16) in 12 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:42:23.432  INFO   57 --- [result-getter-3] org.apache.spark.internal.Logging        : Removed TaskSet 29.0, whose tasks have all completed, from pool 
2022-07-30 11:42:23.433  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 29 (count at Application.java:147) finished in 0.028 s
2022-07-30 11:42:23.434  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 16 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:42:23.434  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 29: Stage finished
2022-07-30 11:42:23.436  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 16 finished: count at Application.java:147, took 0.034083 s
2022-07-30 11:42:23.437  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177721000 ms.0 from job set of time 1659177721000 ms
2022-07-30 11:42:23.438  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 22.437 s for time 1659177721000 ms (execution: 0.202 s)
2022-07-30 11:42:23.439  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177722000 ms.0 from job set of time 1659177722000 ms
2022-07-30 11:42:23.442  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:42:23.442  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:42:23.447  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 26 from persistence list
2022-07-30 11:42:23.449  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 25 from persistence list
2022-07-30 11:42:23.450  INFO   57 --- [-thread-pool-35] org.apache.spark.internal.Logging        : Removing RDD 26
2022-07-30 11:42:23.453  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[25] at receiverStream at Application.java:122 of time 1659177721000 ms
2022-07-30 11:42:23.454  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177719000 ms
2022-07-30 11:42:23.456  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177719000 ms
2022-07-30 11:42:23.460  INFO   57 --- [-thread-pool-37] org.apache.spark.internal.Logging        : Removing RDD 25
2022-07-30 11:42:23.584  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:42:23.585  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 194 (count at Application.java:147) as input to shuffle 13
2022-07-30 11:42:23.586  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 17 (count at Application.java:147) with 1 output partitions
2022-07-30 11:42:23.586  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 31 (count at Application.java:147)
2022-07-30 11:42:23.587  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 30)
2022-07-30 11:42:23.587  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:42:23.588  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 31 (MapPartitionsRDD[197] at count at Application.java:147), which has no missing parents
2022-07-30 11:42:23.598  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_17 stored as values in memory (estimated size 11.0 KiB, free 897.1 MiB)
2022-07-30 11:42:23.609  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_17_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.1 MiB)
2022-07-30 11:42:23.613  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_17_piece0 in memory on host.docker.internal:58170 (size: 5.4 KiB, free: 897.5 MiB)
2022-07-30 11:42:23.613  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 17 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:42:23.614  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 31 (MapPartitionsRDD[197] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:42:23.614  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 31.0 with 1 tasks resource profile 0
2022-07-30 11:42:23.616  INFO   57 --- [er-event-loop-3] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 31.0 (TID 17) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:42:23.617  INFO   57 --- [e 31.0 (TID 17)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 31.0 (TID 17)
2022-07-30 11:42:23.624  INFO   57 --- [e 31.0 (TID 17)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:42:23.624  INFO   57 --- [e 31.0 (TID 17)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-30 11:42:23.626  INFO   57 --- [e 31.0 (TID 17)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 31.0 (TID 17). 2598 bytes result sent to driver
2022-07-30 11:42:23.629  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 31.0 (TID 17) in 13 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:42:23.629  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Removed TaskSet 31.0, whose tasks have all completed, from pool 
2022-07-30 11:42:23.630  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 31 (count at Application.java:147) finished in 0.041 s
2022-07-30 11:42:23.631  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 17 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:42:23.631  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 31: Stage finished
2022-07-30 11:42:23.633  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 17 finished: count at Application.java:147, took 0.048329 s
2022-07-30 11:42:23.635  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177722000 ms.0 from job set of time 1659177722000 ms
2022-07-30 11:42:23.635  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 21.635 s for time 1659177722000 ms (execution: 0.196 s)
2022-07-30 11:42:23.636  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177723000 ms.0 from job set of time 1659177723000 ms
2022-07-30 11:42:23.639  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:42:23.640  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:42:23.640  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 28 from persistence list
2022-07-30 11:42:23.642  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 27 from persistence list
2022-07-30 11:42:23.642  INFO   57 --- [-thread-pool-39] org.apache.spark.internal.Logging        : Removing RDD 28
2022-07-30 11:42:23.645  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[27] at receiverStream at Application.java:122 of time 1659177722000 ms
2022-07-30 11:42:23.646  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177720000 ms
2022-07-30 11:42:23.646  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177720000 ms
2022-07-30 11:42:23.647  INFO   57 --- [-thread-pool-43] org.apache.spark.internal.Logging        : Removing RDD 27
2022-07-30 11:42:23.755  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:42:23.756  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 203 (count at Application.java:147) as input to shuffle 14
2022-07-30 11:42:23.756  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 18 (count at Application.java:147) with 1 output partitions
2022-07-30 11:42:23.757  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 33 (count at Application.java:147)
2022-07-30 11:42:23.757  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 32)
2022-07-30 11:42:23.757  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:42:23.758  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 33 (MapPartitionsRDD[206] at count at Application.java:147), which has no missing parents
2022-07-30 11:42:23.762  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_18 stored as values in memory (estimated size 11.0 KiB, free 897.1 MiB)
2022-07-30 11:42:23.771  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_18_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.1 MiB)
2022-07-30 11:42:23.772  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_18_piece0 in memory on host.docker.internal:58170 (size: 5.4 KiB, free: 897.5 MiB)
2022-07-30 11:42:23.773  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 18 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:42:23.774  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 33 (MapPartitionsRDD[206] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:42:23.774  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 33.0 with 1 tasks resource profile 0
2022-07-30 11:42:23.775  INFO   57 --- [er-event-loop-2] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 33.0 (TID 18) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:42:23.776  INFO   57 --- [e 33.0 (TID 18)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 33.0 (TID 18)
2022-07-30 11:42:23.781  INFO   57 --- [e 33.0 (TID 18)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:42:23.781  INFO   57 --- [e 33.0 (TID 18)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-30 11:42:23.783  INFO   57 --- [e 33.0 (TID 18)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 33.0 (TID 18). 2598 bytes result sent to driver
2022-07-30 11:42:23.784  INFO   57 --- [result-getter-1] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 33.0 (TID 18) in 9 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:42:23.785  INFO   57 --- [result-getter-1] org.apache.spark.internal.Logging        : Removed TaskSet 33.0, whose tasks have all completed, from pool 
2022-07-30 11:42:23.786  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 33 (count at Application.java:147) finished in 0.026 s
2022-07-30 11:42:23.787  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 18 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:42:23.787  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 33: Stage finished
2022-07-30 11:42:23.788  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 18 finished: count at Application.java:147, took 0.033184 s
2022-07-30 11:42:23.795  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:42:23.795  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:42:23.806  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177723000 ms.0 from job set of time 1659177723000 ms
2022-07-30 11:42:23.808  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 20.804 s for time 1659177723000 ms (execution: 0.168 s)
2022-07-30 11:42:23.808  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177724000 ms.0 from job set of time 1659177724000 ms
2022-07-30 11:42:23.835  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 30 from persistence list
2022-07-30 11:42:23.838  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 29 from persistence list
2022-07-30 11:42:23.840  INFO   57 --- [-thread-pool-47] org.apache.spark.internal.Logging        : Removing RDD 30
2022-07-30 11:42:23.842  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[29] at receiverStream at Application.java:122 of time 1659177723000 ms
2022-07-30 11:42:23.843  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177721000 ms
2022-07-30 11:42:23.846  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177721000 ms
2022-07-30 11:42:23.845  INFO   57 --- [-thread-pool-49] org.apache.spark.internal.Logging        : Removing RDD 29
2022-07-30 11:42:23.963  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:42:23.964  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 212 (count at Application.java:147) as input to shuffle 15
2022-07-30 11:42:23.965  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 19 (count at Application.java:147) with 1 output partitions
2022-07-30 11:42:23.965  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 35 (count at Application.java:147)
2022-07-30 11:42:23.965  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 34)
2022-07-30 11:42:23.966  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:42:23.966  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 35 (MapPartitionsRDD[215] at count at Application.java:147), which has no missing parents
2022-07-30 11:42:23.969  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_19 stored as values in memory (estimated size 11.0 KiB, free 897.1 MiB)
2022-07-30 11:42:23.979  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_19_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.1 MiB)
2022-07-30 11:42:23.980  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_19_piece0 in memory on host.docker.internal:58170 (size: 5.4 KiB, free: 897.5 MiB)
2022-07-30 11:42:23.980  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 19 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:42:23.984  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 35 (MapPartitionsRDD[215] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:42:23.984  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 35.0 with 1 tasks resource profile 0
2022-07-30 11:42:23.985  INFO   57 --- [er-event-loop-1] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 35.0 (TID 19) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:42:23.987  INFO   57 --- [e 35.0 (TID 19)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 35.0 (TID 19)
2022-07-30 11:42:23.991  INFO   57 --- [e 35.0 (TID 19)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:42:23.991  INFO   57 --- [e 35.0 (TID 19)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-30 11:42:23.995  INFO   57 --- [e 35.0 (TID 19)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 35.0 (TID 19). 2555 bytes result sent to driver
2022-07-30 11:42:24.000  INFO   57 --- [result-getter-2] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 35.0 (TID 19) in 15 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:42:24.000  INFO   57 --- [result-getter-2] org.apache.spark.internal.Logging        : Removed TaskSet 35.0, whose tasks have all completed, from pool 
2022-07-30 11:42:24.001  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 35 (count at Application.java:147) finished in 0.034 s
2022-07-30 11:42:24.002  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 19 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:42:24.002  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 35: Stage finished
2022-07-30 11:42:24.003  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 19 finished: count at Application.java:147, took 0.039872 s
2022-07-30 11:42:24.012  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177724000 ms.0 from job set of time 1659177724000 ms
2022-07-30 11:42:24.013  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 20.012 s for time 1659177724000 ms (execution: 0.204 s)
2022-07-30 11:42:24.013  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177725000 ms.0 from job set of time 1659177725000 ms
2022-07-30 11:42:24.012  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177744000 ms
2022-07-30 11:42:24.014  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 32 from persistence list
2022-07-30 11:42:24.016  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:42:24.016  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:42:24.016  INFO   57 --- [-thread-pool-53] org.apache.spark.internal.Logging        : Removing RDD 32
2022-07-30 11:42:24.016  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 31 from persistence list
2022-07-30 11:42:24.019  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[31] at receiverStream at Application.java:122 of time 1659177724000 ms
2022-07-30 11:42:24.019  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177722000 ms
2022-07-30 11:42:24.019  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177722000 ms
2022-07-30 11:42:24.020  INFO   57 --- [-thread-pool-55] org.apache.spark.internal.Logging        : Removing RDD 31
2022-07-30 11:42:24.179  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:42:24.180  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 223 (count at Application.java:147) as input to shuffle 16
2022-07-30 11:42:24.180  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 20 (count at Application.java:147) with 1 output partitions
2022-07-30 11:42:24.181  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 37 (count at Application.java:147)
2022-07-30 11:42:24.181  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 36)
2022-07-30 11:42:24.182  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:42:24.182  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 37 (MapPartitionsRDD[226] at count at Application.java:147), which has no missing parents
2022-07-30 11:42:24.186  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_20 stored as values in memory (estimated size 11.0 KiB, free 897.1 MiB)
2022-07-30 11:42:24.197  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_20_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.1 MiB)
2022-07-30 11:42:24.198  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_20_piece0 in memory on host.docker.internal:58170 (size: 5.4 KiB, free: 897.5 MiB)
2022-07-30 11:42:24.199  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 20 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:42:24.200  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 37 (MapPartitionsRDD[226] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:42:24.200  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 37.0 with 1 tasks resource profile 0
2022-07-30 11:42:24.202  INFO   57 --- [er-event-loop-0] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 37.0 (TID 20) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:42:24.203  INFO   57 --- [e 37.0 (TID 20)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 37.0 (TID 20)
2022-07-30 11:42:24.208  INFO   57 --- [e 37.0 (TID 20)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:42:24.209  INFO   57 --- [e 37.0 (TID 20)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 1 ms
2022-07-30 11:42:24.211  INFO   57 --- [e 37.0 (TID 20)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 37.0 (TID 20). 2555 bytes result sent to driver
2022-07-30 11:42:24.215  INFO   57 --- [result-getter-3] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 37.0 (TID 20) in 14 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:42:24.215  INFO   57 --- [result-getter-3] org.apache.spark.internal.Logging        : Removed TaskSet 37.0, whose tasks have all completed, from pool 
2022-07-30 11:42:24.216  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 37 (count at Application.java:147) finished in 0.033 s
2022-07-30 11:42:24.216  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 20 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:42:24.217  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 37: Stage finished
2022-07-30 11:42:24.218  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 20 finished: count at Application.java:147, took 0.038762 s
2022-07-30 11:42:24.219  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177725000 ms.0 from job set of time 1659177725000 ms
2022-07-30 11:42:24.220  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 19.219 s for time 1659177725000 ms (execution: 0.206 s)
2022-07-30 11:42:24.220  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177726000 ms.0 from job set of time 1659177726000 ms
2022-07-30 11:42:24.221  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 34 from persistence list
2022-07-30 11:42:24.223  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:42:24.224  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:42:24.238  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 33 from persistence list
2022-07-30 11:42:24.238  INFO   57 --- [-thread-pool-59] org.apache.spark.internal.Logging        : Removing RDD 34
2022-07-30 11:42:24.241  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[33] at receiverStream at Application.java:122 of time 1659177725000 ms
2022-07-30 11:42:24.241  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177723000 ms
2022-07-30 11:42:24.242  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177723000 ms
2022-07-30 11:42:24.251  INFO   57 --- [-thread-pool-61] org.apache.spark.internal.Logging        : Removing RDD 33
2022-07-30 11:42:24.356  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:42:24.357  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 232 (count at Application.java:147) as input to shuffle 17
2022-07-30 11:42:24.357  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 21 (count at Application.java:147) with 1 output partitions
2022-07-30 11:42:24.357  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 39 (count at Application.java:147)
2022-07-30 11:42:24.358  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 38)
2022-07-30 11:42:24.358  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:42:24.358  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 39 (MapPartitionsRDD[235] at count at Application.java:147), which has no missing parents
2022-07-30 11:42:24.361  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_21 stored as values in memory (estimated size 11.0 KiB, free 897.1 MiB)
2022-07-30 11:42:24.369  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_21_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.1 MiB)
2022-07-30 11:42:24.370  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_21_piece0 in memory on host.docker.internal:58170 (size: 5.4 KiB, free: 897.5 MiB)
2022-07-30 11:42:24.370  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 21 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:42:24.371  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 39 (MapPartitionsRDD[235] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:42:24.371  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 39.0 with 1 tasks resource profile 0
2022-07-30 11:42:24.372  INFO   57 --- [er-event-loop-3] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 39.0 (TID 21) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:42:24.372  INFO   57 --- [e 39.0 (TID 21)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 39.0 (TID 21)
2022-07-30 11:42:24.375  INFO   57 --- [e 39.0 (TID 21)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:42:24.375  INFO   57 --- [e 39.0 (TID 21)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-30 11:42:24.377  INFO   57 --- [e 39.0 (TID 21)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 39.0 (TID 21). 2555 bytes result sent to driver
2022-07-30 11:42:24.378  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 39.0 (TID 21) in 6 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:42:24.378  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Removed TaskSet 39.0, whose tasks have all completed, from pool 
2022-07-30 11:42:24.378  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 39 (count at Application.java:147) finished in 0.019 s
2022-07-30 11:42:24.379  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 21 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:42:24.379  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 39: Stage finished
2022-07-30 11:42:24.380  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 21 finished: count at Application.java:147, took 0.022973 s
2022-07-30 11:42:24.381  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177726000 ms.0 from job set of time 1659177726000 ms
2022-07-30 11:42:24.381  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 18.381 s for time 1659177726000 ms (execution: 0.161 s)
2022-07-30 11:42:24.381  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177727000 ms.0 from job set of time 1659177727000 ms
2022-07-30 11:42:24.383  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 36 from persistence list
2022-07-30 11:42:24.384  INFO   57 --- [-thread-pool-65] org.apache.spark.internal.Logging        : Removing RDD 36
2022-07-30 11:42:24.384  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 35 from persistence list
2022-07-30 11:42:24.385  INFO   57 --- [-thread-pool-69] org.apache.spark.internal.Logging        : Removing RDD 35
2022-07-30 11:42:24.385  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:42:24.386  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:42:24.385  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[35] at receiverStream at Application.java:122 of time 1659177726000 ms
2022-07-30 11:42:24.386  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177724000 ms
2022-07-30 11:42:24.386  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177724000 ms
2022-07-30 11:42:24.523  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:42:24.524  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 241 (count at Application.java:147) as input to shuffle 18
2022-07-30 11:42:24.525  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 22 (count at Application.java:147) with 1 output partitions
2022-07-30 11:42:24.525  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 41 (count at Application.java:147)
2022-07-30 11:42:24.525  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 40)
2022-07-30 11:42:24.525  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:42:24.528  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 41 (MapPartitionsRDD[244] at count at Application.java:147), which has no missing parents
2022-07-30 11:42:24.531  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_22 stored as values in memory (estimated size 11.0 KiB, free 897.1 MiB)
2022-07-30 11:42:24.541  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_22_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.1 MiB)
2022-07-30 11:42:24.542  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_22_piece0 in memory on host.docker.internal:58170 (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:42:24.542  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 22 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:42:24.543  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 41 (MapPartitionsRDD[244] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:42:24.543  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 41.0 with 1 tasks resource profile 0
2022-07-30 11:42:24.545  INFO   57 --- [er-event-loop-2] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 41.0 (TID 22) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:42:24.546  INFO   57 --- [e 41.0 (TID 22)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 41.0 (TID 22)
2022-07-30 11:42:24.549  INFO   57 --- [e 41.0 (TID 22)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:42:24.549  INFO   57 --- [e 41.0 (TID 22)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-30 11:42:24.550  INFO   57 --- [e 41.0 (TID 22)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 41.0 (TID 22). 2555 bytes result sent to driver
2022-07-30 11:42:24.552  INFO   57 --- [result-getter-1] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 41.0 (TID 22) in 8 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:42:24.552  INFO   57 --- [result-getter-1] org.apache.spark.internal.Logging        : Removed TaskSet 41.0, whose tasks have all completed, from pool 
2022-07-30 11:42:24.553  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 41 (count at Application.java:147) finished in 0.023 s
2022-07-30 11:42:24.553  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 22 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:42:24.554  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 41: Stage finished
2022-07-30 11:42:24.554  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 22 finished: count at Application.java:147, took 0.030449 s
2022-07-30 11:42:24.555  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177727000 ms.0 from job set of time 1659177727000 ms
2022-07-30 11:42:24.555  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 17.555 s for time 1659177727000 ms (execution: 0.174 s)
2022-07-30 11:42:24.557  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177728000 ms.0 from job set of time 1659177728000 ms
2022-07-30 11:42:24.558  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 40 from persistence list
2022-07-30 11:42:24.559  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 39 from persistence list
2022-07-30 11:42:24.559  INFO   57 --- [-thread-pool-71] org.apache.spark.internal.Logging        : Removing RDD 40
2022-07-30 11:42:24.561  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[39] at receiverStream at Application.java:122 of time 1659177727000 ms
2022-07-30 11:42:24.559  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:42:24.561  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177725000 ms
2022-07-30 11:42:24.561  INFO   57 --- [-thread-pool-71] org.apache.spark.internal.Logging        : Removing RDD 39
2022-07-30 11:42:24.562  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177725000 ms
2022-07-30 11:42:24.562  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:42:24.636  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:42:24.637  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 250 (count at Application.java:147) as input to shuffle 19
2022-07-30 11:42:24.638  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 23 (count at Application.java:147) with 1 output partitions
2022-07-30 11:42:24.638  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 43 (count at Application.java:147)
2022-07-30 11:42:24.638  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 42)
2022-07-30 11:42:24.639  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:42:24.639  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 43 (MapPartitionsRDD[253] at count at Application.java:147), which has no missing parents
2022-07-30 11:42:24.641  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_23 stored as values in memory (estimated size 11.0 KiB, free 897.0 MiB)
2022-07-30 11:42:24.645  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_23_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.0 MiB)
2022-07-30 11:42:24.646  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_23_piece0 in memory on host.docker.internal:58170 (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:42:24.646  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 23 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:42:24.647  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 43 (MapPartitionsRDD[253] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:42:24.647  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 43.0 with 1 tasks resource profile 0
2022-07-30 11:42:24.648  INFO   57 --- [er-event-loop-1] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 43.0 (TID 23) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:42:24.649  INFO   57 --- [e 43.0 (TID 23)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 43.0 (TID 23)
2022-07-30 11:42:24.653  INFO   57 --- [e 43.0 (TID 23)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:42:24.654  INFO   57 --- [e 43.0 (TID 23)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 1 ms
2022-07-30 11:42:24.655  INFO   57 --- [e 43.0 (TID 23)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 43.0 (TID 23). 2598 bytes result sent to driver
2022-07-30 11:42:24.656  INFO   57 --- [result-getter-2] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 43.0 (TID 23) in 8 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:42:24.656  INFO   57 --- [result-getter-2] org.apache.spark.internal.Logging        : Removed TaskSet 43.0, whose tasks have all completed, from pool 
2022-07-30 11:42:24.657  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 43 (count at Application.java:147) finished in 0.017 s
2022-07-30 11:42:24.658  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 23 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:42:24.658  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 43: Stage finished
2022-07-30 11:42:24.659  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 23 finished: count at Application.java:147, took 0.022447 s
2022-07-30 11:42:24.662  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177728000 ms.0 from job set of time 1659177728000 ms
2022-07-30 11:42:24.662  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 16.662 s for time 1659177728000 ms (execution: 0.105 s)
2022-07-30 11:42:24.663  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177729000 ms.0 from job set of time 1659177729000 ms
2022-07-30 11:42:24.664  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:42:24.664  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:42:24.664  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 49 from persistence list
2022-07-30 11:42:24.666  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 48 from persistence list
2022-07-30 11:42:24.666  INFO   57 --- [-thread-pool-77] org.apache.spark.internal.Logging        : Removing RDD 49
2022-07-30 11:42:24.667  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[48] at receiverStream at Application.java:122 of time 1659177728000 ms
2022-07-30 11:42:24.669  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177726000 ms
2022-07-30 11:42:24.669  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177726000 ms
2022-07-30 11:42:24.669  INFO   57 --- [-thread-pool-80] org.apache.spark.internal.Logging        : Removing RDD 48
2022-07-30 11:42:24.772  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:42:24.773  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 259 (count at Application.java:147) as input to shuffle 20
2022-07-30 11:42:24.774  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 24 (count at Application.java:147) with 1 output partitions
2022-07-30 11:42:24.774  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 45 (count at Application.java:147)
2022-07-30 11:42:24.774  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 44)
2022-07-30 11:42:24.774  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:42:24.775  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 45 (MapPartitionsRDD[262] at count at Application.java:147), which has no missing parents
2022-07-30 11:42:24.779  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_24 stored as values in memory (estimated size 11.0 KiB, free 897.0 MiB)
2022-07-30 11:42:24.782  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_24_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.0 MiB)
2022-07-30 11:42:24.783  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_24_piece0 in memory on host.docker.internal:58170 (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:42:24.784  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 24 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:42:24.784  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 45 (MapPartitionsRDD[262] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:42:24.784  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 45.0 with 1 tasks resource profile 0
2022-07-30 11:42:24.786  INFO   57 --- [er-event-loop-0] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 45.0 (TID 24) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:42:24.787  INFO   57 --- [e 45.0 (TID 24)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 45.0 (TID 24)
2022-07-30 11:42:24.791  INFO   57 --- [e 45.0 (TID 24)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:42:24.792  INFO   57 --- [e 45.0 (TID 24)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-30 11:42:24.793  INFO   57 --- [e 45.0 (TID 24)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 45.0 (TID 24). 2555 bytes result sent to driver
2022-07-30 11:42:24.797  INFO   57 --- [result-getter-3] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 45.0 (TID 24) in 11 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:42:24.797  INFO   57 --- [result-getter-3] org.apache.spark.internal.Logging        : Removed TaskSet 45.0, whose tasks have all completed, from pool 
2022-07-30 11:42:24.798  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 45 (count at Application.java:147) finished in 0.022 s
2022-07-30 11:42:24.798  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 24 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:42:24.799  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 45: Stage finished
2022-07-30 11:42:24.800  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 24 finished: count at Application.java:147, took 0.027773 s
2022-07-30 11:42:24.802  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177729000 ms.0 from job set of time 1659177729000 ms
2022-07-30 11:42:24.802  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 15.802 s for time 1659177729000 ms (execution: 0.139 s)
2022-07-30 11:42:24.802  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177730000 ms.0 from job set of time 1659177730000 ms
2022-07-30 11:42:24.803  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 85 from persistence list
2022-07-30 11:42:24.804  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:42:24.804  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:42:24.804  INFO   57 --- [-thread-pool-83] org.apache.spark.internal.Logging        : Removing RDD 85
2022-07-30 11:42:24.805  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 84 from persistence list
2022-07-30 11:42:24.806  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[84] at receiverStream at Application.java:122 of time 1659177729000 ms
2022-07-30 11:42:24.807  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177727000 ms
2022-07-30 11:42:24.807  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177727000 ms
2022-07-30 11:42:24.808  INFO   57 --- [-thread-pool-88] org.apache.spark.internal.Logging        : Removing RDD 84
2022-07-30 11:42:24.875  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:42:24.878  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 268 (count at Application.java:147) as input to shuffle 21
2022-07-30 11:42:24.880  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 25 (count at Application.java:147) with 1 output partitions
2022-07-30 11:42:24.880  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 47 (count at Application.java:147)
2022-07-30 11:42:24.881  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 46)
2022-07-30 11:42:24.881  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:42:24.881  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 47 (MapPartitionsRDD[271] at count at Application.java:147), which has no missing parents
2022-07-30 11:42:24.883  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_25 stored as values in memory (estimated size 11.0 KiB, free 897.0 MiB)
2022-07-30 11:42:24.889  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_25_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.0 MiB)
2022-07-30 11:42:24.890  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_25_piece0 in memory on host.docker.internal:58170 (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:42:24.890  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 25 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:42:24.891  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 47 (MapPartitionsRDD[271] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:42:24.891  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 47.0 with 1 tasks resource profile 0
2022-07-30 11:42:24.893  INFO   57 --- [er-event-loop-3] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 47.0 (TID 25) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:42:24.898  INFO   57 --- [e 47.0 (TID 25)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 47.0 (TID 25)
2022-07-30 11:42:24.904  INFO   57 --- [e 47.0 (TID 25)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:42:24.904  INFO   57 --- [e 47.0 (TID 25)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-30 11:42:24.906  INFO   57 --- [e 47.0 (TID 25)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 47.0 (TID 25). 2598 bytes result sent to driver
2022-07-30 11:42:24.907  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 47.0 (TID 25) in 15 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:42:24.907  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Removed TaskSet 47.0, whose tasks have all completed, from pool 
2022-07-30 11:42:24.908  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 47 (count at Application.java:147) finished in 0.026 s
2022-07-30 11:42:24.908  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 25 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:42:24.908  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 47: Stage finished
2022-07-30 11:42:24.916  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 25 finished: count at Application.java:147, took 0.039662 s
2022-07-30 11:42:24.920  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177730000 ms.0 from job set of time 1659177730000 ms
2022-07-30 11:42:24.920  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 14.920 s for time 1659177730000 ms (execution: 0.118 s)
2022-07-30 11:42:24.921  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177731000 ms.0 from job set of time 1659177731000 ms
2022-07-30 11:42:24.922  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 125 from persistence list
2022-07-30 11:42:24.920  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:42:24.923  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:42:24.925  INFO   57 --- [-thread-pool-90] org.apache.spark.internal.Logging        : Removing RDD 125
2022-07-30 11:42:24.925  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 124 from persistence list
2022-07-30 11:42:24.935  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[124] at receiverStream at Application.java:122 of time 1659177730000 ms
2022-07-30 11:42:24.935  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177728000 ms
2022-07-30 11:42:24.936  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177728000 ms
2022-07-30 11:42:24.936  INFO   57 --- [-thread-pool-92] org.apache.spark.internal.Logging        : Removing RDD 124
2022-07-30 11:42:25.002  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177745000 ms
2022-07-30 11:42:25.007  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:42:25.008  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 277 (count at Application.java:147) as input to shuffle 22
2022-07-30 11:42:25.009  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 26 (count at Application.java:147) with 1 output partitions
2022-07-30 11:42:25.009  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 49 (count at Application.java:147)
2022-07-30 11:42:25.009  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 48)
2022-07-30 11:42:25.009  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:42:25.010  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 49 (MapPartitionsRDD[280] at count at Application.java:147), which has no missing parents
2022-07-30 11:42:25.020  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_26 stored as values in memory (estimated size 11.0 KiB, free 897.0 MiB)
2022-07-30 11:42:25.022  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_26_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.0 MiB)
2022-07-30 11:42:25.022  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_26_piece0 in memory on host.docker.internal:58170 (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:42:25.023  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 26 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:42:25.024  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 49 (MapPartitionsRDD[280] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:42:25.024  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 49.0 with 1 tasks resource profile 0
2022-07-30 11:42:25.025  INFO   57 --- [er-event-loop-0] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 49.0 (TID 26) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:42:25.026  INFO   57 --- [e 49.0 (TID 26)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 49.0 (TID 26)
2022-07-30 11:42:25.030  INFO   57 --- [e 49.0 (TID 26)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:42:25.031  INFO   57 --- [e 49.0 (TID 26)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-30 11:42:25.032  INFO   57 --- [e 49.0 (TID 26)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 49.0 (TID 26). 2598 bytes result sent to driver
2022-07-30 11:42:25.033  INFO   57 --- [result-getter-1] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 49.0 (TID 26) in 8 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:42:25.033  INFO   57 --- [result-getter-1] org.apache.spark.internal.Logging        : Removed TaskSet 49.0, whose tasks have all completed, from pool 
2022-07-30 11:42:25.034  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 49 (count at Application.java:147) finished in 0.023 s
2022-07-30 11:42:25.034  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 26 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:42:25.035  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 49: Stage finished
2022-07-30 11:42:25.036  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 26 finished: count at Application.java:147, took 0.028556 s
2022-07-30 11:42:25.039  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177731000 ms.0 from job set of time 1659177731000 ms
2022-07-30 11:42:25.040  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 14.038 s for time 1659177731000 ms (execution: 0.117 s)
2022-07-30 11:42:25.040  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177732000 ms.0 from job set of time 1659177732000 ms
2022-07-30 11:42:25.041  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 129 from persistence list
2022-07-30 11:42:25.041  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:42:25.042  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:42:25.045  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 128 from persistence list
2022-07-30 11:42:25.045  INFO   57 --- [-thread-pool-96] org.apache.spark.internal.Logging        : Removing RDD 129
2022-07-30 11:42:25.050  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[128] at receiverStream at Application.java:122 of time 1659177731000 ms
2022-07-30 11:42:25.051  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177729000 ms
2022-07-30 11:42:25.051  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177729000 ms
2022-07-30 11:42:25.051  INFO   57 --- [-thread-pool-97] org.apache.spark.internal.Logging        : Removing RDD 128
2022-07-30 11:42:25.180  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:42:25.181  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 288 (count at Application.java:147) as input to shuffle 23
2022-07-30 11:42:25.182  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 27 (count at Application.java:147) with 1 output partitions
2022-07-30 11:42:25.182  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 51 (count at Application.java:147)
2022-07-30 11:42:25.182  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 50)
2022-07-30 11:42:25.183  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:42:25.185  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 51 (MapPartitionsRDD[291] at count at Application.java:147), which has no missing parents
2022-07-30 11:42:25.197  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_27 stored as values in memory (estimated size 11.0 KiB, free 897.0 MiB)
2022-07-30 11:42:25.201  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_27_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.0 MiB)
2022-07-30 11:42:25.202  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_27_piece0 in memory on host.docker.internal:58170 (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:42:25.203  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 27 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:42:25.203  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 51 (MapPartitionsRDD[291] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:42:25.203  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 51.0 with 1 tasks resource profile 0
2022-07-30 11:42:25.204  INFO   57 --- [er-event-loop-3] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 51.0 (TID 27) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:42:25.205  INFO   57 --- [e 51.0 (TID 27)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 51.0 (TID 27)
2022-07-30 11:42:25.209  INFO   57 --- [e 51.0 (TID 27)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:42:25.210  INFO   57 --- [e 51.0 (TID 27)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-30 11:42:25.213  INFO   57 --- [e 51.0 (TID 27)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 51.0 (TID 27). 2555 bytes result sent to driver
2022-07-30 11:42:25.214  INFO   57 --- [result-getter-2] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 51.0 (TID 27) in 10 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:42:25.214  INFO   57 --- [result-getter-2] org.apache.spark.internal.Logging        : Removed TaskSet 51.0, whose tasks have all completed, from pool 
2022-07-30 11:42:25.215  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 51 (count at Application.java:147) finished in 0.027 s
2022-07-30 11:42:25.215  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 27 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:42:25.215  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 51: Stage finished
2022-07-30 11:42:25.216  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 27 finished: count at Application.java:147, took 0.035180 s
2022-07-30 11:42:25.217  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177732000 ms.0 from job set of time 1659177732000 ms
2022-07-30 11:42:25.217  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 13.217 s for time 1659177732000 ms (execution: 0.177 s)
2022-07-30 11:42:25.218  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177733000 ms.0 from job set of time 1659177733000 ms
2022-07-30 11:42:25.218  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 133 from persistence list
2022-07-30 11:42:25.219  INFO   57 --- [-thread-pool-99] org.apache.spark.internal.Logging        : Removing RDD 133
2022-07-30 11:42:25.219  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:42:25.219  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:42:25.219  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 132 from persistence list
2022-07-30 11:42:25.221  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[132] at receiverStream at Application.java:122 of time 1659177732000 ms
2022-07-30 11:42:25.221  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177730000 ms
2022-07-30 11:42:25.221  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177730000 ms
2022-07-30 11:42:25.222  INFO   57 --- [c-thread-pool-5] org.apache.spark.internal.Logging        : Removing RDD 132
2022-07-30 11:42:25.274  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:42:25.275  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 297 (count at Application.java:147) as input to shuffle 24
2022-07-30 11:42:25.275  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 28 (count at Application.java:147) with 1 output partitions
2022-07-30 11:42:25.275  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 53 (count at Application.java:147)
2022-07-30 11:42:25.275  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 52)
2022-07-30 11:42:25.276  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:42:25.276  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 53 (MapPartitionsRDD[300] at count at Application.java:147), which has no missing parents
2022-07-30 11:42:25.278  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_28 stored as values in memory (estimated size 11.0 KiB, free 897.0 MiB)
2022-07-30 11:42:25.279  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_28_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.0 MiB)
2022-07-30 11:42:25.280  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_28_piece0 in memory on host.docker.internal:58170 (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:42:25.280  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 28 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:42:25.281  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 53 (MapPartitionsRDD[300] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:42:25.281  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 53.0 with 1 tasks resource profile 0
2022-07-30 11:42:25.282  INFO   57 --- [er-event-loop-2] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 53.0 (TID 28) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:42:25.283  INFO   57 --- [e 53.0 (TID 28)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 53.0 (TID 28)
2022-07-30 11:42:25.285  INFO   57 --- [e 53.0 (TID 28)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:42:25.286  INFO   57 --- [e 53.0 (TID 28)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-30 11:42:25.287  INFO   57 --- [e 53.0 (TID 28)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 53.0 (TID 28). 2555 bytes result sent to driver
2022-07-30 11:42:25.288  INFO   57 --- [result-getter-3] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 53.0 (TID 28) in 5 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:42:25.288  INFO   57 --- [result-getter-3] org.apache.spark.internal.Logging        : Removed TaskSet 53.0, whose tasks have all completed, from pool 
2022-07-30 11:42:25.288  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 53 (count at Application.java:147) finished in 0.011 s
2022-07-30 11:42:25.288  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 28 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:42:25.289  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 53: Stage finished
2022-07-30 11:42:25.289  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 28 finished: count at Application.java:147, took 0.014507 s
2022-07-30 11:42:25.290  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177733000 ms.0 from job set of time 1659177733000 ms
2022-07-30 11:42:25.290  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 12.290 s for time 1659177733000 ms (execution: 0.072 s)
2022-07-30 11:42:25.290  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177734000 ms.0 from job set of time 1659177734000 ms
2022-07-30 11:42:25.292  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 135 from persistence list
2022-07-30 11:42:25.292  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:42:25.293  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:42:25.300  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 134 from persistence list
2022-07-30 11:42:25.300  INFO   57 --- [c-thread-pool-6] org.apache.spark.internal.Logging        : Removing RDD 135
2022-07-30 11:42:25.301  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[134] at receiverStream at Application.java:122 of time 1659177733000 ms
2022-07-30 11:42:25.303  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177731000 ms
2022-07-30 11:42:25.303  INFO   57 --- [c-thread-pool-9] org.apache.spark.internal.Logging        : Removing RDD 134
2022-07-30 11:42:25.304  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177731000 ms
2022-07-30 11:42:25.359  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:42:25.360  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 306 (count at Application.java:147) as input to shuffle 25
2022-07-30 11:42:25.361  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 29 (count at Application.java:147) with 1 output partitions
2022-07-30 11:42:25.362  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 55 (count at Application.java:147)
2022-07-30 11:42:25.362  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 54)
2022-07-30 11:42:25.363  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:42:25.363  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 55 (MapPartitionsRDD[309] at count at Application.java:147), which has no missing parents
2022-07-30 11:42:25.366  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_29 stored as values in memory (estimated size 11.0 KiB, free 896.9 MiB)
2022-07-30 11:42:25.368  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_29_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 896.9 MiB)
2022-07-30 11:42:25.368  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_29_piece0 in memory on host.docker.internal:58170 (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:42:25.369  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 29 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:42:25.369  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 55 (MapPartitionsRDD[309] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:42:25.369  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 55.0 with 1 tasks resource profile 0
2022-07-30 11:42:25.371  INFO   57 --- [er-event-loop-1] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 55.0 (TID 29) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:42:25.372  INFO   57 --- [e 55.0 (TID 29)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 55.0 (TID 29)
2022-07-30 11:42:25.375  INFO   57 --- [e 55.0 (TID 29)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:42:25.375  INFO   57 --- [e 55.0 (TID 29)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-30 11:42:25.376  INFO   57 --- [e 55.0 (TID 29)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 55.0 (TID 29). 2555 bytes result sent to driver
2022-07-30 11:42:25.379  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 55.0 (TID 29) in 9 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:42:25.379  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Removed TaskSet 55.0, whose tasks have all completed, from pool 
2022-07-30 11:42:25.380  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 55 (count at Application.java:147) finished in 0.016 s
2022-07-30 11:42:25.380  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 29 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:42:25.381  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 55: Stage finished
2022-07-30 11:42:25.381  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 29 finished: count at Application.java:147, took 0.021651 s
2022-07-30 11:42:25.382  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177734000 ms.0 from job set of time 1659177734000 ms
2022-07-30 11:42:25.382  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 11.382 s for time 1659177734000 ms (execution: 0.092 s)
2022-07-30 11:42:25.383  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177735000 ms.0 from job set of time 1659177735000 ms
2022-07-30 11:42:25.384  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 140 from persistence list
2022-07-30 11:42:25.385  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:42:25.386  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:42:25.388  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 139 from persistence list
2022-07-30 11:42:25.388  INFO   57 --- [-thread-pool-11] org.apache.spark.internal.Logging        : Removing RDD 140
2022-07-30 11:42:25.389  INFO   57 --- [-thread-pool-17] org.apache.spark.internal.Logging        : Removing RDD 139
2022-07-30 11:42:25.389  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[139] at receiverStream at Application.java:122 of time 1659177734000 ms
2022-07-30 11:42:25.390  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177732000 ms
2022-07-30 11:42:25.390  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177732000 ms
2022-07-30 11:42:25.463  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:42:25.464  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 315 (count at Application.java:147) as input to shuffle 26
2022-07-30 11:42:25.464  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 30 (count at Application.java:147) with 1 output partitions
2022-07-30 11:42:25.465  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 57 (count at Application.java:147)
2022-07-30 11:42:25.465  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 56)
2022-07-30 11:42:25.465  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:42:25.465  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 57 (MapPartitionsRDD[318] at count at Application.java:147), which has no missing parents
2022-07-30 11:42:25.467  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_30 stored as values in memory (estimated size 11.0 KiB, free 896.9 MiB)
2022-07-30 11:42:25.469  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_30_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 896.9 MiB)
2022-07-30 11:42:25.470  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_30_piece0 in memory on host.docker.internal:58170 (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:42:25.470  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 30 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:42:25.471  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 57 (MapPartitionsRDD[318] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:42:25.471  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 57.0 with 1 tasks resource profile 0
2022-07-30 11:42:25.472  INFO   57 --- [er-event-loop-0] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 57.0 (TID 30) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:42:25.473  INFO   57 --- [e 57.0 (TID 30)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 57.0 (TID 30)
2022-07-30 11:42:25.479  INFO   57 --- [e 57.0 (TID 30)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:42:25.479  INFO   57 --- [e 57.0 (TID 30)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-30 11:42:25.481  INFO   57 --- [e 57.0 (TID 30)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 57.0 (TID 30). 2555 bytes result sent to driver
2022-07-30 11:42:25.481  INFO   57 --- [result-getter-1] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 57.0 (TID 30) in 9 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:42:25.482  INFO   57 --- [result-getter-1] org.apache.spark.internal.Logging        : Removed TaskSet 57.0, whose tasks have all completed, from pool 
2022-07-30 11:42:25.482  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 57 (count at Application.java:147) finished in 0.016 s
2022-07-30 11:42:25.482  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 30 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:42:25.483  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 57: Stage finished
2022-07-30 11:42:25.483  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 30 finished: count at Application.java:147, took 0.019341 s
2022-07-30 11:42:25.484  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177735000 ms.0 from job set of time 1659177735000 ms
2022-07-30 11:42:25.484  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 10.484 s for time 1659177735000 ms (execution: 0.101 s)
2022-07-30 11:42:25.485  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177736000 ms.0 from job set of time 1659177736000 ms
2022-07-30 11:42:25.486  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 142 from persistence list
2022-07-30 11:42:25.487  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:42:25.487  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:42:25.488  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 141 from persistence list
2022-07-30 11:42:25.488  INFO   57 --- [-thread-pool-18] org.apache.spark.internal.Logging        : Removing RDD 142
2022-07-30 11:42:25.488  INFO   57 --- [-thread-pool-18] org.apache.spark.internal.Logging        : Removing RDD 141
2022-07-30 11:42:25.489  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[141] at receiverStream at Application.java:122 of time 1659177735000 ms
2022-07-30 11:42:25.489  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177733000 ms
2022-07-30 11:42:25.490  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177733000 ms
2022-07-30 11:42:25.556  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:42:25.557  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 324 (count at Application.java:147) as input to shuffle 27
2022-07-30 11:42:25.557  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 31 (count at Application.java:147) with 1 output partitions
2022-07-30 11:42:25.557  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 59 (count at Application.java:147)
2022-07-30 11:42:25.558  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 58)
2022-07-30 11:42:25.558  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:42:25.558  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 59 (MapPartitionsRDD[327] at count at Application.java:147), which has no missing parents
2022-07-30 11:42:25.562  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_31 stored as values in memory (estimated size 11.0 KiB, free 896.9 MiB)
2022-07-30 11:42:25.565  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_31_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 896.9 MiB)
2022-07-30 11:42:25.565  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_31_piece0 in memory on host.docker.internal:58170 (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:42:25.566  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 31 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:42:25.567  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 59 (MapPartitionsRDD[327] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:42:25.567  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 59.0 with 1 tasks resource profile 0
2022-07-30 11:42:25.568  INFO   57 --- [er-event-loop-3] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 59.0 (TID 31) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:42:25.571  INFO   57 --- [e 59.0 (TID 31)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 59.0 (TID 31)
2022-07-30 11:42:25.578  INFO   57 --- [e 59.0 (TID 31)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:42:25.579  INFO   57 --- [e 59.0 (TID 31)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 2 ms
2022-07-30 11:42:25.581  INFO   57 --- [e 59.0 (TID 31)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 59.0 (TID 31). 2555 bytes result sent to driver
2022-07-30 11:42:25.582  INFO   57 --- [result-getter-2] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 59.0 (TID 31) in 14 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:42:25.582  INFO   57 --- [result-getter-2] org.apache.spark.internal.Logging        : Removed TaskSet 59.0, whose tasks have all completed, from pool 
2022-07-30 11:42:25.586  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 59 (count at Application.java:147) finished in 0.024 s
2022-07-30 11:42:25.587  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 31 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:42:25.587  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 59: Stage finished
2022-07-30 11:42:25.588  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 31 finished: count at Application.java:147, took 0.031832 s
2022-07-30 11:42:25.591  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177736000 ms.0 from job set of time 1659177736000 ms
2022-07-30 11:42:25.591  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 9.591 s for time 1659177736000 ms (execution: 0.106 s)
2022-07-30 11:42:25.592  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177737000 ms.0 from job set of time 1659177737000 ms
2022-07-30 11:42:25.593  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:42:25.597  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:42:25.607  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 144 from persistence list
2022-07-30 11:42:25.624  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 143 from persistence list
2022-07-30 11:42:25.635  INFO   57 --- [-thread-pool-25] org.apache.spark.internal.Logging        : Removing RDD 144
2022-07-30 11:42:25.648  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[143] at receiverStream at Application.java:122 of time 1659177736000 ms
2022-07-30 11:42:25.648  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177734000 ms
2022-07-30 11:42:25.649  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177734000 ms
2022-07-30 11:42:25.649  INFO   57 --- [-thread-pool-27] org.apache.spark.internal.Logging        : Removing RDD 143
2022-07-30 11:42:25.700  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:42:25.701  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 333 (count at Application.java:147) as input to shuffle 28
2022-07-30 11:42:25.702  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 32 (count at Application.java:147) with 1 output partitions
2022-07-30 11:42:25.702  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 61 (count at Application.java:147)
2022-07-30 11:42:25.702  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 60)
2022-07-30 11:42:25.702  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:42:25.702  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 61 (MapPartitionsRDD[336] at count at Application.java:147), which has no missing parents
2022-07-30 11:42:25.704  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_32 stored as values in memory (estimated size 11.0 KiB, free 896.9 MiB)
2022-07-30 11:42:25.707  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_32_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 896.9 MiB)
2022-07-30 11:42:25.708  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_32_piece0 in memory on host.docker.internal:58170 (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:42:25.708  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 32 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:42:25.708  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 61 (MapPartitionsRDD[336] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:42:25.709  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 61.0 with 1 tasks resource profile 0
2022-07-30 11:42:25.709  INFO   57 --- [er-event-loop-2] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 61.0 (TID 32) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:42:25.710  INFO   57 --- [e 61.0 (TID 32)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 61.0 (TID 32)
2022-07-30 11:42:25.713  INFO   57 --- [e 61.0 (TID 32)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:42:25.714  INFO   57 --- [e 61.0 (TID 32)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-30 11:42:25.715  INFO   57 --- [e 61.0 (TID 32)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 61.0 (TID 32). 2555 bytes result sent to driver
2022-07-30 11:42:25.716  INFO   57 --- [result-getter-3] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 61.0 (TID 32) in 7 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:42:25.716  INFO   57 --- [result-getter-3] org.apache.spark.internal.Logging        : Removed TaskSet 61.0, whose tasks have all completed, from pool 
2022-07-30 11:42:25.716  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 61 (count at Application.java:147) finished in 0.013 s
2022-07-30 11:42:25.717  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 32 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:42:25.717  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 61: Stage finished
2022-07-30 11:42:25.717  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 32 finished: count at Application.java:147, took 0.016579 s
2022-07-30 11:42:25.718  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177737000 ms.0 from job set of time 1659177737000 ms
2022-07-30 11:42:25.719  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 8.718 s for time 1659177737000 ms (execution: 0.126 s)
2022-07-30 11:42:25.719  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177738000 ms.0 from job set of time 1659177738000 ms
2022-07-30 11:42:25.719  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 146 from persistence list
2022-07-30 11:42:25.720  INFO   57 --- [-thread-pool-33] org.apache.spark.internal.Logging        : Removing RDD 146
2022-07-30 11:42:25.721  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:42:25.721  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:42:25.720  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 145 from persistence list
2022-07-30 11:42:25.737  INFO   57 --- [-thread-pool-34] org.apache.spark.internal.Logging        : Removing RDD 145
2022-07-30 11:42:25.738  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[145] at receiverStream at Application.java:122 of time 1659177737000 ms
2022-07-30 11:42:25.738  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177735000 ms
2022-07-30 11:42:25.738  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177735000 ms
2022-07-30 11:42:25.740  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_17_piece0 on host.docker.internal:58170 in memory (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:42:25.743  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_14_piece0 on host.docker.internal:58170 in memory (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:42:25.746  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_24_piece0 on host.docker.internal:58170 in memory (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:42:25.749  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_28_piece0 on host.docker.internal:58170 in memory (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:42:25.753  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_15_piece0 on host.docker.internal:58170 in memory (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:42:25.756  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_19_piece0 on host.docker.internal:58170 in memory (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:42:25.762  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_30_piece0 on host.docker.internal:58170 in memory (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:42:25.764  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_16_piece0 on host.docker.internal:58170 in memory (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:42:25.766  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_22_piece0 on host.docker.internal:58170 in memory (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:42:25.774  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_18_piece0 on host.docker.internal:58170 in memory (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:42:25.801  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_27_piece0 on host.docker.internal:58170 in memory (size: 5.4 KiB, free: 897.5 MiB)
2022-07-30 11:42:25.805  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_20_piece0 on host.docker.internal:58170 in memory (size: 5.4 KiB, free: 897.5 MiB)
2022-07-30 11:42:25.808  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_23_piece0 on host.docker.internal:58170 in memory (size: 5.4 KiB, free: 897.5 MiB)
2022-07-30 11:42:25.811  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_21_piece0 on host.docker.internal:58170 in memory (size: 5.4 KiB, free: 897.5 MiB)
2022-07-30 11:42:25.816  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_26_piece0 on host.docker.internal:58170 in memory (size: 5.4 KiB, free: 897.5 MiB)
2022-07-30 11:42:25.820  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_29_piece0 on host.docker.internal:58170 in memory (size: 5.4 KiB, free: 897.5 MiB)
2022-07-30 11:42:25.823  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_32_piece0 on host.docker.internal:58170 in memory (size: 5.4 KiB, free: 897.5 MiB)
2022-07-30 11:42:25.826  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_31_piece0 on host.docker.internal:58170 in memory (size: 5.4 KiB, free: 897.5 MiB)
2022-07-30 11:42:25.830  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Removed broadcast_25_piece0 on host.docker.internal:58170 in memory (size: 5.4 KiB, free: 897.5 MiB)
2022-07-30 11:42:25.846  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:42:25.848  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 342 (count at Application.java:147) as input to shuffle 29
2022-07-30 11:42:25.849  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 33 (count at Application.java:147) with 1 output partitions
2022-07-30 11:42:25.849  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 63 (count at Application.java:147)
2022-07-30 11:42:25.849  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 62)
2022-07-30 11:42:25.849  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:42:25.849  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 63 (MapPartitionsRDD[345] at count at Application.java:147), which has no missing parents
2022-07-30 11:42:25.851  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_33 stored as values in memory (estimated size 11.0 KiB, free 897.2 MiB)
2022-07-30 11:42:25.853  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_33_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.2 MiB)
2022-07-30 11:42:25.854  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_33_piece0 in memory on host.docker.internal:58170 (size: 5.4 KiB, free: 897.5 MiB)
2022-07-30 11:42:25.854  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 33 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:42:25.855  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 63 (MapPartitionsRDD[345] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:42:25.855  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 63.0 with 1 tasks resource profile 0
2022-07-30 11:42:25.856  INFO   57 --- [er-event-loop-1] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 63.0 (TID 33) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:42:25.856  INFO   57 --- [e 63.0 (TID 33)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 63.0 (TID 33)
2022-07-30 11:42:25.858  INFO   57 --- [e 63.0 (TID 33)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:42:25.859  INFO   57 --- [e 63.0 (TID 33)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-30 11:42:25.859  INFO   57 --- [e 63.0 (TID 33)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 63.0 (TID 33). 2598 bytes result sent to driver
2022-07-30 11:42:25.860  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 63.0 (TID 33) in 4 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:42:25.862  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Removed TaskSet 63.0, whose tasks have all completed, from pool 
2022-07-30 11:42:25.863  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 63 (count at Application.java:147) finished in 0.013 s
2022-07-30 11:42:25.864  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 33 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:42:25.864  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 63: Stage finished
2022-07-30 11:42:25.865  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 33 finished: count at Application.java:147, took 0.017534 s
2022-07-30 11:42:25.865  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177738000 ms.0 from job set of time 1659177738000 ms
2022-07-30 11:42:25.866  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 7.865 s for time 1659177738000 ms (execution: 0.146 s)
2022-07-30 11:42:25.866  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177739000 ms.0 from job set of time 1659177739000 ms
2022-07-30 11:42:25.868  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:42:25.868  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:42:25.868  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 149 from persistence list
2022-07-30 11:42:25.869  INFO   57 --- [-thread-pool-49] org.apache.spark.internal.Logging        : Removing RDD 149
2022-07-30 11:42:25.870  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 148 from persistence list
2022-07-30 11:42:25.871  INFO   57 --- [-thread-pool-54] org.apache.spark.internal.Logging        : Removing RDD 148
2022-07-30 11:42:25.871  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[148] at receiverStream at Application.java:122 of time 1659177738000 ms
2022-07-30 11:42:25.871  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177736000 ms
2022-07-30 11:42:25.871  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177736000 ms
2022-07-30 11:42:25.936  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:42:25.937  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 351 (count at Application.java:147) as input to shuffle 30
2022-07-30 11:42:25.938  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 34 (count at Application.java:147) with 1 output partitions
2022-07-30 11:42:25.938  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 65 (count at Application.java:147)
2022-07-30 11:42:25.938  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 64)
2022-07-30 11:42:25.938  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:42:25.938  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 65 (MapPartitionsRDD[354] at count at Application.java:147), which has no missing parents
2022-07-30 11:42:25.940  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_34 stored as values in memory (estimated size 11.0 KiB, free 897.2 MiB)
2022-07-30 11:42:25.945  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_34_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.2 MiB)
2022-07-30 11:42:25.945  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_34_piece0 in memory on host.docker.internal:58170 (size: 5.4 KiB, free: 897.5 MiB)
2022-07-30 11:42:25.946  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 34 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:42:25.946  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 65 (MapPartitionsRDD[354] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:42:25.947  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 65.0 with 1 tasks resource profile 0
2022-07-30 11:42:25.947  INFO   57 --- [er-event-loop-0] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 65.0 (TID 34) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:42:25.948  INFO   57 --- [e 65.0 (TID 34)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 65.0 (TID 34)
2022-07-30 11:42:25.951  INFO   57 --- [e 65.0 (TID 34)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:42:25.951  INFO   57 --- [e 65.0 (TID 34)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-30 11:42:25.952  INFO   57 --- [e 65.0 (TID 34)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 65.0 (TID 34). 2598 bytes result sent to driver
2022-07-30 11:42:25.953  INFO   57 --- [result-getter-1] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 65.0 (TID 34) in 6 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:42:25.954  INFO   57 --- [result-getter-1] org.apache.spark.internal.Logging        : Removed TaskSet 65.0, whose tasks have all completed, from pool 
2022-07-30 11:42:25.954  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 65 (count at Application.java:147) finished in 0.015 s
2022-07-30 11:42:25.954  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 34 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:42:25.954  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 65: Stage finished
2022-07-30 11:42:25.955  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 34 finished: count at Application.java:147, took 0.018106 s
2022-07-30 11:42:25.956  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177739000 ms.0 from job set of time 1659177739000 ms
2022-07-30 11:42:25.956  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 6.956 s for time 1659177739000 ms (execution: 0.090 s)
2022-07-30 11:42:25.957  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177740000 ms.0 from job set of time 1659177740000 ms
2022-07-30 11:42:25.959  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 151 from persistence list
2022-07-30 11:42:25.959  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:42:25.960  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:42:25.960  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 150 from persistence list
2022-07-30 11:42:25.960  INFO   57 --- [-thread-pool-58] org.apache.spark.internal.Logging        : Removing RDD 151
2022-07-30 11:42:25.962  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[150] at receiverStream at Application.java:122 of time 1659177739000 ms
2022-07-30 11:42:25.963  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177737000 ms
2022-07-30 11:42:25.963  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177737000 ms
2022-07-30 11:42:25.963  INFO   57 --- [-thread-pool-59] org.apache.spark.internal.Logging        : Removing RDD 150
2022-07-30 11:42:26.002  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177746000 ms
2022-07-30 11:42:26.063  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:42:26.064  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 362 (count at Application.java:147) as input to shuffle 31
2022-07-30 11:42:26.065  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 35 (count at Application.java:147) with 1 output partitions
2022-07-30 11:42:26.065  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 67 (count at Application.java:147)
2022-07-30 11:42:26.065  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 66)
2022-07-30 11:42:26.065  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:42:26.066  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 67 (MapPartitionsRDD[365] at count at Application.java:147), which has no missing parents
2022-07-30 11:42:26.069  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_35 stored as values in memory (estimated size 11.0 KiB, free 897.2 MiB)
2022-07-30 11:42:26.071  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_35_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.1 MiB)
2022-07-30 11:42:26.073  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_35_piece0 in memory on host.docker.internal:58170 (size: 5.4 KiB, free: 897.5 MiB)
2022-07-30 11:42:26.074  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 35 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:42:26.075  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 67 (MapPartitionsRDD[365] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:42:26.075  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 67.0 with 1 tasks resource profile 0
2022-07-30 11:42:26.089  INFO   57 --- [er-event-loop-3] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 67.0 (TID 35) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:42:26.090  INFO   57 --- [e 67.0 (TID 35)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 67.0 (TID 35)
2022-07-30 11:42:26.098  INFO   57 --- [e 67.0 (TID 35)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:42:26.099  INFO   57 --- [e 67.0 (TID 35)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 1 ms
2022-07-30 11:42:26.101  INFO   57 --- [e 67.0 (TID 35)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 67.0 (TID 35). 2598 bytes result sent to driver
2022-07-30 11:42:26.102  INFO   57 --- [result-getter-2] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 67.0 (TID 35) in 22 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:42:26.102  INFO   57 --- [result-getter-2] org.apache.spark.internal.Logging        : Removed TaskSet 67.0, whose tasks have all completed, from pool 
2022-07-30 11:42:26.103  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 67 (count at Application.java:147) finished in 0.036 s
2022-07-30 11:42:26.104  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 35 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:42:26.104  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 67: Stage finished
2022-07-30 11:42:26.105  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 35 finished: count at Application.java:147, took 0.041621 s
2022-07-30 11:42:26.107  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177740000 ms.0 from job set of time 1659177740000 ms
2022-07-30 11:42:26.108  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 6.107 s for time 1659177740000 ms (execution: 0.151 s)
2022-07-30 11:42:26.108  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177741000 ms.0 from job set of time 1659177741000 ms
2022-07-30 11:42:26.115  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 153 from persistence list
2022-07-30 11:42:26.115  INFO   57 --- [-thread-pool-64] org.apache.spark.internal.Logging        : Removing RDD 153
2022-07-30 11:42:26.115  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 152 from persistence list
2022-07-30 11:42:26.116  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:42:26.117  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:42:26.117  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[152] at receiverStream at Application.java:122 of time 1659177740000 ms
2022-07-30 11:42:26.117  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177738000 ms
2022-07-30 11:42:26.118  INFO   57 --- [-thread-pool-68] org.apache.spark.internal.Logging        : Removing RDD 152
2022-07-30 11:42:26.118  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177738000 ms
2022-07-30 11:42:26.172  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:42:26.173  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 371 (count at Application.java:147) as input to shuffle 32
2022-07-30 11:42:26.173  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 36 (count at Application.java:147) with 1 output partitions
2022-07-30 11:42:26.173  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 69 (count at Application.java:147)
2022-07-30 11:42:26.173  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 68)
2022-07-30 11:42:26.174  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:42:26.174  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 69 (MapPartitionsRDD[374] at count at Application.java:147), which has no missing parents
2022-07-30 11:42:26.176  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_36 stored as values in memory (estimated size 11.0 KiB, free 897.1 MiB)
2022-07-30 11:42:26.188  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_36_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.1 MiB)
2022-07-30 11:42:26.189  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_36_piece0 in memory on host.docker.internal:58170 (size: 5.4 KiB, free: 897.5 MiB)
2022-07-30 11:42:26.190  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 36 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:42:26.190  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 69 (MapPartitionsRDD[374] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:42:26.191  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 69.0 with 1 tasks resource profile 0
2022-07-30 11:42:26.191  INFO   57 --- [er-event-loop-2] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 69.0 (TID 36) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:42:26.192  INFO   57 --- [e 69.0 (TID 36)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 69.0 (TID 36)
2022-07-30 11:42:26.195  INFO   57 --- [e 69.0 (TID 36)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:42:26.195  INFO   57 --- [e 69.0 (TID 36)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-30 11:42:26.196  INFO   57 --- [e 69.0 (TID 36)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 69.0 (TID 36). 2555 bytes result sent to driver
2022-07-30 11:42:26.197  INFO   57 --- [result-getter-3] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 69.0 (TID 36) in 6 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:42:26.197  INFO   57 --- [result-getter-3] org.apache.spark.internal.Logging        : Removed TaskSet 69.0, whose tasks have all completed, from pool 
2022-07-30 11:42:26.198  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 69 (count at Application.java:147) finished in 0.023 s
2022-07-30 11:42:26.198  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 36 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:42:26.198  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 69: Stage finished
2022-07-30 11:42:26.200  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 36 finished: count at Application.java:147, took 0.027117 s
2022-07-30 11:42:26.201  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177741000 ms.0 from job set of time 1659177741000 ms
2022-07-30 11:42:26.201  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 5.201 s for time 1659177741000 ms (execution: 0.093 s)
2022-07-30 11:42:26.202  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177742000 ms.0 from job set of time 1659177742000 ms
2022-07-30 11:42:26.203  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:42:26.203  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:42:26.205  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 155 from persistence list
2022-07-30 11:42:26.206  INFO   57 --- [-thread-pool-70] org.apache.spark.internal.Logging        : Removing RDD 155
2022-07-30 11:42:26.206  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 154 from persistence list
2022-07-30 11:42:26.207  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[154] at receiverStream at Application.java:122 of time 1659177741000 ms
2022-07-30 11:42:26.208  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177739000 ms
2022-07-30 11:42:26.208  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177739000 ms
2022-07-30 11:42:26.208  INFO   57 --- [-thread-pool-75] org.apache.spark.internal.Logging        : Removing RDD 154
2022-07-30 11:42:26.292  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:42:26.293  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 380 (count at Application.java:147) as input to shuffle 33
2022-07-30 11:42:26.293  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 37 (count at Application.java:147) with 1 output partitions
2022-07-30 11:42:26.293  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 71 (count at Application.java:147)
2022-07-30 11:42:26.293  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 70)
2022-07-30 11:42:26.295  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:42:26.296  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 71 (MapPartitionsRDD[383] at count at Application.java:147), which has no missing parents
2022-07-30 11:42:26.300  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_37 stored as values in memory (estimated size 11.0 KiB, free 897.1 MiB)
2022-07-30 11:42:26.307  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_37_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.1 MiB)
2022-07-30 11:42:26.309  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_37_piece0 in memory on host.docker.internal:58170 (size: 5.4 KiB, free: 897.5 MiB)
2022-07-30 11:42:26.312  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 37 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:42:26.313  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 71 (MapPartitionsRDD[383] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:42:26.314  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 71.0 with 1 tasks resource profile 0
2022-07-30 11:42:26.316  INFO   57 --- [er-event-loop-1] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 71.0 (TID 37) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:42:26.317  INFO   57 --- [e 71.0 (TID 37)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 71.0 (TID 37)
2022-07-30 11:42:26.321  INFO   57 --- [e 71.0 (TID 37)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:42:26.322  INFO   57 --- [e 71.0 (TID 37)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 1 ms
2022-07-30 11:42:26.323  INFO   57 --- [e 71.0 (TID 37)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 71.0 (TID 37). 2555 bytes result sent to driver
2022-07-30 11:42:26.324  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 71.0 (TID 37) in 9 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:42:26.324  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Removed TaskSet 71.0, whose tasks have all completed, from pool 
2022-07-30 11:42:26.325  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 71 (count at Application.java:147) finished in 0.028 s
2022-07-30 11:42:26.326  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 37 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:42:26.326  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 71: Stage finished
2022-07-30 11:42:26.329  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 37 finished: count at Application.java:147, took 0.036178 s
2022-07-30 11:42:26.330  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177742000 ms.0 from job set of time 1659177742000 ms
2022-07-30 11:42:26.331  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 4.330 s for time 1659177742000 ms (execution: 0.128 s)
2022-07-30 11:42:26.331  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177743000 ms.0 from job set of time 1659177743000 ms
2022-07-30 11:42:26.333  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:42:26.334  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:42:26.359  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 157 from persistence list
2022-07-30 11:42:26.371  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 156 from persistence list
2022-07-30 11:42:26.371  INFO   57 --- [-thread-pool-76] org.apache.spark.internal.Logging        : Removing RDD 157
2022-07-30 11:42:26.372  INFO   57 --- [-thread-pool-77] org.apache.spark.internal.Logging        : Removing RDD 156
2022-07-30 11:42:26.373  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[156] at receiverStream at Application.java:122 of time 1659177742000 ms
2022-07-30 11:42:26.373  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177740000 ms
2022-07-30 11:42:26.373  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177740000 ms
2022-07-30 11:42:26.434  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:42:26.435  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 389 (count at Application.java:147) as input to shuffle 34
2022-07-30 11:42:26.436  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 38 (count at Application.java:147) with 1 output partitions
2022-07-30 11:42:26.436  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 73 (count at Application.java:147)
2022-07-30 11:42:26.436  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 72)
2022-07-30 11:42:26.437  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:42:26.437  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 73 (MapPartitionsRDD[392] at count at Application.java:147), which has no missing parents
2022-07-30 11:42:26.440  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_38 stored as values in memory (estimated size 11.0 KiB, free 897.1 MiB)
2022-07-30 11:42:26.447  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_38_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.1 MiB)
2022-07-30 11:42:26.448  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_38_piece0 in memory on host.docker.internal:58170 (size: 5.4 KiB, free: 897.5 MiB)
2022-07-30 11:42:26.448  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 38 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:42:26.449  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 73 (MapPartitionsRDD[392] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:42:26.449  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 73.0 with 1 tasks resource profile 0
2022-07-30 11:42:26.450  INFO   57 --- [er-event-loop-0] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 73.0 (TID 38) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:42:26.452  INFO   57 --- [e 73.0 (TID 38)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 73.0 (TID 38)
2022-07-30 11:42:26.454  INFO   57 --- [e 73.0 (TID 38)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:42:26.455  INFO   57 --- [e 73.0 (TID 38)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 1 ms
2022-07-30 11:42:26.457  INFO   57 --- [e 73.0 (TID 38)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 73.0 (TID 38). 2555 bytes result sent to driver
2022-07-30 11:42:26.459  INFO   57 --- [result-getter-1] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 73.0 (TID 38) in 10 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:42:26.460  INFO   57 --- [result-getter-1] org.apache.spark.internal.Logging        : Removed TaskSet 73.0, whose tasks have all completed, from pool 
2022-07-30 11:42:26.463  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 73 (count at Application.java:147) finished in 0.025 s
2022-07-30 11:42:26.464  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 38 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:42:26.464  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 73: Stage finished
2022-07-30 11:42:26.468  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 38 finished: count at Application.java:147, took 0.033121 s
2022-07-30 11:42:26.481  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:42:26.481  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:42:26.488  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177743000 ms.0 from job set of time 1659177743000 ms
2022-07-30 11:42:26.489  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 3.488 s for time 1659177743000 ms (execution: 0.157 s)
2022-07-30 11:42:26.489  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177744000 ms.0 from job set of time 1659177744000 ms
2022-07-30 11:42:26.516  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 159 from persistence list
2022-07-30 11:42:26.520  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 158 from persistence list
2022-07-30 11:42:26.520  INFO   57 --- [-thread-pool-80] org.apache.spark.internal.Logging        : Removing RDD 159
2022-07-30 11:42:26.522  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[158] at receiverStream at Application.java:122 of time 1659177743000 ms
2022-07-30 11:42:26.522  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177741000 ms
2022-07-30 11:42:26.523  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177741000 ms
2022-07-30 11:42:26.523  INFO   57 --- [-thread-pool-83] org.apache.spark.internal.Logging        : Removing RDD 158
2022-07-30 11:42:26.622  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:42:26.623  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 398 (count at Application.java:147) as input to shuffle 35
2022-07-30 11:42:26.624  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 39 (count at Application.java:147) with 1 output partitions
2022-07-30 11:42:26.624  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 75 (count at Application.java:147)
2022-07-30 11:42:26.624  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 74)
2022-07-30 11:42:26.624  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:42:26.624  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 75 (MapPartitionsRDD[401] at count at Application.java:147), which has no missing parents
2022-07-30 11:42:26.626  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_39 stored as values in memory (estimated size 11.0 KiB, free 897.1 MiB)
2022-07-30 11:42:26.628  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_39_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.1 MiB)
2022-07-30 11:42:26.629  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_39_piece0 in memory on host.docker.internal:58170 (size: 5.4 KiB, free: 897.5 MiB)
2022-07-30 11:42:26.630  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 39 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:42:26.634  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 75 (MapPartitionsRDD[401] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:42:26.634  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 75.0 with 1 tasks resource profile 0
2022-07-30 11:42:26.635  INFO   57 --- [er-event-loop-3] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 75.0 (TID 39) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:42:26.636  INFO   57 --- [e 75.0 (TID 39)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 75.0 (TID 39)
2022-07-30 11:42:26.639  INFO   57 --- [e 75.0 (TID 39)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:42:26.639  INFO   57 --- [e 75.0 (TID 39)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-30 11:42:26.640  INFO   57 --- [e 75.0 (TID 39)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 75.0 (TID 39). 2598 bytes result sent to driver
2022-07-30 11:42:26.641  INFO   57 --- [result-getter-2] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 75.0 (TID 39) in 6 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:42:26.641  INFO   57 --- [result-getter-2] org.apache.spark.internal.Logging        : Removed TaskSet 75.0, whose tasks have all completed, from pool 
2022-07-30 11:42:26.641  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 75 (count at Application.java:147) finished in 0.016 s
2022-07-30 11:42:26.642  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 39 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:42:26.642  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 75: Stage finished
2022-07-30 11:42:26.646  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 39 finished: count at Application.java:147, took 0.019759 s
2022-07-30 11:42:26.649  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177744000 ms.0 from job set of time 1659177744000 ms
2022-07-30 11:42:26.651  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 2.649 s for time 1659177744000 ms (execution: 0.160 s)
2022-07-30 11:42:26.651  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177745000 ms.0 from job set of time 1659177745000 ms
2022-07-30 11:42:26.651  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 170 from persistence list
2022-07-30 11:42:26.652  INFO   57 --- [-thread-pool-85] org.apache.spark.internal.Logging        : Removing RDD 170
2022-07-30 11:42:26.652  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 169 from persistence list
2022-07-30 11:42:26.653  INFO   57 --- [-thread-pool-86] org.apache.spark.internal.Logging        : Removing RDD 169
2022-07-30 11:42:26.653  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[169] at receiverStream at Application.java:122 of time 1659177744000 ms
2022-07-30 11:42:26.654  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177742000 ms
2022-07-30 11:42:26.654  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177742000 ms
2022-07-30 11:42:26.658  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:42:26.659  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:42:26.768  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:42:26.769  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 407 (count at Application.java:147) as input to shuffle 36
2022-07-30 11:42:26.771  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 40 (count at Application.java:147) with 1 output partitions
2022-07-30 11:42:26.771  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 77 (count at Application.java:147)
2022-07-30 11:42:26.771  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 76)
2022-07-30 11:42:26.772  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:42:26.773  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 77 (MapPartitionsRDD[410] at count at Application.java:147), which has no missing parents
2022-07-30 11:42:26.776  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_40 stored as values in memory (estimated size 11.0 KiB, free 897.1 MiB)
2022-07-30 11:42:26.782  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_40_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.1 MiB)
2022-07-30 11:42:26.783  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_40_piece0 in memory on host.docker.internal:58170 (size: 5.4 KiB, free: 897.5 MiB)
2022-07-30 11:42:26.783  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 40 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:42:26.784  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 77 (MapPartitionsRDD[410] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:42:26.784  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 77.0 with 1 tasks resource profile 0
2022-07-30 11:42:26.786  INFO   57 --- [er-event-loop-2] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 77.0 (TID 40) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:42:26.786  INFO   57 --- [e 77.0 (TID 40)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 77.0 (TID 40)
2022-07-30 11:42:26.790  INFO   57 --- [e 77.0 (TID 40)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:42:26.790  INFO   57 --- [e 77.0 (TID 40)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-30 11:42:26.791  INFO   57 --- [e 77.0 (TID 40)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 77.0 (TID 40). 2555 bytes result sent to driver
2022-07-30 11:42:26.794  INFO   57 --- [result-getter-3] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 77.0 (TID 40) in 9 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:42:26.795  INFO   57 --- [result-getter-3] org.apache.spark.internal.Logging        : Removed TaskSet 77.0, whose tasks have all completed, from pool 
2022-07-30 11:42:26.796  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 77 (count at Application.java:147) finished in 0.021 s
2022-07-30 11:42:26.796  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 40 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:42:26.796  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 77: Stage finished
2022-07-30 11:42:26.797  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 40 finished: count at Application.java:147, took 0.027813 s
2022-07-30 11:42:26.798  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177745000 ms.0 from job set of time 1659177745000 ms
2022-07-30 11:42:26.798  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 1.798 s for time 1659177745000 ms (execution: 0.147 s)
2022-07-30 11:42:26.798  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177746000 ms.0 from job set of time 1659177746000 ms
2022-07-30 11:42:26.800  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 217 from persistence list
2022-07-30 11:42:26.800  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:42:26.800  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:42:26.802  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 216 from persistence list
2022-07-30 11:42:26.803  INFO   57 --- [-thread-pool-93] org.apache.spark.internal.Logging        : Removing RDD 217
2022-07-30 11:42:26.804  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[216] at receiverStream at Application.java:122 of time 1659177745000 ms
2022-07-30 11:42:26.804  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177743000 ms
2022-07-30 11:42:26.805  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177743000 ms
2022-07-30 11:42:26.805  INFO   57 --- [-thread-pool-96] org.apache.spark.internal.Logging        : Removing RDD 216
2022-07-30 11:42:26.864  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:42:26.865  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 416 (count at Application.java:147) as input to shuffle 37
2022-07-30 11:42:26.882  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 41 (count at Application.java:147) with 1 output partitions
2022-07-30 11:42:26.886  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 79 (count at Application.java:147)
2022-07-30 11:42:26.886  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 78)
2022-07-30 11:42:26.887  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:42:26.889  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 79 (MapPartitionsRDD[419] at count at Application.java:147), which has no missing parents
2022-07-30 11:42:26.893  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_41 stored as values in memory (estimated size 11.0 KiB, free 897.1 MiB)
2022-07-30 11:42:26.898  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_41_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.1 MiB)
2022-07-30 11:42:26.901  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_41_piece0 in memory on host.docker.internal:58170 (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:42:26.901  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 41 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:42:26.902  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 79 (MapPartitionsRDD[419] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:42:26.902  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 79.0 with 1 tasks resource profile 0
2022-07-30 11:42:26.903  INFO   57 --- [er-event-loop-1] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 79.0 (TID 41) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:42:26.907  INFO   57 --- [e 79.0 (TID 41)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 79.0 (TID 41)
2022-07-30 11:42:26.919  INFO   57 --- [e 79.0 (TID 41)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:42:26.920  INFO   57 --- [e 79.0 (TID 41)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 2 ms
2022-07-30 11:42:26.923  INFO   57 --- [e 79.0 (TID 41)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 79.0 (TID 41). 2555 bytes result sent to driver
2022-07-30 11:42:26.924  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 79.0 (TID 41) in 21 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:42:26.926  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Removed TaskSet 79.0, whose tasks have all completed, from pool 
2022-07-30 11:42:26.931  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 79 (count at Application.java:147) finished in 0.034 s
2022-07-30 11:42:26.931  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 41 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:42:26.931  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 79: Stage finished
2022-07-30 11:42:26.935  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 41 finished: count at Application.java:147, took 0.070168 s
2022-07-30 11:42:26.937  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177746000 ms.0 from job set of time 1659177746000 ms
2022-07-30 11:42:26.937  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 0.937 s for time 1659177746000 ms (execution: 0.139 s)
2022-07-30 11:42:26.938  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 282 from persistence list
2022-07-30 11:42:26.939  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 281 from persistence list
2022-07-30 11:42:26.939  INFO   57 --- [c-thread-pool-1] org.apache.spark.internal.Logging        : Removing RDD 282
2022-07-30 11:42:26.947  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[281] at receiverStream at Application.java:122 of time 1659177746000 ms
2022-07-30 11:42:26.949  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177744000 ms
2022-07-30 11:42:26.949  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177744000 ms
2022-07-30 11:42:26.949  INFO   57 --- [c-thread-pool-2] org.apache.spark.internal.Logging        : Removing RDD 281
2022-07-30 11:42:27.002  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177747000 ms
2022-07-30 11:42:27.002  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177747000 ms.0 from job set of time 1659177747000 ms
2022-07-30 11:42:27.005  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:42:27.005  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:42:27.115  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:42:27.115  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 427 (count at Application.java:147) as input to shuffle 38
2022-07-30 11:42:27.116  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 42 (count at Application.java:147) with 1 output partitions
2022-07-30 11:42:27.116  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 81 (count at Application.java:147)
2022-07-30 11:42:27.116  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 80)
2022-07-30 11:42:27.116  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:42:27.117  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 81 (MapPartitionsRDD[430] at count at Application.java:147), which has no missing parents
2022-07-30 11:42:27.118  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_42 stored as values in memory (estimated size 11.0 KiB, free 897.0 MiB)
2022-07-30 11:42:27.435  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_42_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.0 MiB)
2022-07-30 11:42:27.436  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_42_piece0 in memory on host.docker.internal:58170 (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:42:27.437  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 42 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:42:27.437  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 81 (MapPartitionsRDD[430] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:42:27.438  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 81.0 with 1 tasks resource profile 0
2022-07-30 11:42:27.438  INFO   57 --- [er-event-loop-0] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 81.0 (TID 42) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:42:27.439  INFO   57 --- [e 81.0 (TID 42)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 81.0 (TID 42)
2022-07-30 11:42:27.442  INFO   57 --- [e 81.0 (TID 42)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:42:27.442  INFO   57 --- [e 81.0 (TID 42)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-30 11:42:27.447  INFO   57 --- [e 81.0 (TID 42)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 81.0 (TID 42). 2555 bytes result sent to driver
2022-07-30 11:42:27.448  INFO   57 --- [result-getter-1] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 81.0 (TID 42) in 10 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:42:27.448  INFO   57 --- [result-getter-1] org.apache.spark.internal.Logging        : Removed TaskSet 81.0, whose tasks have all completed, from pool 
2022-07-30 11:42:27.449  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 81 (count at Application.java:147) finished in 0.332 s
2022-07-30 11:42:27.449  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 42 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:42:27.452  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 81: Stage finished
2022-07-30 11:42:27.452  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 42 finished: count at Application.java:147, took 0.337114 s
2022-07-30 11:42:27.453  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177747000 ms.0 from job set of time 1659177747000 ms
2022-07-30 11:42:27.454  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 0.453 s for time 1659177747000 ms (execution: 0.451 s)
2022-07-30 11:42:27.455  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 360 from persistence list
2022-07-30 11:42:27.457  INFO   57 --- [c-thread-pool-3] org.apache.spark.internal.Logging        : Removing RDD 360
2022-07-30 11:42:27.459  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 359 from persistence list
2022-07-30 11:42:27.462  INFO   57 --- [c-thread-pool-7] org.apache.spark.internal.Logging        : Removing RDD 359
2022-07-30 11:42:27.463  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[359] at receiverStream at Application.java:122 of time 1659177747000 ms
2022-07-30 11:42:27.463  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177745000 ms
2022-07-30 11:42:27.464  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177745000 ms
2022-07-30 11:42:28.002  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177748000 ms
2022-07-30 11:42:28.002  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177748000 ms.0 from job set of time 1659177748000 ms
2022-07-30 11:42:28.005  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:42:28.005  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:42:28.092  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:42:28.094  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 438 (count at Application.java:147) as input to shuffle 39
2022-07-30 11:42:28.095  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 43 (count at Application.java:147) with 1 output partitions
2022-07-30 11:42:28.095  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 83 (count at Application.java:147)
2022-07-30 11:42:28.095  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 82)
2022-07-30 11:42:28.096  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:42:28.096  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 83 (MapPartitionsRDD[441] at count at Application.java:147), which has no missing parents
2022-07-30 11:42:28.099  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_43 stored as values in memory (estimated size 11.0 KiB, free 897.0 MiB)
2022-07-30 11:42:28.101  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_43_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.0 MiB)
2022-07-30 11:42:28.102  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_43_piece0 in memory on host.docker.internal:58170 (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:42:28.103  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 43 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:42:28.103  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 83 (MapPartitionsRDD[441] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:42:28.103  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 83.0 with 1 tasks resource profile 0
2022-07-30 11:42:28.104  INFO   57 --- [er-event-loop-3] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 83.0 (TID 43) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:42:28.105  INFO   57 --- [e 83.0 (TID 43)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 83.0 (TID 43)
2022-07-30 11:42:28.108  INFO   57 --- [e 83.0 (TID 43)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:42:28.108  INFO   57 --- [e 83.0 (TID 43)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-30 11:42:28.109  INFO   57 --- [e 83.0 (TID 43)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 83.0 (TID 43). 2598 bytes result sent to driver
2022-07-30 11:42:28.111  INFO   57 --- [result-getter-2] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 83.0 (TID 43) in 7 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:42:28.111  INFO   57 --- [result-getter-2] org.apache.spark.internal.Logging        : Removed TaskSet 83.0, whose tasks have all completed, from pool 
2022-07-30 11:42:28.112  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 83 (count at Application.java:147) finished in 0.015 s
2022-07-30 11:42:28.113  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 43 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:42:28.113  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 83: Stage finished
2022-07-30 11:42:28.114  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 43 finished: count at Application.java:147, took 0.020950 s
2022-07-30 11:42:28.116  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177748000 ms.0 from job set of time 1659177748000 ms
2022-07-30 11:42:28.116  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 0.116 s for time 1659177748000 ms (execution: 0.114 s)
2022-07-30 11:42:28.119  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 421 from persistence list
2022-07-30 11:42:28.120  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 420 from persistence list
2022-07-30 11:42:28.120  INFO   57 --- [-thread-pool-12] org.apache.spark.internal.Logging        : Removing RDD 421
2022-07-30 11:42:28.121  INFO   57 --- [-thread-pool-11] org.apache.spark.internal.Logging        : Removing RDD 420
2022-07-30 11:42:28.121  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[420] at receiverStream at Application.java:122 of time 1659177748000 ms
2022-07-30 11:42:28.121  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177746000 ms
2022-07-30 11:42:28.122  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177746000 ms
2022-07-30 11:42:29.005  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177749000 ms
2022-07-30 11:42:29.006  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177749000 ms.0 from job set of time 1659177749000 ms
2022-07-30 11:42:29.011  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:42:29.011  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:42:29.096  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:42:29.097  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 449 (count at Application.java:147) as input to shuffle 40
2022-07-30 11:42:29.097  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 44 (count at Application.java:147) with 1 output partitions
2022-07-30 11:42:29.097  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 85 (count at Application.java:147)
2022-07-30 11:42:29.097  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 84)
2022-07-30 11:42:29.098  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:42:29.098  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 85 (MapPartitionsRDD[452] at count at Application.java:147), which has no missing parents
2022-07-30 11:42:29.099  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_44 stored as values in memory (estimated size 11.0 KiB, free 897.0 MiB)
2022-07-30 11:42:29.101  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_44_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.0 MiB)
2022-07-30 11:42:29.102  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_44_piece0 in memory on host.docker.internal:58170 (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:42:29.102  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 44 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:42:29.103  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 85 (MapPartitionsRDD[452] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:42:29.103  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 85.0 with 1 tasks resource profile 0
2022-07-30 11:42:29.104  INFO   57 --- [er-event-loop-2] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 85.0 (TID 44) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:42:29.104  INFO   57 --- [e 85.0 (TID 44)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 85.0 (TID 44)
2022-07-30 11:42:29.108  INFO   57 --- [e 85.0 (TID 44)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:42:29.108  INFO   57 --- [e 85.0 (TID 44)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-30 11:42:29.109  INFO   57 --- [e 85.0 (TID 44)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 85.0 (TID 44). 2598 bytes result sent to driver
2022-07-30 11:42:29.110  INFO   57 --- [result-getter-3] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 85.0 (TID 44) in 6 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:42:29.111  INFO   57 --- [result-getter-3] org.apache.spark.internal.Logging        : Removed TaskSet 85.0, whose tasks have all completed, from pool 
2022-07-30 11:42:29.111  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 85 (count at Application.java:147) finished in 0.012 s
2022-07-30 11:42:29.112  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 44 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:42:29.112  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 85: Stage finished
2022-07-30 11:42:29.112  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 44 finished: count at Application.java:147, took 0.016059 s
2022-07-30 11:42:29.114  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177749000 ms.0 from job set of time 1659177749000 ms
2022-07-30 11:42:29.114  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 0.113 s for time 1659177749000 ms (execution: 0.108 s)
2022-07-30 11:42:29.115  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 432 from persistence list
2022-07-30 11:42:29.116  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 431 from persistence list
2022-07-30 11:42:29.116  INFO   57 --- [-thread-pool-17] org.apache.spark.internal.Logging        : Removing RDD 432
2022-07-30 11:42:29.118  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[431] at receiverStream at Application.java:122 of time 1659177749000 ms
2022-07-30 11:42:29.118  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177747000 ms
2022-07-30 11:42:29.118  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177747000 ms
2022-07-30 11:42:29.119  INFO   57 --- [-thread-pool-20] org.apache.spark.internal.Logging        : Removing RDD 431
2022-07-30 11:42:30.001  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177750000 ms
2022-07-30 11:42:30.001  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177750000 ms.0 from job set of time 1659177750000 ms
2022-07-30 11:42:30.004  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:42:30.004  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:42:30.060  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:42:30.061  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 460 (count at Application.java:147) as input to shuffle 41
2022-07-30 11:42:30.062  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 45 (count at Application.java:147) with 1 output partitions
2022-07-30 11:42:30.062  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 87 (count at Application.java:147)
2022-07-30 11:42:30.062  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 86)
2022-07-30 11:42:30.062  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:42:30.063  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 87 (MapPartitionsRDD[463] at count at Application.java:147), which has no missing parents
2022-07-30 11:42:30.065  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_45 stored as values in memory (estimated size 11.0 KiB, free 897.0 MiB)
2022-07-30 11:42:30.066  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_45_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.0 MiB)
2022-07-30 11:42:30.067  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_45_piece0 in memory on host.docker.internal:58170 (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:42:30.067  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 45 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:42:30.068  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 87 (MapPartitionsRDD[463] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:42:30.068  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 87.0 with 1 tasks resource profile 0
2022-07-30 11:42:30.069  INFO   57 --- [er-event-loop-1] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 87.0 (TID 45) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:42:30.070  INFO   57 --- [e 87.0 (TID 45)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 87.0 (TID 45)
2022-07-30 11:42:30.080  INFO   57 --- [e 87.0 (TID 45)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:42:30.081  INFO   57 --- [e 87.0 (TID 45)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-30 11:42:30.082  INFO   57 --- [e 87.0 (TID 45)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 87.0 (TID 45). 2598 bytes result sent to driver
2022-07-30 11:42:30.083  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 87.0 (TID 45) in 14 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:42:30.083  INFO   57 --- [result-getter-0] org.apache.spark.internal.Logging        : Removed TaskSet 87.0, whose tasks have all completed, from pool 
2022-07-30 11:42:30.083  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 87 (count at Application.java:147) finished in 0.020 s
2022-07-30 11:42:30.083  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 45 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:42:30.084  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 87: Stage finished
2022-07-30 11:42:30.084  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 45 finished: count at Application.java:147, took 0.023428 s
2022-07-30 11:42:30.085  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177750000 ms.0 from job set of time 1659177750000 ms
2022-07-30 11:42:30.085  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 0.084 s for time 1659177750000 ms (execution: 0.083 s)
2022-07-30 11:42:30.085  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 443 from persistence list
2022-07-30 11:42:30.086  INFO   57 --- [-thread-pool-22] org.apache.spark.internal.Logging        : Removing RDD 443
2022-07-30 11:42:30.086  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 442 from persistence list
2022-07-30 11:42:30.087  INFO   57 --- [-thread-pool-23] org.apache.spark.internal.Logging        : Removing RDD 442
2022-07-30 11:42:30.087  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[442] at receiverStream at Application.java:122 of time 1659177750000 ms
2022-07-30 11:42:30.087  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177748000 ms
2022-07-30 11:42:30.087  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177748000 ms
2022-07-30 11:42:31.002  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177751000 ms
2022-07-30 11:42:31.003  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177751000 ms.0 from job set of time 1659177751000 ms
2022-07-30 11:42:31.006  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:42:31.007  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:42:31.069  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:42:31.069  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 471 (count at Application.java:147) as input to shuffle 42
2022-07-30 11:42:31.070  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 46 (count at Application.java:147) with 1 output partitions
2022-07-30 11:42:31.070  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 89 (count at Application.java:147)
2022-07-30 11:42:31.070  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 88)
2022-07-30 11:42:31.071  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:42:31.071  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 89 (MapPartitionsRDD[474] at count at Application.java:147), which has no missing parents
2022-07-30 11:42:31.073  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_46 stored as values in memory (estimated size 11.0 KiB, free 897.0 MiB)
2022-07-30 11:42:31.075  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_46_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.0 MiB)
2022-07-30 11:42:31.075  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_46_piece0 in memory on host.docker.internal:58170 (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:42:31.076  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 46 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:42:31.077  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 89 (MapPartitionsRDD[474] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:42:31.077  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 89.0 with 1 tasks resource profile 0
2022-07-30 11:42:31.078  INFO   57 --- [er-event-loop-0] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 89.0 (TID 46) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:42:31.081  INFO   57 --- [e 89.0 (TID 46)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 89.0 (TID 46)
2022-07-30 11:42:31.086  INFO   57 --- [e 89.0 (TID 46)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:42:31.087  INFO   57 --- [e 89.0 (TID 46)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-30 11:42:31.088  INFO   57 --- [e 89.0 (TID 46)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 89.0 (TID 46). 2555 bytes result sent to driver
2022-07-30 11:42:31.089  INFO   57 --- [result-getter-1] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 89.0 (TID 46) in 11 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:42:31.089  INFO   57 --- [result-getter-1] org.apache.spark.internal.Logging        : Removed TaskSet 89.0, whose tasks have all completed, from pool 
2022-07-30 11:42:31.089  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 89 (count at Application.java:147) finished in 0.017 s
2022-07-30 11:42:31.090  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 46 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:42:31.090  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 89: Stage finished
2022-07-30 11:42:31.090  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 46 finished: count at Application.java:147, took 0.021172 s
2022-07-30 11:42:31.091  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177751000 ms.0 from job set of time 1659177751000 ms
2022-07-30 11:42:31.092  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 0.091 s for time 1659177751000 ms (execution: 0.089 s)
2022-07-30 11:42:31.092  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 454 from persistence list
2022-07-30 11:42:31.095  INFO   57 --- [-thread-pool-29] org.apache.spark.internal.Logging        : Removing RDD 454
2022-07-30 11:42:31.095  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 453 from persistence list
2022-07-30 11:42:31.096  INFO   57 --- [-thread-pool-32] org.apache.spark.internal.Logging        : Removing RDD 453
2022-07-30 11:42:31.096  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[453] at receiverStream at Application.java:122 of time 1659177751000 ms
2022-07-30 11:42:31.097  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177749000 ms
2022-07-30 11:42:31.097  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177749000 ms
2022-07-30 11:42:32.004  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177752000 ms
2022-07-30 11:42:32.004  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177752000 ms.0 from job set of time 1659177752000 ms
2022-07-30 11:42:32.010  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:42:32.010  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:42:32.061  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:42:32.062  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 482 (count at Application.java:147) as input to shuffle 43
2022-07-30 11:42:32.062  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 47 (count at Application.java:147) with 1 output partitions
2022-07-30 11:42:32.062  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 91 (count at Application.java:147)
2022-07-30 11:42:32.062  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 90)
2022-07-30 11:42:32.062  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:42:32.063  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 91 (MapPartitionsRDD[485] at count at Application.java:147), which has no missing parents
2022-07-30 11:42:32.064  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_47 stored as values in memory (estimated size 11.0 KiB, free 897.0 MiB)
2022-07-30 11:42:32.066  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_47_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 897.0 MiB)
2022-07-30 11:42:32.067  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_47_piece0 in memory on host.docker.internal:58170 (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:42:32.067  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 47 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:42:32.067  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 91 (MapPartitionsRDD[485] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:42:32.068  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 91.0 with 1 tasks resource profile 0
2022-07-30 11:42:32.068  INFO   57 --- [er-event-loop-3] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 91.0 (TID 47) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:42:32.069  INFO   57 --- [e 91.0 (TID 47)] org.apache.spark.internal.Logging        : Running task 0.0 in stage 91.0 (TID 47)
2022-07-30 11:42:32.071  INFO   57 --- [e 91.0 (TID 47)] org.apache.spark.internal.Logging        : Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2022-07-30 11:42:32.072  INFO   57 --- [e 91.0 (TID 47)] org.apache.spark.internal.Logging        : Started 0 remote fetches in 0 ms
2022-07-30 11:42:32.072  INFO   57 --- [e 91.0 (TID 47)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 91.0 (TID 47). 2555 bytes result sent to driver
2022-07-30 11:42:32.073  INFO   57 --- [result-getter-2] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 91.0 (TID 47) in 5 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:42:32.074  INFO   57 --- [result-getter-2] org.apache.spark.internal.Logging        : Removed TaskSet 91.0, whose tasks have all completed, from pool 
2022-07-30 11:42:32.074  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 91 (count at Application.java:147) finished in 0.011 s
2022-07-30 11:42:32.074  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 47 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:42:32.074  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 91: Stage finished
2022-07-30 11:42:32.075  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Job 47 finished: count at Application.java:147, took 0.013180 s
2022-07-30 11:42:32.075  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Finished job streaming job 1659177752000 ms.0 from job set of time 1659177752000 ms
2022-07-30 11:42:32.076  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Total delay: 0.075 s for time 1659177752000 ms (execution: 0.071 s)
2022-07-30 11:42:32.077  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 465 from persistence list
2022-07-30 11:42:32.078  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing RDD 464 from persistence list
2022-07-30 11:42:32.078  INFO   57 --- [-thread-pool-34] org.apache.spark.internal.Logging        : Removing RDD 465
2022-07-30 11:42:32.080  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Removing blocks of RDD BlockRDD[464] at receiverStream at Application.java:122 of time 1659177752000 ms
2022-07-30 11:42:32.080  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Deleting batches: 1659177750000 ms
2022-07-30 11:42:32.080  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : remove old batch metadata: 1659177750000 ms
2022-07-30 11:42:32.080  INFO   57 --- [-thread-pool-41] org.apache.spark.internal.Logging        : Removing RDD 464
2022-07-30 11:42:33.650  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177753000 ms
2022-07-30 11:42:33.650  INFO   57 --- [   JobScheduler] org.apache.spark.internal.Logging        : Starting job streaming job 1659177753000 ms.0 from job set of time 1659177753000 ms
2022-07-30 11:42:33.654  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; the static sql configurations will not take effect.
2022-07-30 11:42:33.654  WARN   69 --- [-job-executor-0] org.apache.spark.internal.Logging        : Using an existing SparkSession; some spark core configurations may not take effect.
2022-07-30 11:42:34.443  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177754000 ms
2022-07-30 11:42:34.446  INFO   57 --- [shutdown-hook-0] org.apache.spark.internal.Logging        : Invoking stop(stopGracefully=false) from shutdown hook
2022-07-30 11:42:34.450  INFO   57 --- [-job-executor-0] org.apache.spark.internal.Logging        : Starting job: count at Application.java:147
2022-07-30 11:42:34.451  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Registering RDD 493 (count at Application.java:147) as input to shuffle 44
2022-07-30 11:42:34.452  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Got job 48 (count at Application.java:147) with 1 output partitions
2022-07-30 11:42:34.452  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Final stage: ResultStage 93 (count at Application.java:147)
2022-07-30 11:42:34.452  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Parents of final stage: List(ShuffleMapStage 92)
2022-07-30 11:42:34.452  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Missing parents: List()
2022-07-30 11:42:34.452  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting ResultStage 93 (MapPartitionsRDD[496] at count at Application.java:147), which has no missing parents
2022-07-30 11:42:34.454  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_48 stored as values in memory (estimated size 11.0 KiB, free 896.9 MiB)
2022-07-30 11:42:34.456  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Block broadcast_48_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 896.9 MiB)
2022-07-30 11:42:34.457  INFO   57 --- [er-event-loop-2] org.apache.spark.internal.Logging        : Sent stop signal to all 1 receivers
2022-07-30 11:42:34.457  INFO   57 --- [ckManagerMaster] org.apache.spark.internal.Logging        : Added broadcast_48_piece0 in memory on host.docker.internal:58170 (size: 5.4 KiB, free: 897.4 MiB)
2022-07-30 11:42:34.458  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Created broadcast 48 from broadcast at DAGScheduler.scala:1478
2022-07-30 11:42:34.458  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Submitting 1 missing tasks from ResultStage 93 (MapPartitionsRDD[496] at count at Application.java:147) (first 15 tasks are for partitions Vector(0))
2022-07-30 11:42:34.458  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Adding task set 93.0 with 1 tasks resource profile 0
2022-07-30 11:42:34.458  INFO   57 --- [er-event-loop-3] org.apache.spark.internal.Logging        : Received stop signal
2022-07-30 11:42:34.461  INFO   57 --- [er-event-loop-0] org.apache.spark.internal.Logging        : Starting task 0.0 in stage 93.0 (TID 48) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-07-30 11:42:34.461  INFO   57 --- [er-event-loop-3] org.apache.spark.internal.Logging        : Stopping receiver with message: Stopped by driver: 
2022-07-30 11:42:34.462  INFO   57 --- [er-event-loop-3] org.apache.spark.internal.Logging        : Called receiver onStop
2022-07-30 11:42:34.462  INFO   57 --- [er-event-loop-3] org.apache.spark.internal.Logging        : Deregistering receiver 0
2022-07-30 11:42:34.463  ERROR   94 --- [er-event-loop-0] org.apache.spark.internal.Logging        : Ignoring error
java.util.concurrent.RejectedExecutionException: Task org.apache.spark.executor.Executor$TaskRunner@e1fc5d4 rejected from java.util.concurrent.ThreadPoolExecutor@71a2099f[Shutting down, pool size = 1, active threads = 1, queued tasks = 0, completed tasks = 47]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2063)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:830)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1379)
	at org.apache.spark.executor.Executor.launchTask(Executor.scala:270)
	at org.apache.spark.scheduler.local.LocalEndpoint.$anonfun$reviveOffers$1(LocalSchedulerBackend.scala:93)
	at org.apache.spark.scheduler.local.LocalEndpoint.$anonfun$reviveOffers$1$adapted(LocalSchedulerBackend.scala:91)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at org.apache.spark.scheduler.local.LocalEndpoint.reviveOffers(LocalSchedulerBackend.scala:91)
	at org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$receive$1.applyOrElse(LocalSchedulerBackend.scala:68)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:115)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2022-07-30 11:42:34.465  ERROR   73 --- [er-event-loop-1] org.apache.spark.internal.Logging        : Deregistered receiver for stream 0: Stopped by driver
2022-07-30 11:42:34.716  INFO   57 --- [er-event-loop-3] org.apache.spark.internal.Logging        : Stopped receiver 0
2022-07-30 11:42:34.722  INFO   57 --- [er-event-loop-3] org.apache.spark.internal.Logging        : Stopping BlockGenerator
2022-07-30 11:42:35.003  INFO   57 --- [er-event-loop-3] org.apache.spark.internal.Logging        : Stopped timer for BlockGenerator after time 1659177755000
2022-07-30 11:42:35.005  INFO   57 --- [er-event-loop-3] org.apache.spark.internal.Logging        : Waiting for block pushing thread to terminate
2022-07-30 11:42:35.005  INFO   57 --- [   JobGenerator] org.apache.spark.internal.Logging        : Added jobs for time 1659177755000 ms
2022-07-30 11:42:35.012  INFO   57 --- [      Thread-14] org.apache.spark.internal.Logging        : Pushing out the last 0 blocks
2022-07-30 11:42:35.013  INFO   57 --- [      Thread-14] org.apache.spark.internal.Logging        : Stopped block pushing thread
2022-07-30 11:42:35.015  INFO   57 --- [er-event-loop-3] org.apache.spark.internal.Logging        : Stopped BlockGenerator
2022-07-30 11:42:35.645  INFO   57 --- [age 0.0 (TID 0)] org.apache.spark.internal.Logging        : Stopped receiver without error
2022-07-30 11:42:35.648  INFO   57 --- [age 0.0 (TID 0)] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 0.0 (TID 0). 880 bytes result sent to driver
2022-07-30 11:42:35.650  INFO   57 --- [result-getter-3] org.apache.spark.internal.Logging        : Finished task 0.0 in stage 0.0 (TID 0) in 44431 ms on host.docker.internal (executor driver) (1/1)
2022-07-30 11:42:35.650  INFO   57 --- [result-getter-3] org.apache.spark.internal.Logging        : Removed TaskSet 0.0, whose tasks have all completed, from pool 
2022-07-30 11:42:35.651  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : ResultStage 0 (start at Application.java:156) finished in 46.774 s
2022-07-30 11:42:35.652  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2022-07-30 11:42:35.652  INFO   57 --- [uler-event-loop] org.apache.spark.internal.Logging        : Killing all running tasks in stage 0: Stage finished
2022-07-30 11:42:35.656  INFO   57 --- [shutdown-hook-0] org.apache.spark.internal.Logging        : All of the receivers have deregistered successfully
2022-07-30 11:42:35.658  INFO   57 --- [shutdown-hook-0] org.apache.spark.internal.Logging        : ReceiverTracker stopped
2022-07-30 11:42:35.662  INFO   57 --- [shutdown-hook-0] org.apache.spark.internal.Logging        : Stopping JobGenerator immediately
2022-07-30 11:42:35.670  INFO   57 --- [shutdown-hook-0] org.apache.spark.internal.Logging        : Stopped timer for JobGenerator after time 1659177755000
2022-07-30 11:42:35.674  INFO   57 --- [shutdown-hook-0] org.apache.spark.internal.Logging        : Stopped JobGenerator
2022-07-30 11:42:37.700  INFO   57 --- [shutdown-hook-0] org.apache.spark.internal.Logging        : Stopped JobScheduler
2022-07-30 11:42:37.748  INFO 1153 --- [shutdown-hook-0] ject.jetty.server.handler.ContextHandler : Stopped o.s.j.s.ServletContextHandler@3910fe11{/streaming,null,STOPPED,@Spark}
2022-07-30 11:42:37.750  INFO 1153 --- [shutdown-hook-0] ject.jetty.server.handler.ContextHandler : Stopped o.s.j.s.ServletContextHandler@351e414e{/streaming/json,null,STOPPED,@Spark}
2022-07-30 11:42:37.751  INFO 1153 --- [shutdown-hook-0] ject.jetty.server.handler.ContextHandler : Stopped o.s.j.s.ServletContextHandler@2c2db130{/streaming/batch,null,STOPPED,@Spark}
2022-07-30 11:42:37.751  INFO 1153 --- [shutdown-hook-0] ject.jetty.server.handler.ContextHandler : Stopped o.s.j.s.ServletContextHandler@348d18a3{/streaming/batch/json,null,STOPPED,@Spark}
2022-07-30 11:42:37.753  INFO 1153 --- [shutdown-hook-0] ject.jetty.server.handler.ContextHandler : Stopped o.s.j.s.ServletContextHandler@20e6c4dc{/static/streaming,null,STOPPED,@Spark}
2022-07-30 11:42:37.754  INFO  167 --- [           main] com.elite.cdr.validator.Application      : ****************************************************
2022-07-30 11:42:37.755  INFO   57 --- [shutdown-hook-0] org.apache.spark.internal.Logging        : StreamingContext stopped successfully
2022-07-30 11:42:37.796  INFO  168 --- [           main] com.elite.cdr.validator.Application      : Duration: 0.0 seconds
2022-07-30 11:42:37.796  INFO  169 --- [           main] com.elite.cdr.validator.Application      : Batch executed with success
2022-07-30 11:42:37.796  INFO  170 --- [           main] com.elite.cdr.validator.Application      : ****************************************************
2022-07-30 11:42:37.796  INFO   57 --- [shutdown-hook-0] org.apache.spark.internal.Logging        : Invoking stop() from shutdown hook
2022-07-30 11:42:37.935  INFO  381 --- [shutdown-hook-0] rkproject.jetty.server.AbstractConnector : Stopped Spark@3b9d6699{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2022-07-30 11:42:37.940  INFO   57 --- [shutdown-hook-0] org.apache.spark.internal.Logging        : Stopped Spark web UI at http://host.docker.internal:4040
2022-07-30 11:42:37.949  INFO   57 --- [shutdown-hook-0] org.apache.spark.internal.Logging        : ResultStage 93 (count at Application.java:147) failed in 3.496 s due to Stage cancelled because SparkContext was shut down
2022-07-30 11:42:38.142  INFO   57 --- [er-event-loop-1] org.apache.spark.internal.Logging        : MapOutputTrackerMasterEndpoint stopped!
2022-07-30 11:42:38.313  INFO   57 --- [shutdown-hook-0] org.apache.spark.internal.Logging        : MemoryStore cleared
2022-07-30 11:42:38.314  INFO   57 --- [shutdown-hook-0] org.apache.spark.internal.Logging        : BlockManager stopped
2022-07-30 11:42:38.334  INFO   57 --- [shutdown-hook-0] org.apache.spark.internal.Logging        : BlockManagerMaster stopped
2022-07-30 11:42:38.374  INFO   57 --- [er-event-loop-2] org.apache.spark.internal.Logging        : OutputCommitCoordinator stopped!
2022-07-30 11:42:38.380  INFO   57 --- [shutdown-hook-0] org.apache.spark.internal.Logging        : Successfully stopped SparkContext
2022-07-30 11:42:38.380  INFO   57 --- [shutdown-hook-0] org.apache.spark.internal.Logging        : Shutdown hook called
2022-07-30 11:42:38.381  INFO   57 --- [shutdown-hook-0] org.apache.spark.internal.Logging        : Deleting directory C:\Users\Wael Hamdi\AppData\Local\Temp\spark-dd051668-4184-4362-803e-6132ddd51cfe
